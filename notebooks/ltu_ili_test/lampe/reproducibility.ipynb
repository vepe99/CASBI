{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mcolors\n",
    "mpl.style.use('../../paper.mcstyle')\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "    \n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn as nn\n",
    "\n",
    "import ili\n",
    "from ili.dataloaders import NumpyLoader, TorchLoader\n",
    "from ili.inference import InferenceRunner\n",
    "from ili.validation.metrics import PosteriorCoverage, PlotSinglePosterior\n",
    "from CNN import ConvNet\n",
    "from CASBI.utils import create_template_library as ctl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoneNone\n",
      "NoneNoneNone\n",
      "\n",
      "\n",
      "\n",
      "NoneNone\n",
      "\n",
      "NoneNoneNoneNoneNoneNone\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "NoneNone\n",
      "\n",
      "None\n",
      "NoneNone\n",
      "\n",
      "\n",
      "None\n",
      "NoneNone\n",
      "None\n",
      "None\n",
      "\n",
      "\n",
      "NoneNoneNone\n",
      "\n",
      "\n",
      "NoneNone\n",
      "\n",
      "None\n",
      "None\n",
      "NoneNone\n",
      "\n",
      "None\n",
      "NoneNone\n",
      "None\n",
      "NoneNoneNone\n",
      "None\n",
      "\n",
      "\n",
      "None\n",
      "None\n",
      "\n",
      "NoneNone\n",
      "NoneNoneNoneNone\n",
      "NoneNone\n",
      "\n",
      "None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "None\n",
      "\n",
      "NoneNone\n",
      "None\n",
      "\n",
      "NoneNoneNone\n",
      "\n",
      "None\n",
      "\n",
      "None\n",
      "None\n",
      "NoneNone\n",
      "\n",
      "NoneNone\n",
      "None\n",
      "\n",
      "None\n",
      "None\n",
      "None\n",
      "NoneNone\n",
      "\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "NoneNone\n",
      "\n",
      "NoneNone\n",
      "\n",
      "NoneNone\n",
      "\n",
      "NoneNone\n",
      "\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "NoneNone\n",
      "\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "NoneNone\n",
      "None\n",
      "\n",
      "unique galaxy in the test set that are not empty: 96\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    data = pd.read_parquet('/export/data/vgiusepp/data/full_dataframe/dataframe/dataframe.parquet')\n",
    "    data['star_log10mass'] = 10**data['star_log10mass']\n",
    "    data_mass = data['star_log10mass'].drop_duplicates()\n",
    "    data_mass = data_mass[data_mass<1.4*1e9]\n",
    "    \n",
    "    m_min, m_max = data_mass.min(), data_mass.max()\n",
    "    alpha = 1.25\n",
    "   \n",
    "    mass_name = data[['star_log10mass', 'Galaxy_name', 'infall_time']].drop_duplicates()\n",
    "    mass_name = mass_name[mass_name['star_log10mass']<1.4*1e9]\n",
    "    min_feh, max_feh = data['feh'].min(), data['feh'].max() \n",
    "    min_ofe, max_ofe = data['ofe'].min(), data['ofe'].max()\n",
    "    mass_nn = mass_name['star_log10mass'].values.reshape(-1, 1)\n",
    "    infall_time = mass_name['infall_time'].values.reshape(-1, 1)\n",
    "    galaxy_name = mass_name['Galaxy_name'].values.reshape(-1, 1)\n",
    "    \n",
    "    test_set_sample = 100\n",
    "    train_set_sample = 1_000\n",
    "\n",
    "    mass_nn = mass_name['star_log10mass'].values.reshape(-1, 1)\n",
    "    infall_time = mass_name['infall_time'].values.reshape(-1, 1)\n",
    "    galaxy_name = mass_name['Galaxy_name'].values.reshape(-1, 1)\n",
    "    # with Pool(processes=cpu_count()) as p:\n",
    "    #     result = p.starmap(ctl.gen_real_halo, [[j, galaxy_name, mass_nn, infall_time, m_max, m_min, alpha] for j in range(test_set_sample)]   )\n",
    "    \n",
    "    result = ctl.gen_template_library(test_set_sample, galaxy_name, mass_nn, infall_time, m_max, m_min, alpha)\n",
    "\n",
    "    hist_list_test, params_list_test, galaxy_list_test = zip(*result)\n",
    "\n",
    "    #create the filter to take only the unique galaxies \n",
    "    single_galaxy_test = [arr[0] for arr in galaxy_list_test if arr.size > 0]\n",
    "    unique_indices_test = list({tuple(arr): i for i, arr in enumerate(map(tuple, single_galaxy_test))}.values())\n",
    "    print('unique galaxy in the test set that are not empty:', len(unique_indices_test))\n",
    "\n",
    "    flattened_hist_list_test = [item for i, sublist in enumerate(hist_list_test) if i in unique_indices_test for item in sublist]\n",
    "    flattened_param_list_test = [item for i, sublist in enumerate(params_list_test) if i in unique_indices_test for item in sublist]\n",
    "    flattened_hist_list_test =  np.array(flattened_hist_list_test)\n",
    "    flattened_param_list_test =  np.array(flattened_param_list_test)\n",
    "    galaxies_test = [set(arr[0]) for arr in galaxy_list_test if arr.size > 0] #list that contains set of names of the galaxy in the test set to compare it with the training set \n",
    "\n",
    "\n",
    "    with Pool(processes=cpu_count()) as p:\n",
    "        result = p.starmap(ctl.gen_real_halo, [[j+test_set_sample, galaxy_name, mass_nn, infall_time, galaxies_test] for j in range(train_set_sample)]   )\n",
    "\n",
    "    hist_list, params_list, galaxy_list = zip(*result)\n",
    "\n",
    "    #create the filter to take only the unique galaxies \n",
    "    single_galaxy = [arr[0] for arr in galaxy_list if arr.size > 0]\n",
    "    unique_indices = list({tuple(arr): i for i, arr in enumerate(map(tuple, single_galaxy))}.values())\n",
    "    flattened_hist_list = [item for i, sublist in enumerate(hist_list) if i in unique_indices for item in sublist]\n",
    "    flattened_param_list = [item for i, sublist in enumerate(params_list) if i in unique_indices for item in sublist]\n",
    "    flattened_hist_list =  np.array(flattened_hist_list)\n",
    "    flattened_param_list =  np.array(flattened_param_list)\n",
    "    print('unique galaxy in the training set that are not empty:', len(unique_indices))\n",
    "    \n",
    "    mask = [flattened_hist_list[:, 1, 0, 0] < np.random.uniform(low=0, high=100, size=len(flattened_hist_list[:, 1, 0, 0])) ][0] #applying a mask to not overfit on high N\n",
    "    # mask = [flattened_hist_list[:, 1, 0, 0] < 20 ][0] #applying a mask to not overfit on high N\n",
    "    training_x = flattened_hist_list[mask]\n",
    "    training_theta = flattened_param_list[mask]\n",
    "\n",
    "\n",
    "    test_x = torch.log1p(torch.from_numpy(flattened_hist_list_test)).float()\n",
    "    test_theta = torch.log10(torch.from_numpy(flattened_param_list_test)).float()\n",
    "\n",
    "    x = torch.log1p(torch.from_numpy(training_x)).float()\n",
    "    theta = torch.log10(torch.from_numpy(training_theta)).float()\n",
    "    \n",
    "    \n",
    "    gpu_index = 6  # replace with your desired GPU index\n",
    "    torch.cuda.set_device(gpu_index)\n",
    "    device = f\"cuda:{gpu_index}\"\n",
    "    conditions  = mass_name[['star_log10mass', 'infall_time']]\n",
    "    minimum_theta = [np.log10(conditions[col].values.min()) for col in conditions.columns]   \n",
    "    maximum_theta = [np.log10(conditions[col].values.max()) for col in conditions.columns]    \n",
    "\n",
    "    \n",
    "    def write_to_yaml(minimum_theta, maximum_theta, device):\n",
    "        # Load the existing data\n",
    "        with open('./training.yaml', 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "            \n",
    "        # Update the value\n",
    "        # data['prior']['args']['low'] = minimum_theta[0]\n",
    "        # data['prior']['args']['high'] = maximum_theta[0]\n",
    "        data['device'] = device\n",
    "\n",
    "        # Write the data back to the file\n",
    "        with open('./training.yaml', 'w') as file:\n",
    "            yaml.safe_dump(data, file)\n",
    "            \n",
    "    # write_to_yaml(minimum_theta, maximum_theta, device)\n",
    "    print('write the right prior in the training.yaml file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    with Pool(processes=cpu_count()) as p:\n",
    "        result = p.starmap(ctl.gen_real_halo, [[j+test_set_sample, galaxy_name, mass_nn, infall_time, galaxies_test] for j in range(train_set_sample)]   )\n",
    "\n",
    "    hist_list, params_list, galaxy_list = zip(*result)\n",
    "\n",
    "    #create the filter to take only the unique galaxies \n",
    "    single_galaxy = [arr[0] for arr in galaxy_list if arr.size > 0]\n",
    "    unique_indices = list({tuple(arr): i for i, arr in enumerate(map(tuple, single_galaxy))}.values())\n",
    "    flattened_hist_list = [item for i, sublist in enumerate(hist_list) if i in unique_indices for item in sublist]\n",
    "    flattened_param_list = [item for i, sublist in enumerate(params_list) if i in unique_indices for item in sublist]\n",
    "    flattened_hist_list =  np.array(flattened_hist_list)\n",
    "    flattened_param_list =  np.array(flattened_param_list)\n",
    "    print('unique galaxy in the training set that are not empty:', len(unique_indices))\n",
    "    \n",
    "    mask = [flattened_hist_list[:, 1, 0, 0] < np.random.uniform(low=0, high=100, size=len(flattened_hist_list[:, 1, 0, 0])) ][0] #applying a mask to not overfit on high N\n",
    "    # mask = [flattened_hist_list[:, 1, 0, 0] < 20 ][0] #applying a mask to not overfit on high N\n",
    "    training_x = flattened_hist_list[mask]\n",
    "    training_theta = flattened_param_list[mask]\n",
    "\n",
    "\n",
    "    test_x = torch.log1p(torch.from_numpy(flattened_hist_list_test)).float()\n",
    "    test_theta = torch.log10(torch.from_numpy(flattened_param_list_test)).float()\n",
    "\n",
    "    x = torch.log1p(torch.from_numpy(training_x)).float()\n",
    "    theta = torch.log10(torch.from_numpy(training_theta)).float()\n",
    "    \n",
    "    \n",
    "    gpu_index = 6  # replace with your desired GPU index\n",
    "    torch.cuda.set_device(gpu_index)\n",
    "    device = f\"cuda:{gpu_index}\"\n",
    "    conditions  = mass_name[['star_log10mass', 'infall_time']]\n",
    "    minimum_theta = [np.log10(conditions[col].values.min()) for col in conditions.columns]   \n",
    "    maximum_theta = [np.log10(conditions[col].values.max()) for col in conditions.columns]    \n",
    "\n",
    "    \n",
    "    def write_to_yaml(minimum_theta, maximum_theta, device):\n",
    "        # Load the existing data\n",
    "        with open('./training.yaml', 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "            \n",
    "        # Update the value\n",
    "        # data['prior']['args']['low'] = minimum_theta[0]\n",
    "        # data['prior']['args']['high'] = maximum_theta[0]\n",
    "        data['device'] = device\n",
    "\n",
    "        # Write the data back to the file\n",
    "        with open('./training.yaml', 'w') as file:\n",
    "            yaml.safe_dump(data, file)\n",
    "            \n",
    "    # write_to_yaml(minimum_theta, maximum_theta, device)\n",
    "    print('write the right prior in the training.yaml file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
