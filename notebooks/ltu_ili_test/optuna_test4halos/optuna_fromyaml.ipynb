{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write the right prior in the training.yaml file\n",
      "matched galaxies, try again\n",
      "galaxies {'g4.86e10.00784', 'g7.66e11.00240'}\n",
      "test galaxies ({'g2.37e10.00880', 'g6.96e10.00368'}, {'g3.23e11.00784', 'g2.39e11.00400'}, {'g7.05e09.00288', 'g1.59e11.00960'}, {'g6.91e10.00192', 'g3.54e09.00192'}, {'g3.67e10.00640', 'g1.47e10.00944'}, {'g1.89e10.00944', 'g8.28e11.00496'}, {'g2.64e10.00480', 'g8.06e11.00256'}, {'g6.31e09.00400', 'g4.94e10.00784'}, {'g3.59e11.00320', 'g1.23e10.01008'}, {'g6.12e10.00672', 'g1.47e10.00832'}, {'g4.94e10.00368', 'g6.31e09.00688'}, {'g3.19e10.01008', 'g3.59e11.00224'}, {'g3.54e09.00928', 'g2.19e11.00928'}, {'g2.54e11.00064', 'g1.59e11.00944'}, {'g6.96e10.00720', 'g4.48e10.00352'}, {'g5.05e10.00656', 'g2.39e10.00256'}, {'g1.08e11.00672', 'g5.46e11.00752'}, {'g1.18e10.01024', 'g2.42e11.00896'}, {'g2.39e10.00320', 'g6.31e09.00432'}, {'g4.48e09.00912', 'g4.94e10.00080'}, {'g1.89e10.00480', 'g1.88e10.00128'}, {'g2.37e10.00656', 'g3.06e11.00208'}, {'g6.96e10.00128', 'g4.90e11.00704'}, {'g9.91e09.00752', 'g6.31e09.00240'}, {'g4.99e10.00720', 'g1.23e10.00336'}, {'g4.48e09.00272', 'g4.90e11.00592'}, {'g8.89e10.00832', 'g7.05e09.00912'}, {'g6.91e10.00320', 'g1.88e10.00992'}, {'g9.59e10.00128', 'g3.44e10.00464'}, {'g1.88e10.00960', 'g2.19e11.00320'}, {'g1.64e11.00368', 'g3.49e11.00576'}, {'g1.52e11.00864', 'g5.31e11.00400'}, {'g3.67e10.00400', 'g1.50e10.00336'}, {'g3.21e11.00656', 'g2.63e10.00368'}, {'g7.44e11.00656', 'g4.27e10.01008'}, {'g1.88e10.00672', 'g2.37e10.00800'}, {'g4.99e10.00992', 'g4.86e10.01024'}, {'g1.50e10.00464', 'g2.19e11.00928'}, {'g4.86e10.00384', 'g2.94e10.00464'}, {'g2.57e11.00304', 'g1.50e10.00208'}, {'g2.54e11.00960', 'g2.63e10.00624'}, {'g7.12e10.00880', 'g3.49e11.00976'}, {'g5.46e11.00656', 'g1.23e10.00224'}, {'g2.64e10.00336', 'g1.47e10.00208'}, {'g8.28e11.00272', 'g2.04e11.00400'}, {'g6.91e10.00880', 'g1.57e10.00320'}, {'g2.80e10.00368', 'g5.05e10.00736'}, {'g2.37e10.00256', 'g5.02e11.00176'}, {'g9.59e10.00128', 'g3.67e09.00464'}, {'g7.12e10.00192', 'g7.66e11.00336'}, {'g1.08e11.00176', 'g2.09e10.00432'}, {'g4.99e10.00080', 'g1.50e10.00112'}, {'g2.80e10.00176', 'g3.49e11.00448'}, {'g6.91e10.00128', 'g2.34e10.00768'}, {'g5.41e09.00624', 'g1.23e10.00544'}, {'g6.91e10.00784', 'g3.55e11.00592'}, {'g1.09e10.00368', 'g2.64e10.00640'}, {'g5.55e11.00336', 'g6.37e10.01008'}, {'g6.96e11.00336', 'g4.90e11.00992'}, {'g1.57e11.01024', 'g4.27e10.00864'}, {'g1.52e11.00912', 'g5.05e10.00688'}, {'g3.67e09.01008', 'g5.59e09.00416'}, {'g5.41e09.00336', 'g1.90e10.00976'}, {'g1.59e11.00528', 'g1.92e10.00640'}, {'g2.94e10.01024', 'g2.83e10.00960'}, {'g2.63e10.00480', 'g5.41e09.01024'}, {'g2.83e10.00880', 'g4.48e10.00656'}, {'g7.12e10.01024', 'g2.80e10.01024'}, {'g5.36e11.00688', 'g2.37e10.01024'}, {'g1.88e10.00720', 'g6.12e10.00656'}, {'g2.64e10.00784', 'g5.46e11.00624'}, {'g5.59e09.00384', 'g6.77e10.00704'}, {'g8.28e11.00528', 'g4.99e10.00272'}, {'g4.27e10.00480', 'g4.86e10.00832'}, {'g1.64e11.00592', 'g1.77e12.00192'}, {'g2.63e10.00336', 'g1.52e11.00224'}, {'g6.37e10.00512', 'g2.94e10.01024'}, {'g2.39e10.00784', 'g8.63e09.00320'}, {'g1.08e11.00208', 'g3.71e11.00288'}, {'g3.44e10.00576', 'g8.06e11.00464'}, {'g5.05e10.00608', 'g9.91e09.00976'}, {'g2.39e11.00880', 'g9.59e10.00816'}, {'g1.59e11.01008', 'g8.13e11.00096'}, {'g8.89e10.00784', 'g6.91e10.00928'}, {'g5.05e10.00608', 'g1.50e10.00704'}, {'g2.64e10.00672', 'g1.23e10.00160'}, {'g3.59e11.00416', 'g3.59e11.00752'}, {'g5.55e11.00320', 'g5.41e09.00864'}, {'g2.04e11.00608', 'g2.09e10.00240'}, {'g1.59e11.00336', 'g1.37e11.00128'}, {'g2.37e10.00608', 'g1.05e11.00256'}, {'g9.59e10.01024', 'g3.19e10.00832'}, {'g6.91e10.00304', 'g3.21e11.00160'}, {'g6.96e10.00944', 'g6.96e11.00096'}, {'g5.55e11.00496', 'g3.54e09.00656'}, {'g2.09e10.00720', 'g2.54e11.00144'}, {'g3.67e10.00320', 'g6.77e10.00832'}, {'g2.42e11.00880', 'g3.71e11.00560'}, {'g4.27e10.00432', 'g2.19e11.00512'}, {'g2.39e10.00976', 'g1.64e11.00624'}, {'g6.91e10.00288', 'g2.41e11.00416'}, {'g4.27e10.00192', 'g1.90e10.00992'}, {'g1.88e10.00336', 'g1.88e10.00992'}, {'g1.59e11.00544', 'g2.09e10.00688'}, {'g6.96e11.00544', 'g4.86e10.00656'}, {'g1.05e11.00560', 'g3.67e09.00736'}, {'g2.41e11.00848', 'g3.71e11.00176'}, {'g3.54e09.00544', 'g6.96e11.00400'}, {'g3.67e10.00912', 'g1.57e10.00944'}, {'g1.37e11.00448', 'g8.06e11.00320'}, {'g3.23e11.00640', 'g1.37e11.00736'}, {'g4.99e09.00960', 'g2.04e11.00192'}, {'g3.54e09.01008', 'g2.37e10.00080'}, {'g2.64e10.00064', 'g1.88e10.00336'}, {'g2.39e10.00528', 'g1.90e10.00752'}, {'g2.63e10.00432', 'g7.05e09.00656'}, {'g2.39e11.00384', 'g2.39e10.00640'}, {'g4.27e10.00960', 'g3.54e09.00368'}, {'g2.83e10.00768', 'g1.37e11.00816'}, {'g6.91e10.00128', 'g7.55e11.00080'}, {'g3.59e11.00864', 'g5.02e11.00144'}, {'g2.09e10.00736', 'g4.48e10.00368'}, {'g7.66e11.00272', 'g3.06e11.00320'}, {'g3.59e11.00352', 'g6.96e10.00304'}, {'g4.86e10.00528', 'g3.54e09.00400'}, {'g5.02e11.00416', 'g2.83e10.00848'}, {'g6.96e10.01024', 'g9.91e09.00880'}, {'g1.17e10.00704', 'g2.41e11.00208'}, {'g1.95e10.00384', 'g8.89e10.00192'}, {'g5.02e11.00160', 'g2.39e10.00736'}, {'g6.31e09.00032', 'g1.18e10.00432'}, {'g3.49e11.00272', 'g1.77e12.00080'}, {'g4.90e11.00800', 'g2.09e10.00400'}, {'g9.91e09.00208', 'g5.38e11.00144'}, {'g2.39e11.00512', 'g6.96e10.00144'}, {'g1.50e10.00864', 'g7.12e10.00672'}, {'g6.96e11.00272', 'g1.05e11.00160'}, {'g5.46e11.00512', 'g1.95e10.00976'}, {'g3.93e10.00512', 'g1.57e11.00800'}, {'g9.59e10.00528', 'g2.19e11.00464'}, {'g6.91e10.00512', 'g7.66e11.00224'}, {'g2.39e11.00976', 'g1.05e11.00336'}, {'g2.37e10.00400', 'g2.41e11.00416'}, {'g2.37e10.00784', 'g1.09e10.00832'}, {'g5.05e10.00784', 'g3.55e11.00992'}, {'g1.59e11.00928', 'g1.23e10.00144'}, {'g4.99e09.00912', 'g1.77e12.00192'}, {'g3.21e11.00960', 'g1.64e11.00128'}, {'g3.59e11.00784', 'g6.96e10.00848'}, {'g8.06e11.00480', 'g1.50e10.00688'}, {'g2.80e10.00864', 'g4.86e10.00400'}, {'g2.83e10.00912', 'g2.54e11.00816'}, {'g4.99e10.00528', 'g1.90e10.00304'}, {'g8.06e11.00464', 'g3.59e11.00384'}, {'g3.21e11.00912', 'g1.95e10.00928'}, {'g2.39e11.00672', 'g1.95e10.00480'}, {'g5.59e09.00368', 'g9.91e09.00288'}, {'g2.09e10.00976', 'g1.77e12.00256'}, {'g3.71e11.00384', 'g6.77e10.00416'}, {'g5.02e11.00112', 'g3.49e11.00592'}, {'g4.90e11.00752', 'g5.36e11.00352'}, {'g9.91e09.00576', 'g1.09e10.00928'}, {'g5.36e11.00704', 'g1.90e10.00128'}, {'g5.05e10.00544', 'g3.55e11.00128'}, {'g3.21e11.00800', 'g1.05e11.00336'}, {'g7.05e09.00624', 'g4.48e10.00512'}, {'g3.44e10.00160', 'g5.59e09.00096'}, {'g1.05e11.01008', 'g1.95e10.00816'}, {'g1.64e11.00464', 'g1.08e11.00720'}, {'g5.59e09.00176', 'g2.04e11.00816'}, {'g3.54e09.00464', 'g4.94e10.01024'}, {'g8.28e11.00592', 'g7.05e09.00784'}, {'g4.90e11.00064', 'g2.34e10.00416'}, {'g3.49e11.00736', 'g4.27e10.00992'}, {'g1.88e10.00144', 'g9.91e09.00320'}, {'g2.04e11.00656', 'g5.55e11.00544'}, {'g1.08e11.00912', 'g7.05e09.00960'}, {'g6.96e11.00224', 'g9.59e10.00656'}, {'g5.05e10.00640', 'g1.89e10.00560'}, {'g8.28e11.00576', 'g2.09e10.00544'}, {'g6.31e09.00048', 'g4.48e10.00384'}, {'g2.94e10.00528', 'g2.19e11.00304'}, {'g1.52e11.00496', 'g2.94e10.01024'}, {'g2.64e10.00448', 'g2.79e12.00096'}, {'g1.23e10.00608', 'g1.23e10.00368'}, {'g4.27e10.00848', 'g7.12e10.00896'}, {'g6.37e10.00896', 'g4.94e10.00448'}, {'g1.47e10.00592', 'g5.36e11.00560'}, {'g4.90e11.00656', 'g3.93e10.00928'}, {'g1.64e11.00720', 'g2.80e10.00928'}, {'g3.59e11.00976', 'g5.59e09.00864'}, {'g3.19e10.00576', 'g8.89e10.00160'}, {'g2.63e10.00464', 'g6.96e11.00400'}, {'g5.59e09.00816', 'g6.91e10.00432'}, {'g1.95e10.00384', 'g1.18e10.00848'}, {'g3.55e11.00752', 'g1.88e10.00112'}, {'g5.36e11.00352', 'g4.94e10.00192'}, {'g4.90e11.00288', 'g8.89e10.00896'}, {'g7.12e10.00880', 'g6.96e10.00368'}, {'g1.64e11.00144', 'g5.41e09.00592'}, {'g6.37e10.00128', 'g2.19e11.00096'}, {'g2.04e11.00288', 'g4.94e10.00768'}, {'g2.04e11.00128', 'g1.89e10.00896'}, {'g4.90e11.00688', 'g1.95e10.00160'}, {'g5.41e09.00112', 'g5.59e09.00400'}, {'g8.13e11.00080', 'g3.67e10.00208'}, {'g3.55e11.00672', 'g1.57e11.00416'}, {'g3.44e10.00464', 'g2.09e10.00736'}, {'g5.41e09.00688', 'g3.23e11.00320'}, {'g1.37e11.00912', 'g3.93e10.00800'}, {'g8.06e11.00352', 'g1.44e10.00992'}, {'g4.94e10.00944', 'g3.54e09.00736'}, {'g3.19e10.00160', 'g5.41e09.00496'}, {'g1.09e10.00784', 'g9.91e09.00480'}, {'g1.47e10.01008', 'g2.37e10.00080'}, {'g1.95e10.00096', 'g8.26e11.00144'}, {'g3.44e10.00256', 'g4.27e10.00816'}, {'g1.09e10.00320', 'g1.05e11.00992'}, {'g9.59e10.00240', 'g2.63e10.00704'}, {'g6.96e11.00384', 'g6.37e10.00736'}, {'g6.37e10.00752', 'g2.41e11.00400'}, {'g2.63e10.00496', 'g2.04e11.00960'}, {'g1.09e10.00624', 'g6.37e10.00576'}, {'g1.17e10.00896', 'g3.23e11.00512'}, {'g6.77e10.00320', 'g3.67e09.00848'}, {'g3.71e11.00592', 'g4.94e10.00416'}, {'g5.59e09.00112', 'g4.99e10.00704'}, {'g4.48e09.00720', 'g1.89e10.01024'}, {'g3.93e10.00320', 'g5.05e10.00064'}, {'g2.09e10.00768', 'g7.05e09.00896'}, {'g1.37e11.00880', 'g1.57e10.00992'}, {'g1.59e11.00400', 'g5.55e11.00416'}, {'g1.23e10.00432', 'g2.39e11.00816'}, {'g5.38e11.00352', 'g1.12e12.00112'}, {'g4.99e10.00480', 'g1.23e10.01008'}, {'g2.64e10.00480', 'g6.77e10.00480'}, {'g1.50e10.00096', 'g3.54e09.00704'}, {'g7.12e10.00336', 'g1.57e11.00144'}, {'g1.95e10.00240', 'g3.44e10.00992'}, {'g6.37e10.00848', 'g4.27e10.00624'}, {'g3.93e10.00256', 'g4.48e10.00544'}, {'g8.28e11.00176', 'g6.91e10.00896'}, {'g5.41e09.00192', 'g2.54e11.00864'}, {'g3.21e11.00080', 'g3.67e09.00848'}, {'g5.41e09.00528', 'g4.27e10.01008'}, {'g4.48e09.00064', 'g7.05e09.00192'}, {'g2.41e11.00528', 'g5.46e11.00144'}, {'g1.52e11.00912', 'g4.48e09.00432'}, {'g5.41e09.00784', 'g6.31e09.00768'}, {'g2.19e11.00720', 'g1.57e10.01024'}, {'g3.71e11.00560', 'g1.92e10.00864'}, {'g5.38e11.00320', 'g1.59e11.00784'}, {'g2.80e10.00160', 'g6.96e10.00432'}, {'g3.67e09.00864', 'g3.59e11.00944'}, {'g5.46e11.00368', 'g2.04e11.00320'}, {'g1.47e10.00976', 'g3.54e09.00928'}, {'g1.47e10.00912', 'g3.55e11.00608'}, {'g2.34e10.00816', 'g4.90e11.00656'}, {'g2.42e11.00912', 'g2.19e11.00064'}, {'g7.44e11.00752', 'g2.39e11.00848'}, {'g8.28e11.00560', 'g3.44e10.00992'}, {'g4.94e10.00208', 'g7.44e11.00464'}, {'g2.80e10.00176', 'g2.34e10.00128'}, {'g8.06e11.00400', 'g6.96e11.00256'}, {'g4.99e09.01008', 'g1.57e11.00224'}, {'g3.67e09.00944', 'g1.88e10.00848'}, {'g2.64e10.00208', 'g3.21e11.01008'}, {'g7.55e11.00304', 'g3.21e11.00976'}, {'g3.55e11.00112', 'g7.05e09.00368'}, {'g2.34e10.00960', 'g2.09e10.00768'}, {'g1.77e12.00304', 'g2.39e10.00928'}, {'g3.19e10.01008', 'g3.49e11.00656'}, {'g2.54e11.00368', 'g2.39e10.00464'}, {'g1.77e12.00080', 'g6.96e11.00240'}, {'g4.48e10.00208', 'g2.80e10.00704'}, {'g3.23e11.00576', 'g4.90e11.00400'}, {'g2.09e10.00112', 'g3.71e11.00512'}, {'g5.05e10.00080', 'g1.18e10.00528'}, {'g3.54e09.00992', 'g3.21e11.00976'}, {'g1.09e10.00432', 'g2.41e11.00400'}, {'g2.19e11.00192', 'g1.17e10.00704'}, {'g6.91e10.00896', 'g2.94e10.00704'}, {'g2.94e10.00640', 'g1.47e10.00688'}, {'g9.59e10.00736', 'g1.95e10.01024'}, {'g1.59e11.00480', 'g1.50e10.00080'}, {'g3.21e11.00336', 'g4.48e09.00272'}, {'g1.90e10.00144', 'g2.37e10.00928'}, {'g1.09e10.00976', 'g8.28e11.00464'}, {'g2.04e11.00624', 'g1.44e10.00736'}, {'g1.18e10.00480', 'g3.93e10.00240'}, {'g8.89e10.00816', 'g3.21e11.00416'}, {'g1.64e11.00352', 'g3.54e09.00992'}, {'g2.41e11.00384', 'g3.67e10.00368'}, {'g2.42e11.00560', 'g1.05e11.00272'}, {'g1.50e10.00880', 'g4.94e10.00544'}, {'g5.41e09.00224', 'g1.47e10.00576'}, {'g3.23e11.00112', 'g3.59e11.00352'}, {'g4.94e10.00480', 'g2.54e11.00464'}, {'g1.88e10.00432', 'g1.77e12.00224'}, {'g6.37e10.00848', 'g2.54e11.00288'}, {'g2.94e10.00688', 'g3.21e11.00272'}, {'g3.55e11.00192', 'g9.91e09.00640'}, {'g2.19e11.00400', 'g4.86e10.00896'}, {'g3.44e10.00160', 'g2.37e10.00288'}, {'g4.27e10.00848', 'g3.55e11.00192'}, {'g1.88e10.00640', 'g2.41e11.00400'}, {'g2.41e11.00496', 'g6.37e10.01008'}, {'g1.90e10.00688', 'g5.41e09.00272'}, {'g1.44e10.00624', 'g2.63e10.00800'}, {'g2.83e10.00880', 'g6.37e10.00448'}, {'g1.08e11.00752', 'g6.96e10.00112'}, {'g5.59e09.00640', 'g2.09e10.00224'}, {'g3.21e11.00736', 'g5.02e11.00128'}, {'g2.83e10.00224', 'g2.37e10.00736'}, {'g1.08e11.00064', 'g1.44e10.00160'}, {'g2.09e10.00528', 'g6.37e10.00528'}, {'g1.90e10.00912', 'g8.28e11.00112'}, {'g3.23e11.00784', 'g2.09e10.00464'}, {'g3.67e10.00240', 'g4.48e10.00112'}, {'g4.90e11.00608', 'g1.90e10.00384'}, {'g4.48e09.00336', 'g6.96e11.00320'}, {'g1.64e11.00592', 'g1.88e10.00176'}, {'g2.42e11.00176', 'g7.12e10.00080'}, {'g2.04e11.00128', 'g2.39e11.00912'}, {'g3.23e11.00208', 'g1.52e11.00592'}, {'g1.88e10.00416', 'g1.95e10.00368'}, {'g6.31e09.00096', 'g8.06e11.00272'}, {'g4.86e10.00176', 'g5.02e11.00256'}, {'g2.83e10.00608', 'g2.39e11.00992'}, {'g2.09e10.00496', 'g7.12e10.00368'}, {'g4.86e10.00592', 'g1.08e11.00704'}, {'g3.71e11.00448', 'g2.64e10.00832'}, {'g5.55e11.00256', 'g7.12e10.00400'}, {'g2.41e11.00656', 'g6.12e10.00544'}, {'g7.05e09.00352', 'g3.67e09.00208'}, {'g3.49e11.00256', 'g7.12e10.00752'}, {'g6.96e11.00320', 'g2.94e10.00160'}, {'g4.99e10.00768', 'g5.55e11.00432'}, {'g4.94e10.00144', 'g1.18e10.00880'}, {'g1.92e10.00400', 'g1.47e10.00800'}, {'g5.05e10.00576', 'g2.54e11.00432'}, {'g6.91e10.00640', 'g9.91e09.00272'}, {'g3.44e10.00736', 'g3.67e10.00624'}, {'g1.09e10.00704', 'g3.59e11.00832'}, {'g1.92e10.00352', 'g3.21e11.00976'}, {'g4.27e10.00272', 'g2.34e10.00144'}, {'g2.19e11.00192', 'g4.48e09.00544'}, {'g8.28e11.00240', 'g3.49e11.00576'}, {'g9.91e09.00432', 'g1.23e10.00432'}, {'g1.05e11.00656', 'g7.44e11.00288'}, {'g1.77e12.00272', 'g1.08e11.00576'}, {'g1.08e11.00672', 'g3.67e09.00608'}, {'g3.21e11.00704', 'g6.91e10.00832'}, {'g2.94e10.00224', 'g7.66e11.00400'}, {'g5.41e09.01024', 'g1.47e10.00064'}, {'g1.89e10.00544', 'g3.19e10.01024'}, {'g6.96e11.00288', 'g3.23e11.00272'}, {'g4.48e10.00832', 'g4.94e10.00656'}, {'g2.63e10.00816', 'g4.86e10.00480'}, {'g4.48e10.00400', 'g5.59e09.00800'}, {'g2.37e10.00176', 'g2.94e10.00432'}, {'g6.37e10.00288', 'g7.12e10.00688'}, {'g4.90e11.00272', 'g3.44e10.00672'}, {'g2.54e11.00864', 'g2.63e10.00224'}, {'g6.91e10.00640', 'g2.63e10.00192'}, {'g6.77e10.00560', 'g1.89e10.00368'}, {'g5.02e11.00368', 'g2.39e10.00416'}, {'g5.59e09.00880', 'g1.17e10.00704'}, {'g1.18e10.00960', 'g2.63e10.00416'}, {'g6.12e10.00912', 'g1.92e10.00752'}, {'g5.31e11.00464', 'g4.48e09.00176'}, {'g5.41e09.00896', 'g1.92e10.00272'}, {'g2.64e10.00448', 'g2.54e11.00592'}, {'g3.59e11.00368', 'g7.05e09.00112'}, {'g1.09e10.00896', 'g7.55e11.00304'}, {'g1.23e10.00576', 'g1.77e12.00096'}, {'g6.77e10.00768', 'g6.96e10.00720'}, {'g1.50e10.01024', 'g1.23e10.00704'}, {'g1.23e10.00752', 'g4.86e10.00240'}, {'g7.12e10.00912', 'g2.42e11.00112'}, {'g3.19e10.00960', 'g1.92e10.00976'}, {'g1.57e11.00048', 'g2.54e11.00720'}, {'g2.04e11.00480', 'g3.21e11.00672'}, {'g5.41e09.00800', 'g1.18e10.00768'}, {'g1.37e11.00928', 'g5.55e11.00352'}, {'g1.88e10.00464', 'g3.21e11.00912'}, {'g1.44e10.00336', 'g1.90e10.00304'}, {'g1.59e11.00880', 'g1.47e10.00336'}, {'g3.67e10.00240', 'g3.59e11.00352'}, {'g5.36e11.00464', 'g1.09e10.00512'}, {'g2.94e10.00176', 'g5.46e11.00192'}, {'g7.08e11.00224', 'g8.28e11.00352'}, {'g3.49e11.00896', 'g4.27e10.00224'}, {'g4.99e10.00752', 'g6.91e10.00320'}, {'g3.49e11.00832', 'g9.59e10.00432'}, {'g3.55e11.00752', 'g1.44e10.00240'}, {'g4.99e10.00496', 'g1.44e10.00400'}, {'g4.90e11.00320', 'g5.46e11.00624'}, {'g6.31e09.00896', 'g1.52e11.00784'}, {'g4.48e10.00112', 'g7.12e10.00816'}, {'g2.42e11.00672', 'g1.47e10.00144'}, {'g2.41e11.00352', 'g1.18e10.00400'}, {'g2.39e11.00800', 'g5.31e11.00448'}, {'g2.94e10.00336', 'g2.63e10.00240'}, {'g9.59e10.00288', 'g2.34e10.00480'}, {'g5.55e11.00528', 'g1.57e11.00816'}, {'g3.49e11.00240', 'g3.67e09.00752'}, {'g2.94e10.00720', 'g4.27e10.00672'}, {'g2.37e10.00768', 'g1.88e10.00192'}, {'g1.92e10.00784', 'g1.88e10.00576'}, {'g1.88e10.01008', 'g4.90e11.00720'}, {'g3.55e11.00912', 'g1.09e10.00256'}, {'g9.59e10.00832', 'g3.93e10.00464'}, {'g7.66e11.00128', 'g1.18e10.00176'}, {'g1.89e10.00640', 'g1.52e11.00480'}, {'g2.19e11.00768', 'g4.48e09.00608'}, {'g7.55e11.00112', 'g1.09e10.00992'}, {'g6.37e10.00624', 'g2.34e10.00544'}, {'g4.48e10.00608', 'g1.23e10.00176'}, {'g3.23e11.00880', 'g1.89e10.00400'}, {'g2.04e11.00176', 'g3.55e11.00944'}, {'g3.44e10.00304', 'g1.90e10.00624'}, {'g9.59e10.00576', 'g5.46e11.00544'}, {'g5.05e10.00640', 'g4.90e11.00336'}, {'g1.18e10.00528', 'g4.99e10.00208'}, {'g3.67e09.00704', 'g1.05e11.00880'}, {'g1.09e10.00528', 'g2.39e10.00352'}, {'g1.18e10.00560', 'g6.31e09.00960'}, {'g1.37e11.00592', 'g1.57e11.00864'}, {'g3.44e10.00944', 'g5.46e11.00656'}, {'g1.05e11.00928', 'g6.12e10.00464'}, {'g1.64e11.00944', 'g2.63e10.00096'}, {'g1.57e10.00816', 'g3.06e11.00352'}, {'g6.91e10.00496', 'g1.18e10.00352'}, {'g1.47e10.00880', 'g2.54e11.00128'}, {'g8.89e10.00064', 'g4.90e11.00496'}, {'g5.59e09.00528', 'g6.96e11.00448'}, {'g4.94e10.00512', 'g1.57e10.00096'}, {'g2.37e10.00704', 'g6.77e10.00480'}, {'g8.28e11.00480', 'g4.27e10.00208'}, {'g1.37e11.00608', 'g1.50e10.00208'}, {'g5.59e09.00256', 'g1.08e11.00096'}, {'g3.19e10.00512', 'g2.42e11.00624'}, {'g7.08e11.00112', 'g1.08e11.00976'}, {'g5.46e11.00736', 'g7.05e09.00592'}, {'g2.09e10.00288', 'g4.48e09.00064'}, {'g2.19e11.00800', 'g1.18e10.00592'}, {'g1.90e10.00560', 'g2.19e11.00912'}, {'g3.19e10.00224', 'g1.23e10.00096'}, {'g9.91e09.00160', 'g6.96e10.00320'}, {'g3.71e11.00240', 'g3.67e09.00208'}, {'g6.31e09.00224', 'g3.59e11.00896'}, {'g2.19e11.00880', 'g4.94e10.00240'}, {'g5.46e11.00800', 'g3.19e10.00704'}, {'g3.67e10.00336', 'g2.42e11.00464'}, {'g6.96e10.00704', 'g5.41e09.00752'}, {'g3.93e10.00192', 'g1.88e10.00608'}, {'g8.89e10.00688', 'g6.77e10.00832'}, {'g3.23e11.00944', 'g1.08e11.00960'}, {'g5.59e09.00624', 'g1.59e11.00688'}, {'g8.06e11.00496', 'g2.57e11.00384'}, {'g4.48e09.00528', 'g1.59e11.00272'}, {'g1.09e10.00240', 'g2.09e10.00400'}, {'g3.19e10.00352', 'g2.19e11.00080'}, {'g7.44e11.00704', 'g3.71e11.00256'}, {'g8.89e10.00864', 'g3.19e10.00240'}, {'g3.67e09.00944', 'g1.90e10.00768'}, {'g7.55e11.00112', 'g2.39e10.01008'}, {'g5.38e11.00240', 'g1.89e10.00432'}, {'g2.42e11.00928', 'g1.59e11.00768'}, {'g1.44e10.00464', 'g1.23e10.00640'}, {'g2.54e11.00560', 'g8.89e10.00992'}, {'g1.57e10.00944', 'g6.77e10.00240'}, {'g4.99e10.00624', 'g1.52e11.00608'}, {'g6.91e10.00224', 'g4.48e10.00624'}, {'g1.09e10.00288', 'g2.54e11.00688'}, {'g3.55e11.00416', 'g4.48e09.00400'}, {'g1.57e10.00656', 'g1.64e11.00176'}, {'g2.39e11.00880', 'g4.27e10.00400'}, {'g6.12e10.00704', 'g2.41e11.00336'}, {'g2.37e10.00192', 'g4.90e11.00944'}, {'g1.95e10.00352', 'g1.59e11.00960'}, {'g3.49e11.00384', 'g1.95e10.00400'}, {'g3.54e09.00080', 'g2.63e10.00480'}, {'g1.37e11.00080', 'g8.06e11.00160'}, {'g8.63e09.00160', 'g3.21e11.01008'}, {'g4.94e10.00096', 'g2.83e10.00464'}, {'g3.93e10.00960', 'g7.12e10.00992'}, {'g1.47e10.00640', 'g3.21e11.00560'}, {'g5.41e09.00192', 'g1.57e11.00064'}, {'g1.92e10.00592', 'g1.64e11.00320'}, {'g2.42e11.00848', 'g6.91e10.00384'}, {'g1.23e10.00576', 'g1.88e10.00688'}, {'g5.41e09.00896', 'g1.47e10.00368'}, {'g1.37e11.00656', 'g6.91e10.00832'}, {'g4.48e09.00704', 'g3.44e10.00352'}, {'g7.44e11.00560', 'g5.05e10.00480'}, {'g3.49e11.00928', 'g3.44e10.00352'}, {'g2.83e10.00848', 'g1.57e10.00752'}, {'g2.19e11.00880', 'g6.91e10.00960'}, {'g2.42e11.00864', 'g3.59e11.00848'}, {'g1.50e10.00608', 'g1.08e11.00592'}, {'g2.39e10.00384', 'g3.19e10.00480'}, {'g1.47e10.00144', 'g9.91e09.00608'}, {'g1.08e11.00768', 'g3.67e09.00368'}, {'g1.05e11.00752', 'g3.23e11.01024'}, {'g2.42e11.00928', 'g1.50e10.00528'}, {'g2.64e10.00096', 'g2.94e10.00992'}, {'g6.91e10.00048', 'g3.23e11.00560'}, {'g5.02e11.00384', 'g2.39e10.00912'}, {'g4.94e10.00544', 'g5.59e09.00848'}, {'g2.09e10.00816', 'g1.88e10.00992'}, {'g2.34e10.00336', 'g4.86e10.00592'}, {'g2.04e11.00640', 'g1.23e10.00624'}, {'g3.59e11.00720', 'g4.90e11.00272'}, {'g3.21e11.00848', 'g1.37e11.00192'}, {'g2.04e11.00192', 'g2.04e11.00656'}, {'g9.59e10.00416', 'g4.48e09.00400'}, {'g2.09e10.00320', 'g5.46e11.00736'}, {'g4.27e10.00224', 'g3.19e10.00688'}, {'g6.91e10.00176', 'g3.49e11.00704'}, {'g5.38e11.00320', 'g1.05e11.00768'}, {'g1.64e11.00304', 'g6.31e09.00064'}, {'g2.64e10.00688', 'g1.23e10.00512'}, {'g5.38e11.00160', 'g1.57e11.00864'}, {'g6.31e09.00224', 'g1.18e10.00304'}, {'g1.05e11.00688', 'g2.64e10.00736'}, {'g5.59e09.00576', 'g7.05e09.00768'}, {'g6.37e10.00656', 'g9.91e09.00864'}, {'g1.77e12.00304', 'g2.54e11.00832'}, {'g5.41e09.00512', 'g2.63e10.00896'}, {'g2.37e10.00320', 'g1.88e10.00064'}, {'g4.27e10.00480', 'g3.55e11.00080'}, {'g6.12e10.00736', 'g1.57e10.00624'}, {'g2.39e11.00800', 'g2.09e10.00784'}, {'g3.93e10.00512', 'g1.88e10.00832'}, {'g1.57e11.00608', 'g3.67e09.01024'}, {'g6.96e10.00416', 'g4.86e10.00864'}, {'g4.48e09.00080', 'g1.44e10.00320'}, {'g2.63e10.01008', 'g2.39e10.00656'}, {'g1.64e11.00176', 'g2.80e10.00336'}, {'g3.59e11.00928', 'g1.50e10.00384'}, {'g3.54e09.00944', 'g3.93e10.00288'}, {'g3.55e11.00368', 'g5.05e10.00512'}, {'g2.63e10.00784', 'g1.95e10.01024'}, {'g4.27e10.00848', 'g3.71e11.00496'}, {'g2.39e10.00096', 'g1.47e10.00304'}, {'g4.90e11.00240', 'g2.54e11.00128'}, {'g4.86e10.00784', 'g7.66e11.00240'}, {'g3.54e09.00656', 'g1.92e10.00608'}, {'g4.27e10.00576', 'g3.67e10.00752'}, {'g2.64e10.00128', 'g4.48e10.00192'}, {'g4.90e11.00144', 'g7.12e10.00160'}, {'g1.57e11.00480', 'g5.36e11.00496'}, {'g1.77e12.00224', 'g7.05e09.00896'}, {'g5.36e11.00544', 'g1.64e11.00160'}, {'g1.05e11.00800', 'g1.57e10.00880'}, {'g3.21e11.00640', 'g1.57e10.00176'}, {'g2.80e10.00672', 'g5.46e11.00128'}, {'g2.04e11.00400', 'g1.57e10.00320'}, {'g4.27e10.00624', 'g5.59e09.00288'}, {'g6.77e10.00256', 'g5.02e11.00128'}, {'g1.57e11.01008', 'g1.95e10.00928'}, {'g6.12e10.00688', 'g5.46e11.00112'}, {'g1.59e11.00816', 'g8.28e11.00288'}, {'g9.59e10.00656', 'g1.90e10.00768'}, {'g5.59e09.00272', 'g2.80e10.00544'}, {'g4.48e10.00608', 'g3.49e11.00528'}, {'g2.83e10.00784', 'g3.54e09.00672'}, {'g1.50e10.00464', 'g7.44e11.00464'}, {'g3.54e09.00288', 'g5.02e11.00064'}, {'g1.92e10.00736', 'g3.21e11.00384'}, {'g5.46e11.00640', 'g6.12e10.01024'}, {'g5.55e11.00240', 'g6.91e10.00064'}, {'g5.05e10.00112', 'g9.91e09.00528'}, {'g2.80e10.00896', 'g5.05e10.00688'}, {'g5.59e09.00192', 'g1.88e10.00576'}, {'g1.37e11.00304', 'g2.63e10.00912'}, {'g7.05e09.00992', 'g3.21e11.00480'}, {'g3.93e10.00080', 'g3.55e11.00288'}, {'g3.44e10.00464', 'g2.19e11.00288'}, {'g6.31e09.00224', 'g8.28e11.00512'}, {'g7.44e11.00384', 'g2.19e11.00832'}, {'g5.05e10.00608', 'g1.92e10.00592'}, {'g1.47e10.00288', 'g1.37e11.00592'}, {'g1.52e11.00192', 'g2.42e11.00480'}, {'g4.48e10.00928', 'g1.64e11.00800'}, {'g1.89e10.00800', 'g6.77e10.00544'}, {'g2.39e10.00944', 'g6.96e10.00896'}, {'g5.46e11.00464', 'g1.05e11.00848'}, {'g6.37e10.00752', 'g3.59e11.00464'}, {'g3.21e11.00144', 'g1.18e10.00336'}, {'g5.41e09.00768', 'g4.99e10.00352'}, {'g3.49e11.00416', 'g6.12e10.00528'}, {'g5.05e10.00736', 'g2.42e11.00064'}, {'g1.90e10.00560', 'g1.77e12.00160'}, {'g3.49e11.00256', 'g2.04e11.00416'}, {'g2.37e10.00592', 'g4.48e10.00336'}, {'g1.44e10.00704', 'g5.55e11.00624'}, {'g5.46e11.00896', 'g4.99e10.00304'}, {'g2.54e11.00368', 'g1.88e10.00240'}, {'g1.95e10.00224', 'g2.83e10.00448'}, {'g3.71e11.00608', 'g9.59e10.00912'}, {'g1.64e11.00880', 'g6.96e11.00416'}, {'g1.57e11.00240', 'g7.12e10.00432'}, {'g7.12e10.00432', 'g6.77e10.00496'}, {'g2.09e10.00512', 'g3.23e11.00768'}, {'g3.71e11.00352', 'g7.05e09.00560'}, {'g2.64e10.00672', 'g4.86e10.00240'}, {'g2.37e10.00080', 'g5.05e10.00960'}, {'g1.89e10.00512', 'g3.19e10.00896'}, {'g3.19e10.00736', 'g3.44e10.00432'}, {'g2.19e11.00736', 'g4.94e10.00176'}, {'g1.52e11.00096', 'g2.79e12.00080'}, {'g9.91e09.00240', 'g5.41e09.00416'}, {'g2.42e11.00640', 'g5.59e09.00528'}, {'g3.55e11.00112', 'g1.90e10.00960'}, {'g9.59e10.00976', 'g8.26e11.00128'}, {'g1.08e11.00240', 'g3.67e10.00320'}, {'g2.39e10.00944', 'g2.94e10.00064'}, {'g1.64e11.00912', 'g3.67e10.00528'}, {'g1.92e10.00976', 'g2.57e11.00208'}, {'g1.44e10.00880', 'g1.59e11.00128'}, {'g7.12e10.01024', 'g5.46e11.00160'}, {'g7.66e11.00224', 'g2.09e10.00272'}, {'g3.67e09.00960', 'g4.27e10.00368'}, {'g5.46e11.01008', 'g5.36e11.00736'}, {'g6.12e10.00896', 'g2.64e10.00192'}, {'g5.41e09.00624', 'g9.59e10.00752'}, {'g2.83e10.00112', 'g3.49e11.00944'}, {'g8.89e10.00432', 'g1.23e10.00560'}, {'g1.23e10.00800', 'g2.39e10.00096'}, {'g5.55e11.00448', 'g1.44e10.00880'}, {'g8.89e10.00064', 'g2.34e10.00768'}, {'g6.77e10.00448', 'g2.57e11.00400'}, {'g3.21e11.00896', 'g1.05e11.00512'}, {'g5.59e09.00256', 'g5.05e10.00528'}, {'g1.37e11.00480', 'g2.41e11.00160'}, {'g4.94e10.00080', 'g2.63e10.00736'}, {'g4.27e10.00192', 'g1.17e10.01024'}, {'g1.95e10.00896', 'g6.31e09.00592'}, {'g1.95e10.00560', 'g5.59e09.00704'}, {'g1.92e10.00560', 'g9.59e10.00160'}, {'g5.41e09.00240', 'g1.50e10.00592'}, {'g5.36e11.00720', 'g6.31e09.00272'}, {'g3.44e10.00240', 'g8.89e10.00704'}, {'g6.77e10.00576', 'g4.48e09.00384'}, {'g2.19e11.00960', 'g2.39e11.00496'}, {'g6.12e10.00608', 'g1.95e10.00112'}, {'g5.55e11.00160', 'g2.94e10.00592'}, {'g6.31e09.00656', 'g1.64e11.00944'}, {'g1.44e10.00640', 'g5.36e11.00272'}, {'g5.55e11.00528', 'g3.59e11.00512'}, {'g2.04e11.00304', 'g3.21e11.00768'}, {'g6.37e10.00880', 'g2.83e10.00928'}, {'g1.44e10.00352', 'g2.09e10.00880'}, {'g8.89e10.00256', 'g2.39e10.00416'}, {'g3.44e10.00464', 'g4.27e10.00352'}, {'g3.44e10.00752', 'g2.34e10.00496'}, {'g5.36e11.00608', 'g1.08e11.00688'}, {'g4.48e09.00832', 'g4.48e10.01008'}, {'g4.99e10.00560', 'g4.94e10.00848'}, {'g1.05e11.00912', 'g1.92e10.01008'}, {'g2.04e11.00608', 'g2.42e11.00496'}, {'g2.04e11.00832', 'g1.88e10.00576'}, {'g2.80e10.00496', 'g3.54e09.00128'}, {'g7.66e11.00416', 'g2.63e10.00416'}, {'g3.44e10.00704', 'g3.21e11.00816'}, {'g4.48e10.00064', 'g2.09e10.00752'}, {'g2.41e11.00880', 'g1.08e11.00240'}, {'g2.39e10.00336', 'g8.06e11.00192'}, {'g1.08e11.00096', 'g1.92e10.00640'}, {'g1.23e10.00224', 'g1.57e10.00176'}, {'g1.89e10.00736', 'g5.46e11.00224'}, {'g2.42e11.00256', 'g2.63e10.00096'}, {'g7.12e10.00384', 'g3.54e09.00400'}, {'g1.88e10.00192', 'g1.18e10.00912'}, {'g5.46e11.00960', 'g7.05e09.00272'}, {'g9.59e10.00528', 'g2.34e10.00368'}, {'g2.19e11.00640', 'g3.21e11.00416'}, {'g1.64e11.00720', 'g1.44e10.00480'}, {'g1.88e10.00208', 'g2.37e10.00672'}, {'g1.08e11.00160', 'g8.06e11.00080'}, {'g2.80e10.00896', 'g3.71e11.00304'}, {'g4.86e10.00176', 'g1.37e11.00064'}, {'g1.59e11.00512', 'g3.54e09.00656'}, {'g3.59e11.01008', 'g9.91e09.00048'}, {'g1.64e11.00672', 'g3.49e11.00240'}, {'g3.55e11.00320', 'g6.96e11.00336'}, {'g1.95e10.00464', 'g1.23e10.00432'}, {'g2.63e10.01024', 'g9.59e10.00640'}, {'g2.39e10.00304', 'g1.57e10.00224'}, {'g8.89e10.00464', 'g3.59e11.00896'}, {'g2.19e11.00576', 'g2.54e11.00192'}, {'g9.59e10.00736', 'g3.19e10.00528'}, {'g4.90e11.00528', 'g5.41e09.00576'}, {'g1.89e10.00848', 'g2.41e11.00368'}, {'g1.37e11.00848', 'g2.09e10.00272'}, {'g3.44e10.00432', 'g2.41e11.00944'}, {'g1.92e10.00848', 'g3.23e11.00928'}, {'g2.94e10.00512', 'g2.54e11.00320'}, {'g9.91e09.00432', 'g1.95e10.00704'}, {'g1.47e10.00688', 'g2.83e10.01008'}, {'g2.80e10.00480', 'g5.55e11.00464'}, {'g2.39e11.00576', 'g2.41e11.00640'}, {'g1.90e10.00784', 'g3.44e10.00368'}, {'g7.05e09.00992', 'g6.96e11.00448'}, {'g2.42e11.00352', 'g1.05e11.00704'}, {'g1.08e11.00432', 'g6.31e09.00352'}, {'g3.21e11.00144', 'g2.34e10.00560'}, {'g2.42e11.00128', 'g2.37e10.00816'}, {'g3.93e10.00528', 'g1.50e10.00272'}, {'g2.63e10.00432', 'g1.47e10.00208'}, {'g3.93e10.00992', 'g6.77e10.00256'}, {'g7.66e11.00288', 'g3.93e10.00704'}, {'g9.59e10.00560', 'g1.57e10.00368'}, {'g2.64e10.00704', 'g1.18e10.00336'}, {'g6.96e11.00160', 'g1.23e10.00544'}, {'g3.59e11.00256', 'g2.54e11.00560'}, {'g6.31e09.00448', 'g1.95e10.00304'}, {'g1.52e11.00416', 'g9.59e10.00864'}, {'g2.41e11.00800', 'g3.59e11.00352'}, {'g4.48e09.00752', 'g4.27e10.00384'}, {'g3.23e11.00976', 'g3.59e11.00656'}, {'g6.91e10.00976', 'g2.34e10.00416'}, {'g2.80e10.01008', 'g4.99e10.00320'}, {'g1.57e10.00848', 'g7.05e09.00864'}, {'g1.44e10.00416', 'g9.91e09.00608'}, {'g3.44e10.00944', 'g7.05e09.00384'}, {'g7.12e10.00864', 'g2.09e10.00720'}, {'g1.57e10.00048', 'g1.88e10.00080'}, {'g5.46e11.00352', 'g3.19e10.00672'}, {'g1.92e12.00080', 'g6.37e10.00576'}, {'g1.90e10.00896', 'g2.34e10.00336'}, {'g5.36e11.00720', 'g7.05e09.00464'}, {'g4.48e10.00208', 'g2.64e10.00464'}, {'g5.41e09.01008', 'g1.52e11.00544'}, {'g6.12e10.00464', 'g7.12e10.00320'}, {'g1.23e10.00736', 'g2.42e11.00224'}, {'g1.18e10.00256', 'g3.67e10.00640'}, {'g5.38e11.00208', 'g2.83e10.01008'}, {'g2.63e10.00640', 'g1.18e10.00992'}, {'g3.44e10.00400', 'g2.39e10.00928'}, {'g3.06e11.00304', 'g7.12e10.00288'}, {'g5.46e11.00304', 'g8.89e10.00976'}, {'g3.21e11.00288', 'g2.41e11.00544'}, {'g1.59e11.00896', 'g7.66e11.00400'}, {'g1.44e10.00656', 'g2.41e11.01024'}, {'g5.05e10.00512', 'g7.44e11.00544'}, {'g3.67e10.00400', 'g8.26e11.00128'}, {'g2.42e11.00624', 'g1.23e10.00176'}, {'g4.86e10.00304', 'g1.88e10.00080'}, {'g2.63e10.00688', 'g2.19e11.00096'}, {'g4.48e10.00320', 'g8.28e11.00416'}, {'g6.91e10.00048', 'g2.34e10.00128'}, {'g4.48e10.00704', 'g3.06e11.00832'}, {'g6.37e10.00352', 'g1.09e10.00288'}, {'g1.57e10.00672', 'g5.36e11.00192'}, {'g3.19e10.00256', 'g8.89e10.00752'}, {'g3.23e11.00624', 'g5.05e10.00112'}, {'g1.09e10.00576', 'g6.77e10.00752'}, {'g1.88e10.01008', 'g6.91e10.00064'}, {'g3.55e11.00576', 'g3.49e11.00160'}, {'g6.91e10.00336', 'g3.23e11.00480'}, {'g1.57e10.00336', 'g4.27e10.00576'}, {'g1.44e10.00368', 'g4.90e11.00432'}, {'g4.48e09.00512', 'g5.41e09.00640'}, {'g2.34e10.00864', 'g2.37e10.00400'}, {'g1.50e10.00928', 'g4.90e11.00960'}, {'g2.54e11.00976', 'g3.23e11.00752'}, {'g1.59e11.00256', 'g1.12e12.00048'}, {'g4.86e10.00208', 'g3.54e09.00608'}, {'g1.50e10.00752', 'g4.48e09.00976'}, {'g5.36e11.00800', 'g2.37e10.00560'}, {'g2.63e10.00320', 'g3.44e10.00304'}, {'g1.05e11.00464', 'g3.59e11.01024'}, {'g2.39e11.00688', 'g6.37e10.00384'}, {'g6.37e10.00768', 'g4.90e11.00112'}, {'g5.36e11.00736', 'g7.66e11.00192'}, {'g3.59e11.00720', 'g1.59e11.00512'}, {'g3.44e10.00160', 'g8.89e10.00080'}, {'g5.02e11.00096', 'g2.19e11.00304'}, {'g1.57e11.00656', 'g1.47e10.00272'}, {'g3.49e11.00832', 'g3.71e11.00096'}, {'g6.31e09.00400', 'g8.28e11.00480'}, {'g1.90e10.00528', 'g9.59e10.00816'}, {'g3.44e10.00960', 'g3.55e11.00816'}, {'g3.59e11.00752', 'g6.96e10.00576'}, {'g6.37e10.00400', 'g2.34e10.00400'}, {'g2.80e10.00864', 'g2.19e11.00784'}, {'g6.77e10.00320', 'g4.86e10.00512'}, {'g1.44e10.00160', 'g6.96e11.00528'}, {'g6.96e11.00480', 'g4.48e09.00560'}, {'g6.91e10.01008', 'g1.92e10.00992'}, {'g4.86e10.00240', 'g5.46e11.00432'}, {'g1.52e11.00800', 'g2.09e10.00800'}, {'g1.05e11.00224', 'g3.49e11.00704'}, {'g8.89e10.00288', 'g8.28e11.00256'}, {'g7.44e11.00560', 'g1.47e10.00320'}, {'g1.50e10.00128', 'g3.67e10.00544'}, {'g1.08e11.00368', 'g1.89e10.00368'}, {'g1.64e11.00272', 'g9.59e10.00496'}, {'g1.57e10.00240', 'g4.99e10.00064'}, {'g2.64e10.00304', 'g6.12e10.00576'}, {'g1.57e10.00272', 'g3.67e09.00816'}, {'g3.23e11.01024', 'g3.93e10.00544'}, {'g1.57e10.00336', 'g1.47e10.00208'}, {'g2.64e10.00992', 'g3.55e11.00864'}, {'g1.59e11.00256', 'g6.12e10.00688'}, {'g1.90e10.00896', 'g2.34e10.00768'}, {'g4.99e10.00768', 'g1.57e10.00976'}, {'g3.21e11.00880', 'g4.94e10.00928'}, {'g9.59e10.00240', 'g1.90e10.00752'}, {'g3.44e10.00272', 'g1.92e10.00224'}, {'g3.55e11.00240', 'g3.23e11.00944'}, {'g2.09e10.00320', 'g1.92e10.00736'}, {'g1.88e10.00704', 'g1.95e10.00832'}, {'g1.88e10.00672', 'g2.34e10.00432'}, {'g2.83e10.00208', 'g9.59e10.00432'}, {'g6.96e11.00224', 'g6.12e10.00464'}, {'g5.05e10.00960', 'g9.59e10.00272'}, {'g7.12e10.00800', 'g2.42e11.00768'}, {'g3.19e10.00224', 'g2.39e10.00800'}, {'g2.37e10.00704', 'g2.19e11.00432'}, {'g1.89e10.00816', 'g3.71e11.00576'}, {'g2.04e11.00992', 'g3.54e09.00512'}, {'g2.41e11.01024', 'g3.19e10.00848'}, {'g4.48e10.00080', 'g2.09e10.00160'}, {'g1.57e11.00352', 'g2.80e10.00448'}, {'g1.37e11.00864', 'g7.44e11.00544'}, {'g5.59e09.00800', 'g3.93e10.00544'}, {'g8.89e10.00880', 'g1.57e11.00256'}, {'g5.46e11.00096', 'g1.95e10.00960'}, {'g3.06e11.00800', 'g4.90e11.00720'}, {'g2.64e10.00144', 'g5.38e11.00176'}, {'g6.96e10.00464', 'g2.04e11.00496'}, {'g1.64e11.00336', 'g2.41e11.00096'}, {'g3.55e11.00640', 'g3.59e11.00384'}, {'g3.71e11.00368', 'g6.37e10.00448'}, {'g3.44e10.00272', 'g4.94e10.00480'}, {'g3.67e10.00720', 'g6.31e09.00832'}, {'g3.23e11.00496', 'g2.39e10.00400'}, {'g1.64e11.00880', 'g2.64e10.00240'}, {'g1.37e11.00688', 'g1.89e10.00576'}, {'g6.77e10.00752', 'g9.59e10.00160'}, {'g4.94e10.00960', 'g2.63e10.00240'}, {'g1.47e10.00416', 'g4.48e09.00864'}, {'g2.39e11.00704', 'g2.37e10.00208'}, {'g2.19e11.00960', 'g7.55e11.00080'}, {'g5.38e11.00320', 'g4.86e10.00208'}, {'g8.63e09.00176', 'g1.47e10.00576'}, {'g1.95e10.00944', 'g2.80e10.00960'}, {'g2.63e10.00336', 'g4.48e10.00944'}, {'g4.48e09.00144', 'g8.28e11.00176'}, {'g1.57e11.00720', 'g3.21e11.00400'}, {'g5.02e11.00160', 'g1.17e10.00384'}, {'g5.31e11.00480', 'g8.28e11.00448'}, {'g1.92e10.00944', 'g9.59e10.00624'}, {'g2.94e10.00384', 'g4.94e10.00752'}, {'g1.57e10.00672', 'g2.63e10.00384'}, {'g2.41e11.00272', 'g4.48e10.00688'}, {'g2.54e11.00752', 'g1.47e10.00480'}, {'g9.59e10.00928', 'g2.83e10.00112'}, {'g4.94e10.00528', 'g3.21e11.00720'}, {'g2.54e11.00992', 'g2.04e11.00928'}, {'g3.93e10.00752', 'g2.54e11.00240'}, {'g3.21e11.00576', 'g2.19e11.01024'}, {'g2.39e10.00688', 'g2.42e11.00112'}, {'g6.37e10.00352', 'g2.54e11.00848'}, {'g4.94e10.00256', 'g3.21e11.00192'}, {'g2.41e11.00144', 'g2.37e10.00688'}, {'g1.18e10.00752', 'g1.23e10.00128'}, {'g3.55e11.00608', 'g4.86e10.00288'}, {'g2.19e11.00976', 'g5.02e11.00320'}, {'g6.37e10.00416', 'g4.99e10.00416'}, {'g1.57e11.00304', 'g6.96e11.00560'}, {'g1.47e10.00864', 'g6.37e10.00096'}, {'g5.02e11.00304', 'g1.88e10.00816'}, {'g1.08e11.01024', 'g3.55e11.00688'}, {'g1.23e10.00320', 'g1.44e10.00480'}, {'g2.04e11.00448', 'g2.94e10.00736'}, {'g5.31e11.00480', 'g1.95e10.00448'}, {'g2.09e10.00496', 'g5.55e11.00208'}, {'g1.23e10.00144', 'g1.12e12.00176'}, {'g6.91e10.00288', 'g8.89e10.00768'}, {'g1.23e10.00736', 'g8.28e11.00144'}, {'g6.91e10.00336', 'g1.47e10.00320'}, {'g6.96e10.00800', 'g8.13e11.00096'}, {'g2.19e11.00688', 'g1.57e11.00560'}, {'g1.09e10.00240', 'g3.71e11.00560'}, {'g7.12e10.00576', 'g2.34e10.00944'}, {'g3.59e11.00592', 'g1.57e10.00608'}, {'g1.95e10.00144', 'g8.89e10.00560'}, {'g2.04e11.00800', 'g1.17e10.00192'}, {'g1.09e10.01008', 'g9.91e09.00656'}, {'g1.05e11.00256', 'g1.09e10.00656'}, {'g1.57e11.00496', 'g8.06e11.00256'}, {'g3.49e11.00368', 'g6.96e11.00080'}, {'g2.37e10.00480', 'g1.37e11.00832'}, {'g1.44e10.00992', 'g9.91e09.01008'}, {'g6.77e10.00432', 'g5.05e10.01008'}, {'g2.83e10.00896', 'g9.59e10.00544'}, {'g1.23e10.00464', 'g4.48e09.00512'}, {'g3.59e11.00688', 'g6.96e10.00240'}, {'g6.96e10.00832', 'g1.05e11.00448'}, {'g5.41e09.00352', 'g4.99e10.00112'}, {'g4.99e10.00544', 'g3.23e11.00512'}, {'g3.55e11.00112', 'g5.46e11.00656'}, {'g2.41e11.00800', 'g1.08e11.00800'}, {'g8.06e11.00320', 'g2.39e10.00080'}, {'g2.64e10.00528', 'g1.57e11.00816'}, {'g3.21e11.00928', 'g1.88e10.00224'}, {'g7.08e11.00240', 'g3.23e11.00176'}, {'g2.42e11.00832', 'g4.94e10.00096'}, {'g3.44e10.00672', 'g6.77e10.00864'}, {'g1.44e10.00512', 'g7.12e10.00832'}, {'g9.91e09.00528', 'g1.23e10.00496'}, {'g1.23e10.00688', 'g3.49e11.00704'}, {'g7.12e10.00704', 'g4.86e10.00848'}, {'g1.50e10.00960', 'g2.54e11.00960'}, {'g3.49e11.00880', 'g1.44e10.00176'}, {'g6.77e10.00144', 'g8.89e10.00352'}, {'g3.54e09.00624', 'g1.18e10.00320'}, {'g2.94e10.00816', 'g2.34e10.00384'}, {'g2.04e11.00688', 'g4.86e10.00384'}, {'g6.12e10.00448', 'g2.64e10.00512'}, {'g7.05e09.00704', 'g3.44e10.00800'}, {'g7.05e09.00480', 'g3.49e11.00464'}, {'g8.06e11.00240', 'g3.67e09.00752'}, {'g5.46e11.00832', 'g3.19e10.00800'}, {'g3.93e10.00688', 'g6.37e10.00336'}, {'g2.80e10.01008', 'g4.90e11.00208'}, {'g2.57e11.00224', 'g6.96e10.00688'}, {'g3.19e10.00768', 'g4.90e11.00624'}, {'g2.34e10.00560', 'g2.39e11.00576'}, {'g1.08e11.00768', 'g3.54e09.00176'}, {'g1.77e12.00080', 'g1.59e11.00720'}, {'g3.54e09.00912', 'g2.83e10.00688'}, {'g5.46e11.00208', 'g1.44e10.00720'}, {'g2.09e10.00800', 'g2.80e10.00720'}, {'g1.44e10.00272', 'g7.55e11.00272'}, {'g2.63e10.00832', 'g3.71e11.00096'}, {'g2.64e10.00128', 'g2.39e10.00288'}, {'g6.37e10.00144', 'g1.09e10.00352'}, {'g6.37e10.00096', 'g1.95e10.00912'}, {'g5.46e11.00560', 'g2.34e10.00336'}, {'g3.67e10.00624', 'g1.50e10.00672'}, {'g1.57e10.00848', 'g6.96e10.00560'}, {'g4.86e10.00096', 'g4.94e10.00880'}, {'g1.64e11.01024', 'g1.57e11.00752'}, {'g1.95e10.00496', 'g1.59e11.00240'}, {'g2.19e11.00640', 'g1.44e10.00800'}, {'g1.57e11.00960', 'g6.37e10.00320'}, {'g2.37e10.00576', 'g1.50e10.00288'}, {'g1.09e10.00304', 'g4.48e09.00688'}, {'g3.54e09.00592', 'g9.91e09.00560'}, {'g2.42e11.00688', 'g3.21e11.00928'}, {'g2.37e10.00560', 'g6.96e10.00864'}, {'g7.44e11.00208', 'g1.88e10.00576'}, {'g1.52e11.00336', 'g1.95e10.00912'}, {'g5.41e09.00128', 'g1.88e10.00672'}, {'g1.44e10.00336', 'g4.86e10.00912'}, {'g6.37e10.00496', 'g2.83e10.00320'}, {'g7.44e11.00576', 'g3.19e10.00784'}, {'g8.06e11.00096', 'g1.57e11.00512'}, {'g5.55e11.00080', 'g3.23e11.00800'}, {'g3.21e11.00800', 'g4.27e10.00416'}, {'g2.54e11.01024', 'g9.59e10.00288'}, {'g3.49e11.00576', 'g1.57e11.00368'}, {'g5.02e11.00416', 'g4.86e10.00528'}, {'g1.64e11.00864', 'g1.09e10.00736'}, {'g2.04e11.00464', 'g2.34e10.00960'}, {'g2.39e11.00976', 'g2.54e11.00560'}, {'g4.99e10.00400', 'g3.71e11.00224'}, {'g3.59e11.00832', 'g1.64e11.00240'}, {'g5.41e09.00512', 'g4.27e10.00368'}, {'g6.77e10.00944', 'g6.31e09.00400'}, {'g5.05e10.00160', 'g4.99e10.00944'}, {'g8.28e11.00128', 'g7.12e10.00864'}, {'g2.41e11.00816', 'g3.23e11.00512'}, {'g1.50e10.00544', 'g4.90e11.00592'}, {'g1.18e10.01008', 'g1.52e11.00784'}, {'g3.44e10.00400', 'g6.91e10.00160'}, {'g2.04e11.00832', 'g3.59e11.00816'}, {'g1.64e11.00880', 'g3.21e11.00752'}, {'g3.54e09.01008', 'g9.91e09.00176'}, {'g1.57e10.00960', 'g1.57e10.00512'}, {'g1.23e10.00272', 'g7.12e10.00304'}, {'g2.54e11.00112', 'g1.37e11.00416'}, {'g7.05e09.00640', 'g1.05e11.00416'}, {'g6.91e10.00448', 'g2.04e11.00240'}, {'g9.59e10.00144', 'g3.67e09.00848'}, {'g7.05e09.00640', 'g3.23e11.00528'}, {'g3.67e09.00928', 'g7.05e09.00720'}, {'g4.94e10.00800', 'g2.04e11.00576'}, {'g1.44e10.00928', 'g6.31e09.00128'}, {'g3.23e11.00656', 'g8.89e10.00416'}, {'g9.91e09.00096', 'g5.59e09.00224'}, {'g2.37e10.00848', 'g3.19e10.00800'}, {'g2.04e11.00720', 'g6.96e10.00240'})\n",
      "finish prepare the data\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import yaml\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from ili.dataloaders import StaticNumpyLoader\n",
    "from ili.inference import InferenceRunner\n",
    "from ili.validation import ValidationRunner\n",
    "\n",
    "from CASBI.utils.create_dataframe import rescale\n",
    "\n",
    "\n",
    "\n",
    "N_subhalos = 2\n",
    "data = pd.read_parquet('../../../../data/dataframe/dataframe.parquet')\n",
    "data = rescale(data, mean_and_std_path='../../../../data/preprocess/mean_and_std.parquet', scale_observations=True, scale_parameter=True, inverse=True) \n",
    "data =  data.drop(['gas_log10mass', 'a','redshift', 'mean_metallicity', 'std_metallicity','mean_FeMassFrac', 'std_FeMassFrac', 'mean_OMassFrac', 'std_OMassFrac'], axis=1)\n",
    "min_feh, max_feh = min(data['feh']), max(data['feh'])\n",
    "min_ofe, max_ofe = min(data['ofe']), max(data['ofe'])\n",
    "conditions = data[data.columns.difference(['feh', 'ofe', 'Galaxy_name'], sort=False)].drop_duplicates()\n",
    "\n",
    "minimum_theta = [conditions[col].values.min() for col in conditions.columns]   \n",
    "maximum_theta = [conditions[col].values.max() for col in conditions.columns]       \n",
    "minimum_theta = np.array(minimum_theta)\n",
    "maximum_theta = np.array(maximum_theta)\n",
    "def repeat_array(arr, repetitions):\n",
    "    return np.repeat(arr, repetitions)\n",
    "repeat_minimum_theta = repeat_array(minimum_theta, N_subhalos)\n",
    "repeat_maximum_theta = repeat_array(maximum_theta, N_subhalos) \n",
    "\n",
    "def write_to_yaml(repeat_minimum_theta, repeat_maximum_theta):\n",
    "    # Load the existing data\n",
    "    with open('./training.yaml', 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "\n",
    "    repeat_minimum_theta = repeat_minimum_theta.tolist()\n",
    "    repeat_maximum_theta = repeat_maximum_theta.tolist()\n",
    "    # Update the value\n",
    "    data['prior']['args']['low'] = repeat_minimum_theta\n",
    "    data['prior']['args']['high'] = repeat_maximum_theta\n",
    "\n",
    "    # Write the data back to the file\n",
    "    with open('./training.yaml', 'w') as file:\n",
    "        yaml.safe_dump(data, file)\n",
    "        \n",
    "write_to_yaml(repeat_minimum_theta, repeat_maximum_theta)\n",
    "print('write the right prior in the training.yaml file')\n",
    "\n",
    "N_test = 1_000\n",
    "def preprocess_testset(i):\n",
    "    galaxies = set(data['Galaxy_name'].drop_duplicates().sample(N_subhalos, random_state=i))\n",
    "    parameters =  data[data['Galaxy_name'].isin(galaxies)].drop(['feh', 'ofe', 'Galaxy_name'], axis=1).drop_duplicates().values.T.reshape(-1)\n",
    "    galaxy_data = data[data['Galaxy_name'].isin(galaxies)].values\n",
    "    histogram_galaxy, _, _ = np.histogram2d(galaxy_data[:, 0], galaxy_data[:, 1], bins=64, range=[[min_feh, max_feh], [min_ofe, max_ofe]])\n",
    "    sim_data =  np.expand_dims(np.log10(histogram_galaxy + 1e-6 +1), axis=0)\n",
    "    return parameters, sim_data, galaxies\n",
    "\n",
    "# Create a pool of workers\n",
    "with Pool() as pool:\n",
    "    # Map the function to the data\n",
    "    results = pool.map(preprocess_testset, range(N_test))\n",
    "    \n",
    "# Unpack the results\n",
    "theta_test, x_test, galaxies_test = zip(*results)\n",
    "\n",
    "#take the first test set element as x_0 and theta_0    \n",
    "galaxies_0 = galaxies_test[0]\n",
    "data_to_plot_halos = data[data['Galaxy_name'].isin(galaxies_0)].to_parquet('./halos_0.parquet')\n",
    "theta_0 =  theta_test[0]\n",
    "x_0 =  x_test[0]\n",
    "\n",
    "N = 10_000\n",
    "def process_sample(i):\n",
    "    galaxies = data['Galaxy_name'].drop_duplicates().sample(N_subhalos, random_state=i+int(time.time()))\n",
    "    while (any(set(galaxies) == galaxy_in_testset for galaxy_in_testset in galaxies_test)):\n",
    "        print('matched galaxies, try again')\n",
    "        print('galaxies', set(galaxies))\n",
    "        print('test galaxies', galaxies_test)\n",
    "        galaxies = data['Galaxy_name'].drop_duplicates().sample(N_subhalos, random_state=i)\n",
    "    parameters =  data[data['Galaxy_name'].isin(galaxies)].drop(['feh', 'ofe', 'Galaxy_name'], axis=1).drop_duplicates().values.T.reshape(-1)\n",
    "    galaxy_data = data[data['Galaxy_name'].isin(galaxies)].values\n",
    "    histogram_galaxy, _, _ = np.histogram2d(galaxy_data[:, 0], galaxy_data[:, 1], bins=64, range=[[min_feh, max_feh], [min_ofe, max_ofe]])\n",
    "    sim_data =  np.expand_dims(np.log10(histogram_galaxy + 1e-6 +1), axis=0)\n",
    "    return parameters, sim_data\n",
    "\n",
    "# Create a pool of workers\n",
    "with Pool() as pool:\n",
    "    # Map the function to the data\n",
    "    results = pool.map(process_sample, range(N))\n",
    "\n",
    "# Unpack the results\n",
    "theta, x = zip(*results)\n",
    "\n",
    "#save in .npy files, we remove the first element of the test set since it will be stored as x_0 and theta_0\n",
    "np.save('./x_test.npy', x_test[1:])\n",
    "np.save('./theta_test.npy', theta_test[1:])\n",
    "np.save('./x_0.npy', x_0)\n",
    "np.save('./theta_0.npy', theta_0)\n",
    "np.save('./x.npy', x)\n",
    "np.save('./theta.npy', theta)\n",
    "print('finish prepare the data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest values for the hyperparameters\n",
    "    model = trial.suggest_categorical('model', ['maf', 'nsf'])\n",
    "    hidden_features = trial.suggest_categorical('hidden_features', [10, 50, 70, 100])\n",
    "    num_transforms = trial.suggest_categorical('num_transforms', [5, 10, 15, 20, 30])\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [1e-5, 5e-5, 1e-4]) #suggest_loguniform('learning_rate', 1e-5, 1e-4)\n",
    "    output_dim = trial.suggest_categorical('output_dim', [5, 10, 32, 64])\n",
    "\n",
    "    # Load the existing hyperparameters from training.yaml\n",
    "    with open('training.yaml', 'r') as f:\n",
    "        hyperparameters = yaml.safe_load(f)\n",
    "\n",
    "    # Update the hyperparameters with the suggested values\n",
    "    for net in hyperparameters['model']['nets']:\n",
    "        net['hidden_features'] = hidden_features\n",
    "        net['num_transforms'] = num_transforms\n",
    "        net['model'] = model\n",
    "    hyperparameters['embedding_net']['args']['output_dim'] = output_dim\n",
    "    hyperparameters['train_args']['learning_rate'] = learning_rate\n",
    "\n",
    "    # Save the updated hyperparameters back to training.yaml\n",
    "    with open('training.yaml', 'w') as f:\n",
    "        yaml.dump(hyperparameters, f)\n",
    "        \n",
    "    # reload all simulator examples as a dataloader\n",
    "    all_loader = StaticNumpyLoader.from_config(\"./data.yaml\")\n",
    "\n",
    "    # train a model to infer x -> theta. save it as toy/posterior.pkl\n",
    "    # runner = InferenceRunner.from_config(f\"./training.yaml\")\n",
    "    # _, summaries = runner(loader=all_loader)\n",
    "\n",
    "    \n",
    "    \n",
    "    return summaries[0]['validation_log_probs'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-29 14:05:59,148] A new study created in memory with name: no-name-e3d2b790-bb03-451f-a69a-a794856bb7f7\n",
      "[W 2024-05-29 14:05:59,185] Trial 4 failed with parameters: {'model': 'nsf', 'hidden_features': 70, 'num_transforms': 15, 'learning_rate': 0.0001, 'output_dim': 10} because of the following error: TypeError(\"'NoneType' object is not subscriptable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/vgiusepp/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3161542/222344881.py\", line 14, in objective\n",
      "    for net in hyperparameters['model']['nets']:\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "[W 2024-05-29 14:05:59,186] Trial 2 failed with parameters: {'model': 'nsf', 'hidden_features': 100, 'num_transforms': 10, 'learning_rate': 5e-05, 'output_dim': 32} because of the following error: TypeError(\"'NoneType' object is not subscriptable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/vgiusepp/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3161542/222344881.py\", line 14, in objective\n",
      "    for net in hyperparameters['model']['nets']:\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "[W 2024-05-29 14:05:59,201] Trial 4 failed with value None.\n",
      "[W 2024-05-29 14:05:59,212] Trial 2 failed with value None.\n",
      "[W 2024-05-29 14:05:59,270] Trial 9 failed with parameters: {'model': 'maf', 'hidden_features': 70, 'num_transforms': 20, 'learning_rate': 0.0001, 'output_dim': 32} because of the following error: TypeError(\"'NoneType' object is not subscriptable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/vgiusepp/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3161542/222344881.py\", line 14, in objective\n",
      "    for net in hyperparameters['model']['nets']:\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "[W 2024-05-29 14:05:59,280] Trial 9 failed with value None.\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "INFO:root:Training model 1 / 1.\n",
      "INFO:root:Training model 1 / 1.\n",
      "INFO:root:Training model 1 / 1.\n",
      "INFO:root:Training model 1 / 1.\n",
      "INFO:root:Training model 1 / 1.\n",
      "INFO:root:Training model 1 / 1.\n",
      "INFO:root:Training model 1 / 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py:99\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m completed:\n\u001b[0;32m---> 99\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m futures\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    102\u001b[0m     executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    103\u001b[0m         _optimize_sequential,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    115\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Update the hyperparameters with the suggested values\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m net \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnets\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     15\u001b[0m     net[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m hidden_features\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m  optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py:81\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     78\u001b[0m time_start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     79\u001b[0m futures: \u001b[38;5;28mset\u001b[39m[Future] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mn_jobs) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n_submitted_trials \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcount():\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_stop_flag:\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study =  optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial, device):\n",
    "#     # Suggest values for the hyperparameters\n",
    "#     model = trial.suggest_categorical('model', ['maf', 'nsf'])\n",
    "#     hidden_features = trial.suggest_categorical('hidden_features', [10, 50, 70, 100])\n",
    "#     num_transforms = trial.suggest_categorical('num_transforms', [5, 10, 15, 20, 30])\n",
    "#     learning_rate = trial.suggest_categorical('learning_rate', [1e-5, 5e-5, 1e-4]) #suggest_loguniform('learning_rate', 1e-5, 1e-4)\n",
    "#     output_dim = trial.suggest_categorical('output_dim', [5, 10, 32, 64])\n",
    "\n",
    "#     # Load the existing hyperparameters from training.yaml\n",
    "#     with open('training.yaml', 'r') as f:\n",
    "#         hyperparameters = yaml.safe_load(f)\n",
    "\n",
    "#     # Update the hyperparameters with the suggested values\n",
    "#     for net in hyperparameters['model']['nets']:\n",
    "#         net['hidden_features'] = hidden_features\n",
    "#         net['num_transforms'] = num_transforms\n",
    "#         net['model'] = model\n",
    "#     hyperparameters['embedding_net']['args']['output_dim'] = output_dim\n",
    "#     hyperparameters['train_args']['learning_rate'] = learning_rate\n",
    "#     hyperparameters['device'] = device\n",
    "\n",
    "#     # Save the updated hyperparameters back to training.yaml\n",
    "#     with open('training.yaml', 'w') as f:\n",
    "#         yaml.dump(hyperparameters, f)\n",
    "        \n",
    "#     # reload all simulator examples as a dataloader\n",
    "#     all_loader = StaticNumpyLoader.from_config(\"./data.yaml\")\n",
    "\n",
    "#     # train a model to infer x -> theta. save it as toy/posterior.pkl\n",
    "#     runner = InferenceRunner.from_config(f\"./training.yaml\")\n",
    "#     _, summaries = runner(loader=all_loader)\n",
    "\n",
    "#     return summaries[0]['validation_log_probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-29 10:41:09,367] A new study created in RDB with name: example_study\n"
     ]
    }
   ],
   "source": [
    "# study_name = 'example_study'  # Unique identifier of the study.\n",
    "# storage_name = 'sqlite:///example.db'\n",
    "# study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n",
      "INFO:root:Training model 1 / 1.\n",
      "INFO:root:Training model 1 / 1.\n",
      "INFO:root:Training model 1 / 1.\n",
      "INFO:root:Training model 1 / 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " raining neural network. Epochs trained: 221raining neural network. Epochs trained: 1Training neural network. Epochs trained: 1Training neural network. Epochs trained: 1Training neural network. Epochs trained: 2Training neural network. Epochs trained: 2Training neural network. Epochs trained: 2Training neural network. Epochs trained: 2Training neural network. Epochs trained: 3Training neural network. Epochs trained: 3Training neural network. Epochs trained: 3Training neural network. Epochs trained: 3Training neural network. Epochs trained: 4Training neural network. Epochs trained: 4Training neural network. Epochs trained: 4Training neural network. Epochs trained: 4Training neural network. Epochs trained: 5  Training neural network. Epochs trained: 5Training neural network. Epochs trained: 5Training neural network. Epochs trained: 5Training neural network. Epochs trained: 6Training neural network. Epochs trained: 6Training neural network. Epochs trained: 6Training neural network. Epochs trained: 6Training neural network. Epochs trained: 7Training neural network. Epochs trained: 7Training neural network. Epochs trained: 7Training neural network. Epochs trained: 7Training neural network. Epochs trained: 8Training neural network. Epochs trained: 8Training neural network. Epochs trained: 8Training neural network. Epochs trained: 8Training neural network. Epochs trained: 9Training neural network. Epochs trained: 9Training neural network. Epochs trained: 9Training neural network. Epochs trained: 9Training neural network. Epochs trained: 10Training neural network. Epochs trained: 10Training neural network. Epochs trained: 10Training neural network. Epochs trained: 10Training neural network. Epochs trained: 11Training neural network. Epochs trained: 11Training neural network. Epochs trained: 11Training neural network. Epochs trained: 11Training neural network. Epochs trained: 12Training neural network. Epochs trained: 12Training neural network. Epochs trained: 12Training neural network. Epochs trained: 12Training neural network. Epochs trained: 13Training neural network. Epochs trained: 13Training neural network. Epochs trained: 13Training neural network. Epochs trained: 13Training neural network. Epochs trained: 14Training neural network. Epochs trained: 14Training neural network. Epochs trained: 14Training neural network. Epochs trained: 14Training neural network. Epochs trained: 15Training neural network. Epochs trained: 15Training neural network. Epochs trained: 15Training neural network. Epochs trained: 15Training neural network. Epochs trained: 16Training neural network. Epochs trained: 16Training neural network. Epochs trained: 16Training neural network. Epochs trained: 16Training neural network. Epochs trained: 17Training neural network. Epochs trained: 17Training neural network. Epochs trained: 17Training neural network. Epochs trained: 17Training neural network. Epochs trained: 18Training neural network. Epochs trained: 18Training neural network. Epochs trained: 18Training neural network. Epochs trained: 18Training neural network. Epochs trained: 19Training neural network. Epochs trained: 19Training neural network. Epochs trained: 19Training neural network. Epochs trained: 19Training neural network. Epochs trained: 20Training neural network. Epochs trained: 20Training neural network. Epochs trained: 20Training neural network. Epochs trained: 20Training neural network. Epochs trained: 21Training neural network. Epochs trained: 21Training neural network. Epochs trained: 21Training neural network. Epochs trained: 21Training neural network. Epochs trained: 22Training neural network. Epochs trained: 22Training neural network. Epochs trained: 22Training neural network. Epochs trained: 22Training neural network. Epochs trained: 23Training neural network. Epochs trained: 23Training neural network. Epochs trained: 23Training neural network. Epochs trained: 23Training neural network. Epochs trained: 24Training neural network. Epochs trained: 24Training neural network. Epochs trained: 24Training neural network. Epochs trained: 24Training neural network. Epochs trained: 25Training neural network. Epochs trained: 25Training neural network. Epochs trained: 25Training neural network. Epochs trained: 25Training neural network. Epochs trained: 26Training neural network. Epochs trained: 26Training neural network. Epochs trained: 26Training neural network. Epochs trained: 26Training neural network. Epochs trained: 27Training neural network. Epochs trained: 27Training neural network. Epochs trained: 27Training neural network. Epochs trained: 27Training neural network. Epochs trained: 28Training neural network. Epochs trained: 28Training neural network. Epochs trained: 28Training neural network. Epochs trained: 28Training neural network. Epochs trained: 29Training neural network. Epochs trained: 29Training neural network. Epochs trained: 29Training neural network. Epochs trained: 29Training neural network. Epochs trained: 30Training neural network. Epochs trained: 30Training neural network. Epochs trained: 30Training neural network. Epochs trained: 30Training neural network. Epochs trained: 31Training neural network. Epochs trained: 31Training neural network. Epochs trained: 31Training neural network. Epochs trained: 31Training neural network. Epochs trained: 32Training neural network. Epochs trained: 32Training neural network. Epochs trained: 32Training neural network. Epochs trained: 32Training neural network. Epochs trained: 33Training neural network. Epochs trained: 33Training neural network. Epochs trained: 33Training neural network. Epochs trained: 33Training neural network. Epochs trained: 34Training neural network. Epochs trained: 34Training neural network. Epochs trained: 34Training neural network. Epochs trained: 34Training neural network. Epochs trained: 35Training neural network. Epochs trained: 35Training neural network. Epochs trained: 35Training neural network. Epochs trained: 35Training neural network. Epochs trained: 36Training neural network. Epochs trained: 36Training neural network. Epochs trained: 36Training neural network. Epochs trained: 36Training neural network. Epochs trained: 37Training neural network. Epochs trained: 37Training neural network. Epochs trained: 37Training neural network. Epochs trained: 37Training neural network. Epochs trained: 38Training neural network. Epochs trained: 38Training neural network. Epochs trained: 38Training neural network. Epochs trained: 38Training neural network. Epochs trained: 39Training neural network. Epochs trained: 39Training neural network. Epochs trained: 39Training neural network. Epochs trained: 39Training neural network. Epochs trained: 40Training neural network. Epochs trained: 40Training neural network. Epochs trained: 40Training neural network. Epochs trained: 41Training neural network. Epochs trained: 40Training neural network. Epochs trained: 41Training neural network. Epochs trained: 41Training neural network. Epochs trained: 41Training neural network. Epochs trained: 42Training neural network. Epochs trained: 42Training neural network. Epochs trained: 42Training neural network. Epochs trained: 43Training neural network. Epochs trained: 42Training neural network. Epochs trained: 43Training neural network. Epochs trained: 43Training neural network. Epochs trained: 44Training neural network. Epochs trained: 43Training neural network. Epochs trained: 44Training neural network. Epochs trained: 44Training neural network. Epochs trained: 45Training neural network. Epochs trained: 44Training neural network. Epochs trained: 45Training neural network. Epochs trained: 45Training neural network. Epochs trained: 46Training neural network. Epochs trained: 46Training neural network. Epochs trained: 45Training neural network. Epochs trained: 46Training neural network. Epochs trained: 47Training neural network. Epochs trained: 47Training neural network. Epochs trained: 46Training neural network. Epochs trained: 47Training neural network. Epochs trained: 48Training neural network. Epochs trained: 48Training neural network. Epochs trained: 47Training neural network. Epochs trained: 49Training neural network. Epochs trained: 48Training neural network. Epochs trained: 49Training neural network. Epochs trained: 48Training neural network. Epochs trained: 50Training neural network. Epochs trained: 49Training neural network. Epochs trained: 50Training neural network. Epochs trained: 49Training neural network. Epochs trained: 51Training neural network. Epochs trained: 50Training neural network. Epochs trained: 51Training neural network. Epochs trained: 50Training neural network. Epochs trained: 52Training neural network. Epochs trained: 51Training neural network. Epochs trained: 52Training neural network. Epochs trained: 51Training neural network. Epochs trained: 53Training neural network. Epochs trained: 52Training neural network. Epochs trained: 53Training neural network. Epochs trained: 52Training neural network. Epochs trained: 54Training neural network. Epochs trained: 53Training neural network. Epochs trained: 54Training neural network. Epochs trained: 53Training neural network. Epochs trained: 55Training neural network. Epochs trained: 54Training neural network. Epochs trained: 55Training neural network. Epochs trained: 54Training neural network. Epochs trained: 56Training neural network. Epochs trained: 55Training neural network. Epochs trained: 56Training neural network. Epochs trained: 55Training neural network. Epochs trained: 57Training neural network. Epochs trained: 56Training neural network. Epochs trained: 57Training neural network. Epochs trained: 56Training neural network. Epochs trained: 58Training neural network. Epochs trained: 57Training neural network. Epochs trained: 58Training neural network. Epochs trained: 57Training neural network. Epochs trained: 59Training neural network. Epochs trained: 58Training neural network. Epochs trained: 59Training neural network. Epochs trained: 58Training neural network. Epochs trained: 60Training neural network. Epochs trained: 59Training neural network. Epochs trained: 60Training neural network. Epochs trained: 59Training neural network. Epochs trained: 61Training neural network. Epochs trained: 60Training neural network. Epochs trained: 61Training neural network. Epochs trained: 60Training neural network. Epochs trained: 62Training neural network. Epochs trained: 61Training neural network. Epochs trained: 62Training neural network. Epochs trained: 61Training neural network. Epochs trained: 63Training neural network. Epochs trained: 63Training neural network. Epochs trained: 62Training neural network. Epochs trained: 62Training neural network. Epochs trained: 63Training neural network. Epochs trained: 64Training neural network. Epochs trained: 64Training neural network. Epochs trained: 63Training neural network. Epochs trained: 65Training neural network. Epochs trained: 64Training neural network. Epochs trained: 65Training neural network. Epochs trained: 64Training neural network. Epochs trained: 66Training neural network. Epochs trained: 65Training neural network. Epochs trained: 66Training neural network. Epochs trained: 65Training neural network. Epochs trained: 67Training neural network. Epochs trained: 66Training neural network. Epochs trained: 67Training neural network. Epochs trained: 66Training neural network. Epochs trained: 68Training neural network. Epochs trained: 67Training neural network. Epochs trained: 68Training neural network. Epochs trained: 67Training neural network. Epochs trained: 69Training neural network. Epochs trained: 68Training neural network. Epochs trained: 69Training neural network. Epochs trained: 68Training neural network. Epochs trained: 70Training neural network. Epochs trained: 69Training neural network. Epochs trained: 70Training neural network. Epochs trained: 69Training neural network. Epochs trained: 71Training neural network. Epochs trained: 71Training neural network. Epochs trained: 70Training neural network. Epochs trained: 70Training neural network. Epochs trained: 72Training neural network. Epochs trained: 72Training neural network. Epochs trained: 71Training neural network. Epochs trained: 71Training neural network. Epochs trained: 73Training neural network. Epochs trained: 73Training neural network. Epochs trained: 72Training neural network. Epochs trained: 72Training neural network. Epochs trained: 74Training neural network. Epochs trained: 74Training neural network. Epochs trained: 73Training neural network. Epochs trained: 73Training neural network. Epochs trained: 75Training neural network. Epochs trained: 74Training neural network. Epochs trained: 75Training neural network. Epochs trained: 74Training neural network. Epochs trained: 76Training neural network. Epochs trained: 76Training neural network. Epochs trained: 75Training neural network. Epochs trained: 77Training neural network. Epochs trained: 75Training neural network. Epochs trained: 77Training neural network. Epochs trained: 76Training neural network. Epochs trained: 78Training neural network. Epochs trained: 76Training neural network. Epochs trained: 78Training neural network. Epochs trained: 77Training neural network. Epochs trained: 79Training neural network. Epochs trained: 79Training neural network. Epochs trained: 77Training neural network. Epochs trained: 78Training neural network. Epochs trained: 80Training neural network. Epochs trained: 80Training neural network. Epochs trained: 78Training neural network. Epochs trained: 79Training neural network. Epochs trained: 81Training neural network. Epochs trained: 81Training neural network. Epochs trained: 79Training neural network. Epochs trained: 80Training neural network. Epochs trained: 82Training neural network. Epochs trained: 82Training neural network. Epochs trained: 80Training neural network. Epochs trained: 81Training neural network. Epochs trained: 83Training neural network. Epochs trained: 83Training neural network. Epochs trained: 82Training neural network. Epochs trained: 81Training neural network. Epochs trained: 84Training neural network. Epochs trained: 84Training neural network. Epochs trained: 83Training neural network. Epochs trained: 82Training neural network. Epochs trained: 85Training neural network. Epochs trained: 85Training neural network. Epochs trained: 84Training neural network. Epochs trained: 83Training neural network. Epochs trained: 86Training neural network. Epochs trained: 86Training neural network. Epochs trained: 85Training neural network. Epochs trained: 84Training neural network. Epochs trained: 87Training neural network. Epochs trained: 87Training neural network. Epochs trained: 86Training neural network. Epochs trained: 85Training neural network. Epochs trained: 88Training neural network. Epochs trained: 88Training neural network. Epochs trained: 87Training neural network. Epochs trained: 86Training neural network. Epochs trained: 89Training neural network. Epochs trained: 89Training neural network. Epochs trained: 88Training neural network. Epochs trained: 87Training neural network. Epochs trained: 90Training neural network. Epochs trained: 90Training neural network. Epochs trained: 89Training neural network. Epochs trained: 88Training neural network. Epochs trained: 91Training neural network. Epochs trained: 91Training neural network. Epochs trained: 90Training neural network. Epochs trained: 89Training neural network. Epochs trained: 92Training neural network. Epochs trained: 92Training neural network. Epochs trained: 91Training neural network. Epochs trained: 90Training neural network. Epochs trained: 93Training neural network. Epochs trained: 93Training neural network. Epochs trained: 92Training neural network. Epochs trained: 91Training neural network. Epochs trained: 94Training neural network. Epochs trained: 94Training neural network. Epochs trained: 93Training neural network. Epochs trained: 92Training neural network. Epochs trained: 95Training neural network. Epochs trained: 95Training neural network. Epochs trained: 94Training neural network. Epochs trained: 93Training neural network. Epochs trained: 96Training neural network. Epochs trained: 96Training neural network. Epochs trained: 95Training neural network. Epochs trained: 94Training neural network. Epochs trained: 97Training neural network. Epochs trained: 97Training neural network. Epochs trained: 96Training neural network. Epochs trained: 95Training neural network. Epochs trained: 98Training neural network. Epochs trained: 97Training neural network. Epochs trained: 98Training neural network. Epochs trained: 96Training neural network. Epochs trained: 99Training neural network. Epochs trained: 99Training neural network. Epochs trained: 98Training neural network. Epochs trained: 97Training neural network. Epochs trained: 100Training neural network. Epochs trained: 100Training neural network. Epochs trained: 99Training neural network. Epochs trained: 98Training neural network. Epochs trained: 101Training neural network. Epochs trained: 101Training neural network. Epochs trained: 100Training neural network. Epochs trained: 99Training neural network. Epochs trained: 102Training neural network. Epochs trained: 102Training neural network. Epochs trained: 101Training neural network. Epochs trained: 100Training neural network. Epochs trained: 103Training neural network. Epochs trained: 102Training neural network. Epochs trained: 103Training neural network. Epochs trained: 101Training neural network. Epochs trained: 104Training neural network. Epochs trained: 104Training neural network. Epochs trained: 103Training neural network. Epochs trained: 102Training neural network. Epochs trained: 105Training neural network. Epochs trained: 105Training neural network. Epochs trained: 104Training neural network. Epochs trained: 106Training neural network. Epochs trained: 103Training neural network. Epochs trained: 106Training neural network. Epochs trained: 105Training neural network. Epochs trained: 107Training neural network. Epochs trained: 104Training neural network. Epochs trained: 107Training neural network. Epochs trained: 106Training neural network. Epochs trained: 108Training neural network. Epochs trained: 105Training neural network. Epochs trained: 107Training neural network. Epochs trained: 108Training neural network. Epochs trained: 106Training neural network. Epochs trained: 109Training neural network. Epochs trained: 108Training neural network. Epochs trained: 109Training neural network. Epochs trained: 107Training neural network. Epochs trained: 110Training neural network. Epochs trained: 109Training neural network. Epochs trained: 110Training neural network. Epochs trained: 108Training neural network. Epochs trained: 111Training neural network. Epochs trained: 110Training neural network. Epochs trained: 111Training neural network. Epochs trained: 112Training neural network. Epochs trained: 109Training neural network. Epochs trained: 111Training neural network. Epochs trained: 112Training neural network. Epochs trained: 113Training neural network. Epochs trained: 110Training neural network. Epochs trained: 112Training neural network. Epochs trained: 113Training neural network. Epochs trained: 114Training neural network. Epochs trained: 111Training neural network. Epochs trained: 113Training neural network. Epochs trained: 114Training neural network. Epochs trained: 112Training neural network. Epochs trained: 115Training neural network. Epochs trained: 114Training neural network. Epochs trained: 115Training neural network. Epochs trained: 113Training neural network. Epochs trained: 116Training neural network. Epochs trained: 115Training neural network. Epochs trained: 116Training neural network. Epochs trained: 114Training neural network. Epochs trained: 117Training neural network. Epochs trained: 116Training neural network. Epochs trained: 117Training neural network. Epochs trained: 118Training neural network. Epochs trained: 115Training neural network. Epochs trained: 117Training neural network. Epochs trained: 118Training neural network. Epochs trained: 119Training neural network. Epochs trained: 116Training neural network. Epochs trained: 118Training neural network. Epochs trained: 119Training neural network. Epochs trained: 117Training neural network. Epochs trained: 120Training neural network. Epochs trained: 119Training neural network. Epochs trained: 120Training neural network. Epochs trained: 118Training neural network. Epochs trained: 121Training neural network. Epochs trained: 120Training neural network. Epochs trained: 121Training neural network. Epochs trained: 119Training neural network. Epochs trained: 122Training neural network. Epochs trained: 121Training neural network. Epochs trained: 122Training neural network. Epochs trained: 123Training neural network. Epochs trained: 120Training neural network. Epochs trained: 122Training neural network. Epochs trained: 123Training neural network. Epochs trained: 124Training neural network. Epochs trained: 121Training neural network. Epochs trained: 123Training neural network. Epochs trained: 124Training neural network. Epochs trained: 125Training neural network. Epochs trained: 122Training neural network. Epochs trained: 124Training neural network. Epochs trained: 125Training neural network. Epochs trained: 123Training neural network. Epochs trained: 126Training neural network. Epochs trained: 125Training neural network. Epochs trained: 126Training neural network. Epochs trained: 124Training neural network. Epochs trained: 127Training neural network. Epochs trained: 126Training neural network. Epochs trained: 127Training neural network. Epochs trained: 125Training neural network. Epochs trained: 128Training neural network. Epochs trained: 127Training neural network. Epochs trained: 128Training neural network. Epochs trained: 129Training neural network. Epochs trained: 126Training neural network. Epochs trained: 128Training neural network. Epochs trained: 129Training neural network. Epochs trained: 130Training neural network. Epochs trained: 127Training neural network. Epochs trained: 129Training neural network. Epochs trained: 130Training neural network. Epochs trained: 131Training neural network. Epochs trained: 128Training neural network. Epochs trained: 130Training neural network. Epochs trained: 131Training neural network. Epochs trained: 132Training neural network. Epochs trained: 129Training neural network. Epochs trained: 131Training neural network. Epochs trained: 132Training neural network. Epochs trained: 133Training neural network. Epochs trained: 130Training neural network. Epochs trained: 132Training neural network. Epochs trained: 133Training neural network. Epochs trained: 134Training neural network. Epochs trained: 131Training neural network. Epochs trained: 133Training neural network. Epochs trained: 134Training neural network. Epochs trained: 135Training neural network. Epochs trained: 132Training neural network. Epochs trained: 134Training neural network. Epochs trained: 135Training neural network. Epochs trained: 136Training neural network. Epochs trained: 133Training neural network. Epochs trained: 135Training neural network. Epochs trained: 136Training neural network. Epochs trained: 137Training neural network. Epochs trained: 134Training neural network. Epochs trained: 136Training neural network. Epochs trained: 137Training neural network. Epochs trained: 138Training neural network. Epochs trained: 135Training neural network. Epochs trained: 137Training neural network. Epochs trained: 138Training neural network. Epochs trained: 139Training neural network. Epochs trained: 136Training neural network. Epochs trained: 138Training neural network. Epochs trained: 139Training neural network. Epochs trained: 140Training neural network. Epochs trained: 137Training neural network. Epochs trained: 139Training neural network. Epochs trained: 140Training neural network. Epochs trained: 141Training neural network. Epochs trained: 138Training neural network. Epochs trained: 140Training neural network. Epochs trained: 141Training neural network. Epochs trained: 142Training neural network. Epochs trained: 139Training neural network. Epochs trained: 141Training neural network. Epochs trained: 142Training neural network. Epochs trained: 143Training neural network. Epochs trained: 140Training neural network. Epochs trained: 142Training neural network. Epochs trained: 143Training neural network. Epochs trained: 144Training neural network. Epochs trained: 141Training neural network. Epochs trained: 143Training neural network. Epochs trained: 144Training neural network. Epochs trained: 145Training neural network. Epochs trained: 142Training neural network. Epochs trained: 144Training neural network. Epochs trained: 145Training neural network. Epochs trained: 146Training neural network. Epochs trained: 143Training neural network. Epochs trained: 145Training neural network. Epochs trained: 146Training neural network. Epochs trained: 147Training neural network. Epochs trained: 144Training neural network. Epochs trained: 146Training neural network. Epochs trained: 147Training neural network. Epochs trained: 148Training neural network. Epochs trained: 145Training neural network. Epochs trained: 147Training neural network. Epochs trained: 148Training neural network. Epochs trained: 149Training neural network. Epochs trained: 146Training neural network. Epochs trained: 148Training neural network. Epochs trained: 149Training neural network. Epochs trained: 150Training neural network. Epochs trained: 147Training neural network. Epochs trained: 149Training neural network. Epochs trained: 150Training neural network. Epochs trained: 151Training neural network. Epochs trained: 148Training neural network. Epochs trained: 150Training neural network. Epochs trained: 151Training neural network. Epochs trained: 152Training neural network. Epochs trained: 149Training neural network. Epochs trained: 151Training neural network. Epochs trained: 152Training neural network. Epochs trained: 153Training neural network. Epochs trained: 150Training neural network. Epochs trained: 152Training neural network. Epochs trained: 153Training neural network. Epochs trained: 154Training neural network. Epochs trained: 151Training neural network. Epochs trained: 153Training neural network. Epochs trained: 154Training neural network. Epochs trained: 155Training neural network. Epochs trained: 152Training neural network. Epochs trained: 154Training neural network. Epochs trained: 155Training neural network. Epochs trained: 156Training neural network. Epochs trained: 153Training neural network. Epochs trained: 155Training neural network. Epochs trained: 156Training neural network. Epochs trained: 157Training neural network. Epochs trained: 154Training neural network. Epochs trained: 156Training neural network. Epochs trained: 157Training neural network. Epochs trained: 158Training neural network. Epochs trained: 155Training neural network. Epochs trained: 157Training neural network. Epochs trained: 158Training neural network. Epochs trained: 159Training neural network. Epochs trained: 156Training neural network. Epochs trained: 158Training neural network. Epochs trained: 159Training neural network. Epochs trained: 160Training neural network. Epochs trained: 157Training neural network. Epochs trained: 159Training neural network. Epochs trained: 160Training neural network. Epochs trained: 161Training neural network. Epochs trained: 158Training neural network. Epochs trained: 160Training neural network. Epochs trained: 161Training neural network. Epochs trained: 162Training neural network. Epochs trained: 159Training neural network. Epochs trained: 161Training neural network. Epochs trained: 162Training neural network. Epochs trained: 163Training neural network. Epochs trained: 160Training neural network. Epochs trained: 162Training neural network. Epochs trained: 163Training neural network. Epochs trained: 164Training neural network. Epochs trained: 161Training neural network. Epochs trained: 163Training neural network. Epochs trained: 164Training neural network. Epochs trained: 165Training neural network. Epochs trained: 162Training neural network. Epochs trained: 164Training neural network. Epochs trained: 165Training neural network. Epochs trained: 166Training neural network. Epochs trained: 163Training neural network. Epochs trained: 165Training neural network. Epochs trained: 166Training neural network. Epochs trained: 167Training neural network. Epochs trained: 164Training neural network. Epochs trained: 166Training neural network. Epochs trained: 167Training neural network. Epochs trained: 168Training neural network. Epochs trained: 165Training neural network. Epochs trained: 167Training neural network. Epochs trained: 168Training neural network. Epochs trained: 169Training neural network. Epochs trained: 166Training neural network. Epochs trained: 168Training neural network. Epochs trained: 169Training neural network. Epochs trained: 170Training neural network. Epochs trained: 167Training neural network. Epochs trained: 169Training neural network. Epochs trained: 170Training neural network. Epochs trained: 171Training neural network. Epochs trained: 168Training neural network. Epochs trained: 170Training neural network. Epochs trained: 171Training neural network. Epochs trained: 172Training neural network. Epochs trained: 169Training neural network. Epochs trained: 171Training neural network. Epochs trained: 172Training neural network. Epochs trained: 173Training neural network. Epochs trained: 170Training neural network. Epochs trained: 172Training neural network. Epochs trained: 173Training neural network. Epochs trained: 174Training neural network. Epochs trained: 171Training neural network. Epochs trained: 173Training neural network. Epochs trained: 174Training neural network. Epochs trained: 175Training neural network. Epochs trained: 172Training neural network. Epochs trained: 174Training neural network. Epochs trained: 175Training neural network. Epochs trained: 176Training neural network. Epochs trained: 173Training neural network. Epochs trained: 175Training neural network. Epochs trained: 176Training neural network. Epochs trained: 177Training neural network. Epochs trained: 174Training neural network. Epochs trained: 176Training neural network. Epochs trained: 177Training neural network. Epochs trained: 178Training neural network. Epochs trained: 175Training neural network. Epochs trained: 177Training neural network. Epochs trained: 179Training neural network. Epochs trained: 178Training neural network. Epochs trained: 176Training neural network. Epochs trained: 178Training neural network. Epochs trained: 180Training neural network. Epochs trained: 179Training neural network. Epochs trained: 177Training neural network. Epochs trained: 179Training neural network. Epochs trained: 181Training neural network. Epochs trained: 180Training neural network. Epochs trained: 178Training neural network. Epochs trained: 180Training neural network. Epochs trained: 182Training neural network. Epochs trained: 181Training neural network. Epochs trained: 179Training neural network. Epochs trained: 181Training neural network. Epochs trained: 183Training neural network. Epochs trained: 182Training neural network. Epochs trained: 180Training neural network. Epochs trained: 184Training neural network. Epochs trained: 182Training neural network. Epochs trained: 183Training neural network. Epochs trained: 181Training neural network. Epochs trained: 185Training neural network. Epochs trained: 183Training neural network. Epochs trained: 184Training neural network. Epochs trained: 182Training neural network. Epochs trained: 186Training neural network. Epochs trained: 184Training neural network. Epochs trained: 185Training neural network. Epochs trained: 183Training neural network. Epochs trained: 187Training neural network. Epochs trained: 185Training neural network. Epochs trained: 186Training neural network. Epochs trained: 184Training neural network. Epochs trained: 186Training neural network. Epochs trained: 188Training neural network. Epochs trained: 187Training neural network. Epochs trained: 185Training neural network. Epochs trained: 187Training neural network. Epochs trained: 189Training neural network. Epochs trained: 188Training neural network. Epochs trained: 186Training neural network. Epochs trained: 190Training neural network. Epochs trained: 188Training neural network. Epochs trained: 189Training neural network. Epochs trained: 187Training neural network. Epochs trained: 191Training neural network. Epochs trained: 189Training neural network. Epochs trained: 190Training neural network. Epochs trained: 188Training neural network. Epochs trained: 192Training neural network. Epochs trained: 190Training neural network. Epochs trained: 191Training neural network. Epochs trained: 189Training neural network. Epochs trained: 191Training neural network. Epochs trained: 193Training neural network. Epochs trained: 192Training neural network. Epochs trained: 190Training neural network. Epochs trained: 192Training neural network. Epochs trained: 194Training neural network. Epochs trained: 193Training neural network. Epochs trained: 191Training neural network. Epochs trained: 193Training neural network. Epochs trained: 195Training neural network. Epochs trained: 194Training neural network. Epochs trained: 192Training neural network. Epochs trained: 194Training neural network. Epochs trained: 196Training neural network. Epochs trained: 195Training neural network. Epochs trained: 193Training neural network. Epochs trained: 195Training neural network. Epochs trained: 197Training neural network. Epochs trained: 196Training neural network. Epochs trained: 194Training neural network. Epochs trained: 196Training neural network. Epochs trained: 198Training neural network. Epochs trained: 197Training neural network. Epochs trained: 195Training neural network. Epochs trained: 197Training neural network. Epochs trained: 199Training neural network. Epochs trained: 198Training neural network. Epochs trained: 196Training neural network. Epochs trained: 198Training neural network. Epochs trained: 200Training neural network. Epochs trained: 199Training neural network. Epochs trained: 197Training neural network. Epochs trained: 199Training neural network. Epochs trained: 201Training neural network. Epochs trained: 200Training neural network. Epochs trained: 198Training neural network. Epochs trained: 202Training neural network. Epochs trained: 200Training neural network. Epochs trained: 201Training neural network. Epochs trained: 199 Training neural network. Epochs trained: 203Training neural network. Epochs trained: 202Training neural network. Epochs trained: 200Training neural network. Epochs trained: 204Training neural network. Epochs trained: 202Training neural network. Epochs trained: 203Training neural network. Epochs trained: 201Training neural network. Epochs trained: 203Training neural network. Epochs trained: 205Training neural network. Epochs trained: 204Training neural network. Epochs trained: 202Training neural network. Epochs trained: 204Training neural network. Epochs trained: 206Training neural network. Epochs trained: 205Training neural network. Epochs trained: 203Training neural network. Epochs trained: 207Training neural network. Epochs trained: 205Training neural network. Epochs trained: 206Training neural network. Epochs trained: 204Training neural network. Epochs trained: 208Training neural network. Epochs trained: 206Training neural network. Epochs trained: 207Training neural network. Epochs trained: 205Training neural network. Epochs trained: 209Training neural network. Epochs trained: 207Training neural network. Epochs trained: 208Training neural network. Epochs trained: 206Training neural network. Epochs trained: 208Training neural network. Epochs trained: 210Training neural network. Epochs trained: 209Training neural network. Epochs trained: 207Training neural network. Epochs trained: 209Training neural network. Epochs trained: 211Training neural network. Epochs trained: 210Training neural network. Epochs trained: 208Training neural network. Epochs trained: 212Training neural network. Epochs trained: 210Training neural network. Epochs trained: 211Training neural network. Epochs trained: 209Training neural network. Epochs trained: 213Training neural network. Epochs trained: 211Training neural network. Epochs trained: 212Training neural network. Epochs trained: 210Training neural network. Epochs trained: 214Training neural network. Epochs trained: 212Training neural network. Epochs trained: 213Training neural network. Epochs trained: 211Training neural network. Epochs trained: 215Training neural network. Epochs trained: 213Training neural network. Epochs trained: 214Training neural network. Epochs trained: 212Training neural network. Epochs trained: 214Training neural network. Epochs trained: 216Training neural network. Epochs trained: 215Training neural network. Epochs trained: 213Training neural network. Epochs trained: 215Training neural network. Epochs trained: 217Training neural network. Epochs trained: 214Training neural network. Epochs trained: 216Training neural network. Epochs trained: 218Training neural network. Epochs trained: 216Training neural network. Epochs trained: 215Training neural network. Epochs trained: 217Training neural network. Epochs trained: 219Training neural network. Epochs trained: 217Training neural network. Epochs trained: 220Training neural network. Epochs trained: 218Training neural network. Epochs trained: 216Training neural network. Epochs trained: 218 Training neural network. Epochs trained: 219Training neural network. Epochs trained: 217Training neural network. Epochs trained: 219  Training neural network. Epochs trained: 222Training neural network. Epochs trained: 218Training neural network. Epochs trained: 220Training neural network. Epochs trained: 220  Training neural network. Epochs trained: 219Training neural network. Epochs trained: 223Training neural network. Epochs trained: 221Training neural network. Epochs trained: 221Training neural network. Epochs trained: 220Training neural network. Epochs trained: 224Training neural network. Epochs trained: 222Training neural network. Epochs trained: 222Training neural network. Epochs trained: 225Training neural network. Epochs trained: 221Training neural network. Epochs trained: 223Training neural network. Epochs trained: 223Training neural network. Epochs trained: 226Training neural network. Epochs trained: 222Training neural network. Epochs trained: 224Training neural network. Epochs trained: 224Training neural network. Epochs trained: 223Training neural network. Epochs trained: 227Training neural network. Epochs trained: 225Training neural network. Epochs trained: 225Training neural network. Epochs trained: 224Training neural network. Epochs trained: 228Training neural network. Epochs trained: 226Training neural network. Epochs trained: 226Training neural network. Epochs trained: 225Training neural network. Epochs trained: 229Training neural network. Epochs trained: 227Training neural network. Epochs trained: 227Training neural network. Epochs trained: 226Training neural network. Epochs trained: 230Training neural network. Epochs trained: 228Training neural network. Epochs trained: 228Training neural network. Epochs trained: 231Training neural network. Epochs trained: 227Training neural network. Epochs trained: 229Training neural network. Epochs trained: 229Training neural network. Epochs trained: 228Training neural network. Epochs trained: 232Training neural network. Epochs trained: 230Training neural network. Epochs trained: 230Training neural network. Epochs trained: 229Training neural network. Epochs trained: 233Training neural network. Epochs trained: 231Training neural network. Epochs trained: 231Training neural network. Epochs trained: 230Training neural network. Epochs trained: 234Training neural network. Epochs trained: 232Training neural network. Epochs trained: 232Training neural network. Epochs trained: 231Training neural network. Epochs trained: 235Training neural network. Epochs trained: 233Training neural network. Epochs trained: 233Training neural network. Epochs trained: 236Training neural network. Epochs trained: 232Training neural network. Epochs trained: 234Training neural network. Epochs trained: 234Training neural network. Epochs trained: 237Training neural network. Epochs trained: 233Training neural network. Epochs trained: 235Training neural network. Epochs trained: 235Training neural network. Epochs trained: 238Training neural network. Epochs trained: 234Training neural network. Epochs trained: 236Training neural network. Epochs trained: 236Training neural network. Epochs trained: 239Training neural network. Epochs trained: 235Training neural network. Epochs trained: 237Training neural network. Epochs trained: 237Training neural network. Epochs trained: 240Training neural network. Epochs trained: 236Training neural network. Epochs trained: 238Training neural network. Epochs trained: 238Training neural network. Epochs trained: 241Training neural network. Epochs trained: 237Training neural network. Epochs trained: 239Training neural network. Epochs trained: 239Training neural network. Epochs trained: 242Training neural network. Epochs trained: 238Training neural network. Epochs trained: 240Training neural network. Epochs trained: 240Training neural network. Epochs trained: 243Training neural network. Epochs trained: 239Training neural network. Epochs trained: 241Training neural network. Epochs trained: 241Training neural network. Epochs trained: 244Training neural network. Epochs trained: 240Training neural network. Epochs trained: 242Training neural network. Epochs trained: 242Training neural network. Epochs trained: 245Training neural network. Epochs trained: 241Training neural network. Epochs trained: 243Training neural network. Epochs trained: 243Training neural network. Epochs trained: 246Training neural network. Epochs trained: 242Training neural network. Epochs trained: 244Training neural network. Epochs trained: 244Training neural network. Epochs trained: 247Training neural network. Epochs trained: 243Training neural network. Epochs trained: 245Training neural network. Epochs trained: 245Training neural network. Epochs trained: 248Training neural network. Epochs trained: 244Training neural network. Epochs trained: 246Training neural network. Epochs trained: 246Training neural network. Epochs trained: 249Training neural network. Epochs trained: 245Training neural network. Epochs trained: 247Training neural network. Epochs trained: 247Training neural network. Epochs trained: 250Training neural network. Epochs trained: 246Training neural network. Epochs trained: 248Training neural network. Epochs trained: 248Training neural network. Epochs trained: 251Training neural network. Epochs trained: 247Training neural network. Epochs trained: 249Training neural network. Epochs trained: 249Training neural network. Epochs trained: 252Training neural network. Epochs trained: 248Training neural network. Epochs trained: 250Training neural network. Epochs trained: 250Training neural network. Epochs trained: 253Training neural network. Epochs trained: 251Training neural network. Epochs trained: 249Training neural network. Epochs trained: 251Training neural network. Epochs trained: 254Training neural network. Epochs trained: 252Training neural network. Epochs trained: 250Training neural network. Epochs trained: 252Training neural network. Epochs trained: 255Training neural network. Epochs trained: 253Training neural network. Epochs trained: 251Training neural network. Epochs trained: 253Training neural network. Epochs trained: 256Training neural network. Epochs trained: 254Training neural network. Epochs trained: 252Training neural network. Epochs trained: 254Training neural network. Epochs trained: 257Training neural network. Epochs trained: 253Training neural network. Epochs trained: 255Training neural network. Epochs trained: 255Training neural network. Epochs trained: 258Training neural network. Epochs trained: 256Training neural network. Epochs trained: 254Training neural network. Epochs trained: 259Training neural network. Epochs trained: 256Training neural network. Epochs trained: 257Training neural network. Epochs trained: 255Training neural network. Epochs trained: 257Training neural network. Epochs trained: 260Training neural network. Epochs trained: 258Training neural network. Epochs trained: 256Training neural network. Epochs trained: 261Training neural network. Epochs trained: 258Training neural network. Epochs trained: 259Training neural network. Epochs trained: 257Training neural network. Epochs trained: 262Training neural network. Epochs trained: 259Training neural network. Epochs trained: 260Training neural network. Epochs trained: 258Training neural network. Epochs trained: 263Training neural network. Epochs trained: 260Training neural network. Epochs trained: 261Training neural network. Epochs trained: 259Training neural network. Epochs trained: 264Training neural network. Epochs trained: 261Training neural network. Epochs trained: 262Training neural network. Epochs trained: 260Training neural network. Epochs trained: 265Training neural network. Epochs trained: 262Training neural network. Epochs trained: 263Training neural network. Epochs trained: 261Training neural network. Epochs trained: 266Training neural network. Epochs trained: 263Training neural network. Epochs trained: 264Training neural network. Epochs trained: 262Training neural network. Epochs trained: 267Training neural network. Epochs trained: 264Training neural network. Epochs trained: 265Training neural network. Epochs trained: 263Training neural network. Epochs trained: 268Training neural network. Epochs trained: 265Training neural network. Epochs trained: 266Training neural network. Epochs trained: 264Training neural network. Epochs trained: 269Training neural network. Epochs trained: 266Training neural network. Epochs trained: 267Training neural network. Epochs trained: 265Training neural network. Epochs trained: 270Training neural network. Epochs trained: 267Training neural network. Epochs trained: 268Training neural network. Epochs trained: 266Training neural network. Epochs trained: 271Training neural network. Epochs trained: 268Training neural network. Epochs trained: 269Training neural network. Epochs trained: 267Training neural network. Epochs trained: 272Training neural network. Epochs trained: 269Training neural network. Epochs trained: 270Training neural network. Epochs trained: 268Training neural network. Epochs trained: 273Training neural network. Epochs trained: 270Training neural network. Epochs trained: 271Training neural network. Epochs trained: 269Training neural network. Epochs trained: 274Training neural network. Epochs trained: 271Training neural network. Epochs trained: 272Training neural network. Epochs trained: 270Training neural network. Epochs trained: 275Training neural network. Epochs trained: 272Training neural network. Epochs trained: 273Training neural network. Epochs trained: 271Training neural network. Epochs trained: 276Training neural network. Epochs trained: 273Training neural network. Epochs trained: 274Training neural network. Epochs trained: 272Training neural network. Epochs trained: 277Training neural network. Epochs trained: 274Training neural network. Epochs trained: 275Training neural network. Epochs trained: 273Training neural network. Epochs trained: 278Training neural network. Epochs trained: 275Training neural network. Epochs trained: 276Training neural network. Epochs trained: 274Training neural network. Epochs trained: 279Training neural network. Epochs trained: 276Training neural network. Epochs trained: 277Training neural network. Epochs trained: 275Training neural network. Epochs trained: 280Training neural network. Epochs trained: 277Training neural network. Epochs trained: 278Training neural network. Epochs trained: 276Training neural network. Epochs trained: 281Training neural network. Epochs trained: 278Training neural network. Epochs trained: 279Training neural network. Epochs trained: 277Training neural network. Epochs trained: 282Training neural network. Epochs trained: 279Training neural network. Epochs trained: 280Training neural network. Epochs trained: 278Training neural network. Epochs trained: 283Training neural network. Epochs trained: 280Training neural network. Epochs trained: 281Training neural network. Epochs trained: 279Training neural network. Epochs trained: 284Training neural network. Epochs trained: 281Training neural network. Epochs trained: 282Training neural network. Epochs trained: 280Training neural network. Epochs trained: 285Training neural network. Epochs trained: 282Training neural network. Epochs trained: 283Training neural network. Epochs trained: 286Training neural network. Epochs trained: 281Training neural network. Epochs trained: 283Training neural network. Epochs trained: 284Training neural network. Epochs trained: 287Training neural network. Epochs trained: 282Training neural network. Epochs trained: 284Training neural network. Epochs trained: 285Training neural network. Epochs trained: 288Training neural network. Epochs trained: 283Training neural network. Epochs trained: 285Training neural network. Epochs trained: 286Training neural network. Epochs trained: 289Training neural network. Epochs trained: 284Training neural network. Epochs trained: 286Training neural network. Epochs trained: 287Training neural network. Epochs trained: 290Training neural network. Epochs trained: 285Training neural network. Epochs trained: 287Training neural network. Epochs trained: 288Training neural network. Epochs trained: 291Training neural network. Epochs trained: 286Training neural network. Epochs trained: 288Training neural network. Epochs trained: 289Training neural network. Epochs trained: 292Training neural network. Epochs trained: 287Training neural network. Epochs trained: 289Training neural network. Epochs trained: 290Training neural network. Epochs trained: 293Training neural network. Epochs trained: 288Training neural network. Epochs trained: 290Training neural network. Epochs trained: 291Training neural network. Epochs trained: 294Training neural network. Epochs trained: 289Training neural network. Epochs trained: 292Training neural network. Epochs trained: 291Training neural network. Epochs trained: 295Training neural network. Epochs trained: 290Training neural network. Epochs trained: 293Training neural network. Epochs trained: 292Training neural network. Epochs trained: 296Training neural network. Epochs trained: 291Training neural network. Epochs trained: 293Training neural network. Epochs trained: 294Training neural network. Epochs trained: 297Training neural network. Epochs trained: 292Training neural network. Epochs trained: 295Training neural network. Epochs trained: 294Training neural network. Epochs trained: 298Training neural network. Epochs trained: 293Training neural network. Epochs trained: 296Training neural network. Epochs trained: 295Training neural network. Epochs trained: 299Training neural network. Epochs trained: 294Training neural network. Epochs trained: 297Training neural network. Epochs trained: 296Training neural network. Epochs trained: 300Training neural network. Epochs trained: 295Training neural network. Epochs trained: 298Training neural network. Epochs trained: 297Training neural network. Epochs trained: 301Training neural network. Epochs trained: 296Training neural network. Epochs trained: 298Training neural network. Epochs trained: 299Training neural network. Epochs trained: 302Training neural network. Epochs trained: 297Training neural network. Epochs trained: 300Training neural network. Epochs trained: 299Training neural network. Epochs trained: 303Training neural network. Epochs trained: 298Training neural network. Epochs trained: 301Training neural network. Epochs trained: 300Training neural network. Epochs trained: 304Training neural network. Epochs trained: 299Training neural network. Epochs trained: 302Training neural network. Epochs trained: 301Training neural network. Epochs trained: 305Training neural network. Epochs trained: 300Training neural network. Epochs trained: 303Training neural network. Epochs trained: 302Training neural network. Epochs trained: 306Training neural network. Epochs trained: 301Training neural network. Epochs trained: 303Training neural network. Epochs trained: 304Training neural network. Epochs trained: 307Training neural network. Epochs trained: 302Training neural network. Epochs trained: 305Training neural network. Epochs trained: 304Training neural network. Epochs trained: 308Training neural network. Epochs trained: 303Training neural network. Epochs trained: 306Training neural network. Epochs trained: 305Training neural network. Epochs trained: 309Training neural network. Epochs trained: 304Training neural network. Epochs trained: 307Training neural network. Epochs trained: 306Training neural network. Epochs trained: 310Training neural network. Epochs trained: 305Training neural network. Epochs trained: 308Training neural network. Epochs trained: 307Training neural network. Epochs trained: 311Training neural network. Epochs trained: 306Training neural network. Epochs trained: 309Training neural network. Epochs trained: 308Training neural network. Epochs trained: 312Training neural network. Epochs trained: 307Training neural network. Epochs trained: 309Training neural network. Epochs trained: 310Training neural network. Epochs trained: 313Training neural network. Epochs trained: 308Training neural network. Epochs trained: 311Training neural network. Epochs trained: 310Training neural network. Epochs trained: 314Training neural network. Epochs trained: 309Training neural network. Epochs trained: 312Training neural network. Epochs trained: 311Training neural network. Epochs trained: 315Training neural network. Epochs trained: 310Training neural network. Epochs trained: 313Training neural network. Epochs trained: 312Training neural network. Epochs trained: 316Training neural network. Epochs trained: 311Training neural network. Epochs trained: 314Training neural network. Epochs trained: 313Training neural network. Epochs trained: 317Training neural network. Epochs trained: 312Training neural network. Epochs trained: 315Training neural network. Epochs trained: 314Training neural network. Epochs trained: 318Training neural network. Epochs trained: 313Training neural network. Epochs trained: 316Training neural network. Epochs trained: 319Training neural network. Epochs trained: 315Training neural network. Epochs trained: 314Training neural network. Epochs trained: 317Training neural network. Epochs trained: 320Training neural network. Epochs trained: 316Training neural network. Epochs trained: 315Training neural network. Epochs trained: 318Training neural network. Epochs trained: 321Training neural network. Epochs trained: 317Training neural network. Epochs trained: 316Training neural network. Epochs trained: 319Training neural network. Epochs trained: 322Training neural network. Epochs trained: 318Training neural network. Epochs trained: 317Training neural network. Epochs trained: 320Training neural network. Epochs trained: 323Training neural network. Epochs trained: 319Training neural network. Epochs trained: 318Training neural network. Epochs trained: 321Training neural network. Epochs trained: 324Training neural network. Epochs trained: 320Training neural network. Epochs trained: 319Training neural network. Epochs trained: 322Training neural network. Epochs trained: 325Training neural network. Epochs trained: 321Training neural network. Epochs trained: 320Training neural network. Epochs trained: 323Training neural network. Epochs trained: 326Training neural network. Epochs trained: 322Training neural network. Epochs trained: 321Training neural network. Epochs trained: 324Training neural network. Epochs trained: 327Training neural network. Epochs trained: 323Training neural network. Epochs trained: 322Training neural network. Epochs trained: 325Training neural network. Epochs trained: 328Training neural network. Epochs trained: 324Training neural network. Epochs trained: 323Training neural network. Epochs trained: 326Training neural network. Epochs trained: 329Training neural network. Epochs trained: 325Training neural network. Epochs trained: 324Training neural network. Epochs trained: 327Training neural network. Epochs trained: 330Training neural network. Epochs trained: 326Training neural network. Epochs trained: 325Training neural network. Epochs trained: 328Training neural network. Epochs trained: 331Training neural network. Epochs trained: 327Training neural network. Epochs trained: 326Training neural network. Epochs trained: 329Training neural network. Epochs trained: 332Training neural network. Epochs trained: 328Training neural network. Epochs trained: 327Training neural network. Epochs trained: 330Training neural network. Epochs trained: 333Training neural network. Epochs trained: 329Training neural network. Epochs trained: 328Training neural network. Epochs trained: 331Training neural network. Epochs trained: 334Training neural network. Epochs trained: 330Training neural network. Epochs trained: 329Training neural network. Epochs trained: 332Training neural network. Epochs trained: 335Training neural network. Epochs trained: 331Training neural network. Epochs trained: 330Training neural network. Epochs trained: 333Training neural network. Epochs trained: 336Training neural network. Epochs trained: 332Training neural network. Epochs trained: 331Training neural network. Epochs trained: 334Training neural network. Epochs trained: 337Training neural network. Epochs trained: 333Training neural network. Epochs trained: 332Training neural network. Epochs trained: 335Training neural network. Epochs trained: 338Training neural network. Epochs trained: 334Training neural network. Epochs trained: 333Training neural network. Epochs trained: 336Training neural network. Epochs trained: 339Training neural network. Epochs trained: 335Training neural network. Epochs trained: 334Training neural network. Epochs trained: 337Training neural network. Epochs trained: 340Training neural network. Epochs trained: 336Training neural network. Epochs trained: 335Training neural network. Epochs trained: 338Training neural network. Epochs trained: 341Training neural network. Epochs trained: 337Training neural network. Epochs trained: 336Training neural network. Epochs trained: 339Training neural network. Epochs trained: 342Training neural network. Epochs trained: 338Training neural network. Epochs trained: 337Training neural network. Epochs trained: 340Training neural network. Epochs trained: 343Training neural network. Epochs trained: 339Training neural network. Epochs trained: 338Training neural network. Epochs trained: 341Training neural network. Epochs trained: 344Training neural network. Epochs trained: 340Training neural network. Epochs trained: 339Training neural network. Epochs trained: 342Training neural network. Epochs trained: 345Training neural network. Epochs trained: 341Training neural network. Epochs trained: 340Training neural network. Epochs trained: 343Training neural network. Epochs trained: 346Training neural network. Epochs trained: 342Training neural network. Epochs trained: 341Training neural network. Epochs trained: 344Training neural network. Epochs trained: 347Training neural network. Epochs trained: 343Training neural network. Epochs trained: 342Training neural network. Epochs trained: 345Training neural network. Epochs trained: 348Training neural network. Epochs trained: 344Training neural network. Epochs trained: 343Training neural network. Epochs trained: 346Training neural network. Epochs trained: 349Training neural network. Epochs trained: 345Training neural network. Epochs trained: 344Training neural network. Epochs trained: 347Training neural network. Epochs trained: 350Training neural network. Epochs trained: 346Training neural network. Epochs trained: 345Training neural network. Epochs trained: 348Training neural network. Epochs trained: 351Training neural network. Epochs trained: 347Training neural network. Epochs trained: 346Training neural network. Epochs trained: 349Training neural network. Epochs trained: 352Training neural network. Epochs trained: 348Training neural network. Epochs trained: 347Training neural network. Epochs trained: 350Training neural network. Epochs trained: 353Training neural network. Epochs trained: 349Training neural network. Epochs trained: 348Training neural network. Epochs trained: 351Training neural network. Epochs trained: 354Training neural network. Epochs trained: 350Training neural network. Epochs trained: 352Training neural network. Epochs trained: 349Training neural network. Epochs trained: 355Training neural network. Epochs trained: 351Training neural network. Epochs trained: 353Training neural network. Epochs trained: 350Training neural network. Epochs trained: 356Training neural network. Epochs trained: 352Training neural network. Epochs trained: 354Training neural network. Epochs trained: 351Training neural network. Epochs trained: 357Training neural network. Epochs trained: 353Training neural network. Epochs trained: 352Training neural network. Epochs trained: 355Training neural network. Epochs trained: 358Training neural network. Epochs trained: 354Training neural network. Epochs trained: 353Training neural network. Epochs trained: 356Training neural network. Epochs trained: 359Training neural network. Epochs trained: 355Training neural network. Epochs trained: 354Training neural network. Epochs trained: 357Training neural network. Epochs trained: 360Training neural network. Epochs trained: 356Training neural network. Epochs trained: 358Training neural network. Epochs trained: 355Training neural network. Epochs trained: 361Training neural network. Epochs trained: 357Training neural network. Epochs trained: 359Training neural network. Epochs trained: 356Training neural network. Epochs trained: 362Training neural network. Epochs trained: 358Training neural network. Epochs trained: 360Training neural network. Epochs trained: 357Training neural network. Epochs trained: 363Training neural network. Epochs trained: 359Training neural network. Epochs trained: 361Training neural network. Epochs trained: 358Training neural network. Epochs trained: 364Training neural network. Epochs trained: 360Training neural network. Epochs trained: 362Training neural network. Epochs trained: 359Training neural network. Epochs trained: 365Neural network successfully converged after 365 epochs."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/posterior_ensemble.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._weights = torch.tensor(weights) / sum(weights)\n",
      "INFO:root:It took 1065.1026091575623 seconds to train models.\n",
      "INFO:root:Saving model to .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-05-29 10:59:02,371] Trial 2 failed with parameters: {'model': 'maf', 'hidden_features': 72, 'num_transforms': 14, 'learning_rate': 5e-05, 'output_dim': 64} because of the following error: The number of the values 365 did not match the number of the objectives 1.\n",
      "[W 2024-05-29 10:59:02,373] Trial 2 failed with value [-11.238193359375, -11.1837421875, -11.11859765625, -11.051810546875, -10.989634765625, -10.92475, -10.8642451171875, -10.793447265625, -10.71277734375, -10.6235322265625, -10.544611328125, -10.453900390625, -10.360392578125, -10.2717763671875, -10.1816015625, -10.0954716796875, -10.0034111328125, -9.92290625, -9.843298828125, -9.756330078125, -9.674427734375, -9.57765234375, -9.486142578125, -9.3875009765625, -9.291708984375, -9.1958408203125, -9.090654296875, -8.9892880859375, -8.88846875, -8.769263671875, -8.6483369140625, -8.534103515625, -8.40283203125, -8.303240234375, -8.17621875, -8.0787900390625, -7.96617822265625, -7.87684765625, -7.77866943359375, -7.685943359375, -7.595224609375, -7.503724609375, -7.4266923828125, -7.34637744140625, -7.24732763671875, -7.192021484375, -7.10242529296875, -7.03871923828125, -6.95486572265625, -6.8968310546875, -6.814318359375, -6.7424541015625, -6.65127294921875, -6.57206640625, -6.4870712890625, -6.43599267578125, -6.38106689453125, -6.3472158203125, -6.2825849609375, -6.21315185546875, -6.1635087890625, -6.09840625, -6.0522900390625, -6.02591943359375, -5.9620048828125, -5.91364453125, -5.8663916015625, -5.8095185546875, -5.78788037109375, -5.7055029296875, -5.68135546875, -5.62581689453125, -5.58847998046875, -5.5308525390625, -5.47264404296875, -5.43241357421875, -5.39619482421875, -5.3641484375, -5.30971240234375, -5.2510546875, -5.2342490234375, -5.16583154296875, -5.134015625, -5.0941572265625, -5.0530029296875, -5.04467578125, -4.9771064453125, -4.982962890625, -4.9190703125, -4.8875166015625, -4.85875439453125, -4.834958984375, -4.78130810546875, -4.7649326171875, -4.7269794921875, -4.70571728515625, -4.67305078125, -4.6184306640625, -4.5886455078125, -4.59489013671875, -4.5445302734375, -4.52767138671875, -4.5214404296875, -4.4790791015625, -4.44472265625, -4.43714794921875, -4.383076171875, -4.3626318359375, -4.3500126953125, -4.3138798828125, -4.2943544921875, -4.2881181640625, -4.26803466796875, -4.2241591796875, -4.19553759765625, -4.18466796875, -4.15764453125, -4.14372509765625, -4.12655517578125, -4.115376953125, -4.091633056640625, -4.069864501953125, -4.037037353515625, -4.0289833984375, -4.009514892578125, -3.984489501953125, -3.93695556640625, -3.95721923828125, -3.914080078125, -3.905446044921875, -3.88133251953125, -3.857167724609375, -3.878078125, -3.8387255859375, -3.8301455078125, -3.82800048828125, -3.81313671875, -3.773923095703125, -3.806968017578125, -3.78081103515625, -3.752331787109375, -3.71736083984375, -3.6932861328125, -3.684655517578125, -3.670043212890625, -3.64247802734375, -3.635133544921875, -3.61362841796875, -3.61046484375, -3.623559814453125, -3.57848681640625, -3.55514794921875, -3.527218017578125, -3.526671875, -3.499683837890625, -3.48525634765625, -3.475841796875, -3.45937939453125, -3.43779443359375, -3.4060986328125, -3.397185546875, -3.4228056640625, -3.3691728515625, -3.349034423828125, -3.3527646484375, -3.351279052734375, -3.32034765625, -3.30042431640625, -3.305470947265625, -3.296655029296875, -3.248204345703125, -3.272666015625, -3.27376220703125, -3.250478515625, -3.209859375, -3.21115283203125, -3.180021484375, -3.178576171875, -3.1840341796875, -3.1966708984375, -3.143990234375, -3.15560302734375, -3.19249658203125, -3.108240966796875, -3.105203369140625, -3.084453369140625, -3.07477587890625, -3.059446533203125, -3.04392822265625, -3.04740234375, -3.0234873046875, -3.01651611328125, -3.000259765625, -3.04809375, -3.00619189453125, -2.992070556640625, -2.96554052734375, -2.96178955078125, -2.96187451171875, -2.94909130859375, -2.971158447265625, -2.94070166015625, -2.921720947265625, -2.9112646484375, -2.91958154296875, -2.904642333984375, -2.883697021484375, -2.9197744140625, -2.857548583984375, -2.86222998046875, -2.8490927734375, -2.8382783203125, -2.85672021484375, -2.887241455078125, -2.820906982421875, -2.80956689453125, -2.79768701171875, -2.79930810546875, -2.80615576171875, -2.769109130859375, -2.7519453125, -2.791172607421875, -2.7521796875, -2.734767333984375, -2.729035888671875, -2.71472900390625, -2.7420615234375, -2.69651611328125, -2.740997802734375, -2.784202880859375, -2.69016064453125, -2.67338525390625, -2.6865205078125, -2.6629169921875, -2.6871923828125, -2.66672021484375, -2.68013134765625, -2.6262314453125, -2.62638134765625, -2.629611572265625, -2.627593017578125, -2.6338466796875, -2.60468798828125, -2.610467529296875, -2.677100341796875, -2.57508837890625, -2.59095556640625, -2.60436474609375, -2.586213134765625, -2.584705078125, -2.57157421875, -2.605945556640625, -2.5495263671875, -2.607222412109375, -2.6085185546875, -2.591703125, -2.532416015625, -2.541916015625, -2.5565048828125, -2.546207275390625, -2.554138671875, -2.540467529296875, -2.54025244140625, -2.532615234375, -2.503888671875, -2.47138720703125, -2.486110595703125, -2.496234375, -2.473120849609375, -2.51798681640625, -2.506382080078125, -2.44291748046875, -2.4606552734375, -2.453024169921875, -2.428079833984375, -2.4644365234375, -2.45436083984375, -2.420546875, -2.39953125, -2.392753173828125, -2.40379638671875, -2.38940185546875, -2.38884375, -2.403991455078125, -2.421939453125, -2.37252587890625, -2.3841181640625, -2.3433173828125, -2.3221748046875, -2.384440673828125, -2.340052001953125, -2.334322998046875, -2.38311865234375, -2.406337890625, -2.312294921875, -2.32241552734375, -2.330228515625, -2.34401708984375, -2.2953486328125, -2.285908203125, -2.27679638671875, -2.382724365234375, -2.294373046875, -2.2661142578125, -2.25603076171875, -2.284065673828125, -2.274249267578125, -2.309943115234375, -2.26439404296875, -2.25438671875, -2.3170556640625, -2.220864501953125, -2.249965576171875, -2.237313232421875, -2.24580029296875, -2.20907421875, -2.210512939453125, -2.30501123046875, -2.21739111328125, -2.24376123046875, -2.20668505859375, -2.215618408203125, -2.196561279296875, -2.18455078125, -2.276479736328125, -2.17589111328125, -2.211144775390625, -2.2133955078125, -2.1489873046875, -2.19673974609375, -2.154677734375, -2.12999267578125, -2.24942919921875, -2.122992919921875, -2.12054296875, -2.20929248046875, -2.12677587890625, -2.11535693359375, -2.2375830078125, -2.112549072265625, -2.123431396484375, -2.151298828125, -2.139744140625, -2.148411865234375, -2.10220458984375, -2.1272001953125, -2.1087216796875, -2.256116943359375, -2.34585546875, -2.218542236328125, -2.2743408203125, -2.27957958984375, -2.2477421875, -2.20271240234375, -2.227239990234375, -2.308984619140625, -2.2645361328125, -2.1823251953125, -2.20733740234375, -2.297805419921875, -2.195896484375, -2.245196044921875, -2.277802978515625, -2.20959228515625, -2.1577822265625].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "[W 2024-05-29 10:59:03,046] Trial 4 failed with parameters: {'model': 'maf', 'hidden_features': 61, 'num_transforms': 8, 'learning_rate': 5e-05, 'output_dim': 64} because of the following error: AssertionError('Unrecognized device cuda:1, should be one of [`cpu`, `cuda`, f`cuda:{index}`]').\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/vgiusepp/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1459283/1212460247.py\", line 6, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, device), n_trials=100)\n",
      "  File \"/tmp/ipykernel_1459283/1168232568.py\", line 31, in objective\n",
      "    _, summaries = runner(loader=all_loader)\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 289, in __call__\n",
      "    models = [self._setup_engine(net) for net in self.nets]\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 289, in <listcomp>\n",
      "    models = [self._setup_engine(net) for net in self.nets]\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 173, in _setup_engine\n",
      "    return inference_class(\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/snpe/snpe_c.py\", line 84, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/snpe/snpe_base.py\", line 65, in __init__\n",
      "    super().__init__(\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/base.py\", line 111, in __init__\n",
      "    self._device = process_device(device)\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py\", line 38, in process_device\n",
      "    assert device == f\"cuda:{current_gpu_index}\", (\n",
      "AssertionError: Unrecognized device cuda:1, should be one of [`cpu`, `cuda`, f`cuda:{index}`]\n",
      "[W 2024-05-29 10:59:03,057] Trial 4 failed with value None.\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "[W 2024-05-29 10:59:04,159] Trial 5 failed with parameters: {'model': 'nsf', 'hidden_features': 22, 'num_transforms': 15, 'learning_rate': 1e-05, 'output_dim': 32} because of the following error: AssertionError('Unrecognized device cuda:4, should be one of [`cpu`, `cuda`, f`cuda:{index}`]').\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/vgiusepp/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1459283/1212460247.py\", line 6, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, device), n_trials=100)\n",
      "  File \"/tmp/ipykernel_1459283/1168232568.py\", line 31, in objective\n",
      "    _, summaries = runner(loader=all_loader)\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 289, in __call__\n",
      "    models = [self._setup_engine(net) for net in self.nets]\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 289, in <listcomp>\n",
      "    models = [self._setup_engine(net) for net in self.nets]\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 173, in _setup_engine\n",
      "    return inference_class(\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/snpe/snpe_c.py\", line 84, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/snpe/snpe_base.py\", line 65, in __init__\n",
      "    super().__init__(\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/base.py\", line 111, in __init__\n",
      "    self._device = process_device(device)\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py\", line 38, in process_device\n",
      "    assert device == f\"cuda:{current_gpu_index}\", (\n",
      "AssertionError: Unrecognized device cuda:4, should be one of [`cpu`, `cuda`, f`cuda:{index}`]\n",
      "[W 2024-05-29 10:59:04,161] Trial 5 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 362Training neural network. Epochs trained: 364Training neural network. Epochs trained: 361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-05-29 10:59:05,758] Trial 6 failed with parameters: {'model': 'nsf', 'hidden_features': 40, 'num_transforms': 9, 'learning_rate': 0.0001, 'output_dim': 32} because of the following error: RuntimeError('CUDA error: out of memory\\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/vgiusepp/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1459283/1212460247.py\", line 6, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, device), n_trials=100)\n",
      "  File \"/tmp/ipykernel_1459283/1168232568.py\", line 30, in objective\n",
      "    runner = InferenceRunner.from_config(f\"./training.yaml\")\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner.py\", line 84, in from_config\n",
      "    return runner_class.from_config(config_path, **config)\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 109, in from_config\n",
      "    prior = load_from_config(config[\"prior\"])\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/utils/import_utils.py\", line 38, in load_from_config\n",
      "    return load_class(config['module'], config['class'])(**config[\"args\"])\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/utils/distributions_pt.py\", line 37, in __init__\n",
      "    kwargs = {k: torch.as_tensor(v, dtype=torch.float32, device=device)\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/utils/distributions_pt.py\", line 37, in <dictcomp>\n",
      "    kwargs = {k: torch.as_tensor(v, dtype=torch.float32, device=device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "[W 2024-05-29 10:59:05,764] Trial 6 failed with value None.\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "[W 2024-05-29 10:59:06,535] Trial 7 failed with parameters: {'model': 'nsf', 'hidden_features': 66, 'num_transforms': 15, 'learning_rate': 1e-05, 'output_dim': 32} because of the following error: AssertionError('Unrecognized device cuda:6, should be one of [`cpu`, `cuda`, f`cuda:{index}`]').\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/vgiusepp/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1459283/1212460247.py\", line 6, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, device), n_trials=100)\n",
      "  File \"/tmp/ipykernel_1459283/1168232568.py\", line 31, in objective\n",
      "    _, summaries = runner(loader=all_loader)\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 289, in __call__\n",
      "    models = [self._setup_engine(net) for net in self.nets]\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 289, in <listcomp>\n",
      "    models = [self._setup_engine(net) for net in self.nets]\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 173, in _setup_engine\n",
      "    return inference_class(\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/snpe/snpe_c.py\", line 84, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/snpe/snpe_base.py\", line 65, in __init__\n",
      "    super().__init__(\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/base.py\", line 111, in __init__\n",
      "    self._device = process_device(device)\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py\", line 38, in process_device\n",
      "    assert device == f\"cuda:{current_gpu_index}\", (\n",
      "AssertionError: Unrecognized device cuda:6, should be one of [`cpu`, `cuda`, f`cuda:{index}`]\n",
      "[W 2024-05-29 10:59:06,537] Trial 7 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 363Training neural network. Epochs trained: 365Neural network successfully converged after 365 epochs.Training neural network. Epochs trained: 362"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n",
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/posterior_ensemble.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._weights = torch.tensor(weights) / sum(weights)\n",
      "INFO:root:It took 1070.6305184364319 seconds to train models.\n",
      "INFO:root:Saving model to .\n",
      "[W 2024-05-29 10:59:07,857] Trial 1 failed with parameters: {'model': 'nsf', 'hidden_features': 10, 'num_transforms': 15, 'learning_rate': 0.0001, 'output_dim': 64} because of the following error: The number of the values 365 did not match the number of the objectives 1.\n",
      "[W 2024-05-29 10:59:07,859] Trial 1 failed with value [-11.238193359375, -11.1837421875, -11.11859765625, -11.051810546875, -10.989634765625, -10.92475, -10.8642451171875, -10.793447265625, -10.71277734375, -10.6235322265625, -10.544611328125, -10.453900390625, -10.360392578125, -10.2717763671875, -10.1816015625, -10.0954716796875, -10.0034111328125, -9.92290625, -9.843298828125, -9.756330078125, -9.674427734375, -9.57765234375, -9.486142578125, -9.3875009765625, -9.291708984375, -9.1958408203125, -9.090654296875, -8.9892880859375, -8.88846875, -8.769263671875, -8.6483369140625, -8.534103515625, -8.40283203125, -8.303240234375, -8.17621875, -8.0787900390625, -7.96617822265625, -7.87684765625, -7.77866943359375, -7.685943359375, -7.595224609375, -7.503724609375, -7.4266923828125, -7.34637744140625, -7.24732763671875, -7.192021484375, -7.10242529296875, -7.03871923828125, -6.95486572265625, -6.8968310546875, -6.814318359375, -6.7424541015625, -6.65127294921875, -6.57206640625, -6.4870712890625, -6.43599267578125, -6.38106689453125, -6.3472158203125, -6.2825849609375, -6.21315185546875, -6.1635087890625, -6.09840625, -6.0522900390625, -6.02591943359375, -5.9620048828125, -5.91364453125, -5.8663916015625, -5.8095185546875, -5.78788037109375, -5.7055029296875, -5.68135546875, -5.62581689453125, -5.58847998046875, -5.5308525390625, -5.47264404296875, -5.43241357421875, -5.39619482421875, -5.3641484375, -5.30971240234375, -5.2510546875, -5.2342490234375, -5.16583154296875, -5.134015625, -5.0941572265625, -5.0530029296875, -5.04467578125, -4.9771064453125, -4.982962890625, -4.9190703125, -4.8875166015625, -4.85875439453125, -4.834958984375, -4.78130810546875, -4.7649326171875, -4.7269794921875, -4.70571728515625, -4.67305078125, -4.6184306640625, -4.5886455078125, -4.59489013671875, -4.5445302734375, -4.52767138671875, -4.5214404296875, -4.4790791015625, -4.44472265625, -4.43714794921875, -4.383076171875, -4.3626318359375, -4.3500126953125, -4.3138798828125, -4.2943544921875, -4.2881181640625, -4.26803466796875, -4.2241591796875, -4.19553759765625, -4.18466796875, -4.15764453125, -4.14372509765625, -4.12655517578125, -4.115376953125, -4.091633056640625, -4.069864501953125, -4.037037353515625, -4.0289833984375, -4.009514892578125, -3.984489501953125, -3.93695556640625, -3.95721923828125, -3.914080078125, -3.905446044921875, -3.88133251953125, -3.857167724609375, -3.878078125, -3.8387255859375, -3.8301455078125, -3.82800048828125, -3.81313671875, -3.773923095703125, -3.806968017578125, -3.78081103515625, -3.752331787109375, -3.71736083984375, -3.6932861328125, -3.684655517578125, -3.670043212890625, -3.64247802734375, -3.635133544921875, -3.61362841796875, -3.61046484375, -3.623559814453125, -3.57848681640625, -3.55514794921875, -3.527218017578125, -3.526671875, -3.499683837890625, -3.48525634765625, -3.475841796875, -3.45937939453125, -3.43779443359375, -3.4060986328125, -3.397185546875, -3.4228056640625, -3.3691728515625, -3.349034423828125, -3.3527646484375, -3.351279052734375, -3.32034765625, -3.30042431640625, -3.305470947265625, -3.296655029296875, -3.248204345703125, -3.272666015625, -3.27376220703125, -3.250478515625, -3.209859375, -3.21115283203125, -3.180021484375, -3.178576171875, -3.1840341796875, -3.1966708984375, -3.143990234375, -3.15560302734375, -3.19249658203125, -3.108240966796875, -3.105203369140625, -3.084453369140625, -3.07477587890625, -3.059446533203125, -3.04392822265625, -3.04740234375, -3.0234873046875, -3.01651611328125, -3.000259765625, -3.04809375, -3.00619189453125, -2.992070556640625, -2.96554052734375, -2.96178955078125, -2.96187451171875, -2.94909130859375, -2.971158447265625, -2.94070166015625, -2.921720947265625, -2.9112646484375, -2.91958154296875, -2.904642333984375, -2.883697021484375, -2.9197744140625, -2.857548583984375, -2.86222998046875, -2.8490927734375, -2.8382783203125, -2.85672021484375, -2.887241455078125, -2.820906982421875, -2.80956689453125, -2.79768701171875, -2.79930810546875, -2.80615576171875, -2.769109130859375, -2.7519453125, -2.791172607421875, -2.7521796875, -2.734767333984375, -2.729035888671875, -2.71472900390625, -2.7420615234375, -2.69651611328125, -2.740997802734375, -2.784202880859375, -2.69016064453125, -2.67338525390625, -2.6865205078125, -2.6629169921875, -2.6871923828125, -2.66672021484375, -2.68013134765625, -2.6262314453125, -2.62638134765625, -2.629611572265625, -2.627593017578125, -2.6338466796875, -2.60468798828125, -2.610467529296875, -2.677100341796875, -2.57508837890625, -2.59095556640625, -2.60436474609375, -2.586213134765625, -2.584705078125, -2.57157421875, -2.605945556640625, -2.5495263671875, -2.607222412109375, -2.6085185546875, -2.591703125, -2.532416015625, -2.541916015625, -2.5565048828125, -2.546207275390625, -2.554138671875, -2.540467529296875, -2.54025244140625, -2.532615234375, -2.503888671875, -2.47138720703125, -2.486110595703125, -2.496234375, -2.473120849609375, -2.51798681640625, -2.506382080078125, -2.44291748046875, -2.4606552734375, -2.453024169921875, -2.428079833984375, -2.4644365234375, -2.45436083984375, -2.420546875, -2.39953125, -2.392753173828125, -2.40379638671875, -2.38940185546875, -2.38884375, -2.403991455078125, -2.421939453125, -2.37252587890625, -2.3841181640625, -2.3433173828125, -2.3221748046875, -2.384440673828125, -2.340052001953125, -2.334322998046875, -2.38311865234375, -2.406337890625, -2.312294921875, -2.32241552734375, -2.330228515625, -2.34401708984375, -2.2953486328125, -2.285908203125, -2.27679638671875, -2.382724365234375, -2.294373046875, -2.2661142578125, -2.25603076171875, -2.284065673828125, -2.274249267578125, -2.309943115234375, -2.26439404296875, -2.25438671875, -2.3170556640625, -2.220864501953125, -2.249965576171875, -2.237313232421875, -2.24580029296875, -2.20907421875, -2.210512939453125, -2.30501123046875, -2.21739111328125, -2.24376123046875, -2.20668505859375, -2.215618408203125, -2.196561279296875, -2.18455078125, -2.276479736328125, -2.17589111328125, -2.211144775390625, -2.2133955078125, -2.1489873046875, -2.19673974609375, -2.154677734375, -2.12999267578125, -2.24942919921875, -2.122992919921875, -2.12054296875, -2.20929248046875, -2.12677587890625, -2.11535693359375, -2.2375830078125, -2.112549072265625, -2.123431396484375, -2.151298828125, -2.139744140625, -2.148411865234375, -2.10220458984375, -2.1272001953125, -2.1087216796875, -2.256116943359375, -2.34585546875, -2.218542236328125, -2.2743408203125, -2.27957958984375, -2.2477421875, -2.20271240234375, -2.227239990234375, -2.308984619140625, -2.2645361328125, -2.1823251953125, -2.20733740234375, -2.297805419921875, -2.195896484375, -2.245196044921875, -2.277802978515625, -2.20959228515625, -2.1577822265625].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "[W 2024-05-29 10:59:08,675] Trial 8 failed with parameters: {'model': 'maf', 'hidden_features': 96, 'num_transforms': 14, 'learning_rate': 5e-05, 'output_dim': 10} because of the following error: AssertionError('Unrecognized device cuda:2, should be one of [`cpu`, `cuda`, f`cuda:{index}`]').\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/vgiusepp/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1459283/1212460247.py\", line 6, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, device), n_trials=100)\n",
      "  File \"/tmp/ipykernel_1459283/1168232568.py\", line 31, in objective\n",
      "    _, summaries = runner(loader=all_loader)\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 289, in __call__\n",
      "    models = [self._setup_engine(net) for net in self.nets]\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 289, in <listcomp>\n",
      "    models = [self._setup_engine(net) for net in self.nets]\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 173, in _setup_engine\n",
      "    return inference_class(\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/snpe/snpe_c.py\", line 84, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/snpe/snpe_base.py\", line 65, in __init__\n",
      "    super().__init__(\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/base.py\", line 111, in __init__\n",
      "    self._device = process_device(device)\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py\", line 38, in process_device\n",
      "    assert device == f\"cuda:{current_gpu_index}\", (\n",
      "AssertionError: Unrecognized device cuda:2, should be one of [`cpu`, `cuda`, f`cuda:{index}`]\n",
      "[W 2024-05-29 10:59:08,692] Trial 8 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 363Training neural network. Epochs trained: 365Neural network successfully converged after 365 epochs.Training neural network. Epochs trained: 364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n",
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/posterior_ensemble.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._weights = torch.tensor(weights) / sum(weights)\n",
      "INFO:root:It took 1074.1652762889862 seconds to train models.\n",
      "INFO:root:Saving model to .\n",
      "[W 2024-05-29 10:59:11,006] Trial 3 failed with parameters: {'model': 'nsf', 'hidden_features': 22, 'num_transforms': 10, 'learning_rate': 5e-05, 'output_dim': 10} because of the following error: The number of the values 365 did not match the number of the objectives 1.\n",
      "[W 2024-05-29 10:59:11,008] Trial 3 failed with value [-11.238193359375, -11.1837421875, -11.11859765625, -11.051810546875, -10.989634765625, -10.92475, -10.8642451171875, -10.793447265625, -10.71277734375, -10.6235322265625, -10.544611328125, -10.453900390625, -10.360392578125, -10.2717763671875, -10.1816015625, -10.0954716796875, -10.0034111328125, -9.92290625, -9.843298828125, -9.756330078125, -9.674427734375, -9.57765234375, -9.486142578125, -9.3875009765625, -9.291708984375, -9.1958408203125, -9.090654296875, -8.9892880859375, -8.88846875, -8.769263671875, -8.6483369140625, -8.534103515625, -8.40283203125, -8.303240234375, -8.17621875, -8.0787900390625, -7.96617822265625, -7.87684765625, -7.77866943359375, -7.685943359375, -7.595224609375, -7.503724609375, -7.4266923828125, -7.34637744140625, -7.24732763671875, -7.192021484375, -7.10242529296875, -7.03871923828125, -6.95486572265625, -6.8968310546875, -6.814318359375, -6.7424541015625, -6.65127294921875, -6.57206640625, -6.4870712890625, -6.43599267578125, -6.38106689453125, -6.3472158203125, -6.2825849609375, -6.21315185546875, -6.1635087890625, -6.09840625, -6.0522900390625, -6.02591943359375, -5.9620048828125, -5.91364453125, -5.8663916015625, -5.8095185546875, -5.78788037109375, -5.7055029296875, -5.68135546875, -5.62581689453125, -5.58847998046875, -5.5308525390625, -5.47264404296875, -5.43241357421875, -5.39619482421875, -5.3641484375, -5.30971240234375, -5.2510546875, -5.2342490234375, -5.16583154296875, -5.134015625, -5.0941572265625, -5.0530029296875, -5.04467578125, -4.9771064453125, -4.982962890625, -4.9190703125, -4.8875166015625, -4.85875439453125, -4.834958984375, -4.78130810546875, -4.7649326171875, -4.7269794921875, -4.70571728515625, -4.67305078125, -4.6184306640625, -4.5886455078125, -4.59489013671875, -4.5445302734375, -4.52767138671875, -4.5214404296875, -4.4790791015625, -4.44472265625, -4.43714794921875, -4.383076171875, -4.3626318359375, -4.3500126953125, -4.3138798828125, -4.2943544921875, -4.2881181640625, -4.26803466796875, -4.2241591796875, -4.19553759765625, -4.18466796875, -4.15764453125, -4.14372509765625, -4.12655517578125, -4.115376953125, -4.091633056640625, -4.069864501953125, -4.037037353515625, -4.0289833984375, -4.009514892578125, -3.984489501953125, -3.93695556640625, -3.95721923828125, -3.914080078125, -3.905446044921875, -3.88133251953125, -3.857167724609375, -3.878078125, -3.8387255859375, -3.8301455078125, -3.82800048828125, -3.81313671875, -3.773923095703125, -3.806968017578125, -3.78081103515625, -3.752331787109375, -3.71736083984375, -3.6932861328125, -3.684655517578125, -3.670043212890625, -3.64247802734375, -3.635133544921875, -3.61362841796875, -3.61046484375, -3.623559814453125, -3.57848681640625, -3.55514794921875, -3.527218017578125, -3.526671875, -3.499683837890625, -3.48525634765625, -3.475841796875, -3.45937939453125, -3.43779443359375, -3.4060986328125, -3.397185546875, -3.4228056640625, -3.3691728515625, -3.349034423828125, -3.3527646484375, -3.351279052734375, -3.32034765625, -3.30042431640625, -3.305470947265625, -3.296655029296875, -3.248204345703125, -3.272666015625, -3.27376220703125, -3.250478515625, -3.209859375, -3.21115283203125, -3.180021484375, -3.178576171875, -3.1840341796875, -3.1966708984375, -3.143990234375, -3.15560302734375, -3.19249658203125, -3.108240966796875, -3.105203369140625, -3.084453369140625, -3.07477587890625, -3.059446533203125, -3.04392822265625, -3.04740234375, -3.0234873046875, -3.01651611328125, -3.000259765625, -3.04809375, -3.00619189453125, -2.992070556640625, -2.96554052734375, -2.96178955078125, -2.96187451171875, -2.94909130859375, -2.971158447265625, -2.94070166015625, -2.921720947265625, -2.9112646484375, -2.91958154296875, -2.904642333984375, -2.883697021484375, -2.9197744140625, -2.857548583984375, -2.86222998046875, -2.8490927734375, -2.8382783203125, -2.85672021484375, -2.887241455078125, -2.820906982421875, -2.80956689453125, -2.79768701171875, -2.79930810546875, -2.80615576171875, -2.769109130859375, -2.7519453125, -2.791172607421875, -2.7521796875, -2.734767333984375, -2.729035888671875, -2.71472900390625, -2.7420615234375, -2.69651611328125, -2.740997802734375, -2.784202880859375, -2.69016064453125, -2.67338525390625, -2.6865205078125, -2.6629169921875, -2.6871923828125, -2.66672021484375, -2.68013134765625, -2.6262314453125, -2.62638134765625, -2.629611572265625, -2.627593017578125, -2.6338466796875, -2.60468798828125, -2.610467529296875, -2.677100341796875, -2.57508837890625, -2.59095556640625, -2.60436474609375, -2.586213134765625, -2.584705078125, -2.57157421875, -2.605945556640625, -2.5495263671875, -2.607222412109375, -2.6085185546875, -2.591703125, -2.532416015625, -2.541916015625, -2.5565048828125, -2.546207275390625, -2.554138671875, -2.540467529296875, -2.54025244140625, -2.532615234375, -2.503888671875, -2.47138720703125, -2.486110595703125, -2.496234375, -2.473120849609375, -2.51798681640625, -2.506382080078125, -2.44291748046875, -2.4606552734375, -2.453024169921875, -2.428079833984375, -2.4644365234375, -2.45436083984375, -2.420546875, -2.39953125, -2.392753173828125, -2.40379638671875, -2.38940185546875, -2.38884375, -2.403991455078125, -2.421939453125, -2.37252587890625, -2.3841181640625, -2.3433173828125, -2.3221748046875, -2.384440673828125, -2.340052001953125, -2.334322998046875, -2.38311865234375, -2.406337890625, -2.312294921875, -2.32241552734375, -2.330228515625, -2.34401708984375, -2.2953486328125, -2.285908203125, -2.27679638671875, -2.382724365234375, -2.294373046875, -2.2661142578125, -2.25603076171875, -2.284065673828125, -2.274249267578125, -2.309943115234375, -2.26439404296875, -2.25438671875, -2.3170556640625, -2.220864501953125, -2.249965576171875, -2.237313232421875, -2.24580029296875, -2.20907421875, -2.210512939453125, -2.30501123046875, -2.21739111328125, -2.24376123046875, -2.20668505859375, -2.215618408203125, -2.196561279296875, -2.18455078125, -2.276479736328125, -2.17589111328125, -2.211144775390625, -2.2133955078125, -2.1489873046875, -2.19673974609375, -2.154677734375, -2.12999267578125, -2.24942919921875, -2.122992919921875, -2.12054296875, -2.20929248046875, -2.12677587890625, -2.11535693359375, -2.2375830078125, -2.112549072265625, -2.123431396484375, -2.151298828125, -2.139744140625, -2.148411865234375, -2.10220458984375, -2.1272001953125, -2.1087216796875, -2.256116943359375, -2.34585546875, -2.218542236328125, -2.2743408203125, -2.27957958984375, -2.2477421875, -2.20271240234375, -2.227239990234375, -2.308984619140625, -2.2645361328125, -2.1823251953125, -2.20733740234375, -2.297805419921875, -2.195896484375, -2.245196044921875, -2.277802978515625, -2.20959228515625, -2.1577822265625].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 365Neural network successfully converged after 365 epochs."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "INFO:root:Training model 1 / 1.\n",
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n",
      "/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/posterior_ensemble.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._weights = torch.tensor(weights) / sum(weights)\n",
      "INFO:root:It took 1075.449700832367 seconds to train models.\n",
      "INFO:root:Saving model to .\n",
      "[W 2024-05-29 10:59:12,561] Trial 0 failed with parameters: {'model': 'maf', 'hidden_features': 24, 'num_transforms': 5, 'learning_rate': 0.0001, 'output_dim': 10} because of the following error: The number of the values 365 did not match the number of the objectives 1.\n",
      "[W 2024-05-29 10:59:12,563] Trial 0 failed with value [-11.238193359375, -11.1837421875, -11.11859765625, -11.051810546875, -10.989634765625, -10.92475, -10.8642451171875, -10.793447265625, -10.71277734375, -10.6235322265625, -10.544611328125, -10.453900390625, -10.360392578125, -10.2717763671875, -10.1816015625, -10.0954716796875, -10.0034111328125, -9.92290625, -9.843298828125, -9.756330078125, -9.674427734375, -9.57765234375, -9.486142578125, -9.3875009765625, -9.291708984375, -9.1958408203125, -9.090654296875, -8.9892880859375, -8.88846875, -8.769263671875, -8.6483369140625, -8.534103515625, -8.40283203125, -8.303240234375, -8.17621875, -8.0787900390625, -7.96617822265625, -7.87684765625, -7.77866943359375, -7.685943359375, -7.595224609375, -7.503724609375, -7.4266923828125, -7.34637744140625, -7.24732763671875, -7.192021484375, -7.10242529296875, -7.03871923828125, -6.95486572265625, -6.8968310546875, -6.814318359375, -6.7424541015625, -6.65127294921875, -6.57206640625, -6.4870712890625, -6.43599267578125, -6.38106689453125, -6.3472158203125, -6.2825849609375, -6.21315185546875, -6.1635087890625, -6.09840625, -6.0522900390625, -6.02591943359375, -5.9620048828125, -5.91364453125, -5.8663916015625, -5.8095185546875, -5.78788037109375, -5.7055029296875, -5.68135546875, -5.62581689453125, -5.58847998046875, -5.5308525390625, -5.47264404296875, -5.43241357421875, -5.39619482421875, -5.3641484375, -5.30971240234375, -5.2510546875, -5.2342490234375, -5.16583154296875, -5.134015625, -5.0941572265625, -5.0530029296875, -5.04467578125, -4.9771064453125, -4.982962890625, -4.9190703125, -4.8875166015625, -4.85875439453125, -4.834958984375, -4.78130810546875, -4.7649326171875, -4.7269794921875, -4.70571728515625, -4.67305078125, -4.6184306640625, -4.5886455078125, -4.59489013671875, -4.5445302734375, -4.52767138671875, -4.5214404296875, -4.4790791015625, -4.44472265625, -4.43714794921875, -4.383076171875, -4.3626318359375, -4.3500126953125, -4.3138798828125, -4.2943544921875, -4.2881181640625, -4.26803466796875, -4.2241591796875, -4.19553759765625, -4.18466796875, -4.15764453125, -4.14372509765625, -4.12655517578125, -4.115376953125, -4.091633056640625, -4.069864501953125, -4.037037353515625, -4.0289833984375, -4.009514892578125, -3.984489501953125, -3.93695556640625, -3.95721923828125, -3.914080078125, -3.905446044921875, -3.88133251953125, -3.857167724609375, -3.878078125, -3.8387255859375, -3.8301455078125, -3.82800048828125, -3.81313671875, -3.773923095703125, -3.806968017578125, -3.78081103515625, -3.752331787109375, -3.71736083984375, -3.6932861328125, -3.684655517578125, -3.670043212890625, -3.64247802734375, -3.635133544921875, -3.61362841796875, -3.61046484375, -3.623559814453125, -3.57848681640625, -3.55514794921875, -3.527218017578125, -3.526671875, -3.499683837890625, -3.48525634765625, -3.475841796875, -3.45937939453125, -3.43779443359375, -3.4060986328125, -3.397185546875, -3.4228056640625, -3.3691728515625, -3.349034423828125, -3.3527646484375, -3.351279052734375, -3.32034765625, -3.30042431640625, -3.305470947265625, -3.296655029296875, -3.248204345703125, -3.272666015625, -3.27376220703125, -3.250478515625, -3.209859375, -3.21115283203125, -3.180021484375, -3.178576171875, -3.1840341796875, -3.1966708984375, -3.143990234375, -3.15560302734375, -3.19249658203125, -3.108240966796875, -3.105203369140625, -3.084453369140625, -3.07477587890625, -3.059446533203125, -3.04392822265625, -3.04740234375, -3.0234873046875, -3.01651611328125, -3.000259765625, -3.04809375, -3.00619189453125, -2.992070556640625, -2.96554052734375, -2.96178955078125, -2.96187451171875, -2.94909130859375, -2.971158447265625, -2.94070166015625, -2.921720947265625, -2.9112646484375, -2.91958154296875, -2.904642333984375, -2.883697021484375, -2.9197744140625, -2.857548583984375, -2.86222998046875, -2.8490927734375, -2.8382783203125, -2.85672021484375, -2.887241455078125, -2.820906982421875, -2.80956689453125, -2.79768701171875, -2.79930810546875, -2.80615576171875, -2.769109130859375, -2.7519453125, -2.791172607421875, -2.7521796875, -2.734767333984375, -2.729035888671875, -2.71472900390625, -2.7420615234375, -2.69651611328125, -2.740997802734375, -2.784202880859375, -2.69016064453125, -2.67338525390625, -2.6865205078125, -2.6629169921875, -2.6871923828125, -2.66672021484375, -2.68013134765625, -2.6262314453125, -2.62638134765625, -2.629611572265625, -2.627593017578125, -2.6338466796875, -2.60468798828125, -2.610467529296875, -2.677100341796875, -2.57508837890625, -2.59095556640625, -2.60436474609375, -2.586213134765625, -2.584705078125, -2.57157421875, -2.605945556640625, -2.5495263671875, -2.607222412109375, -2.6085185546875, -2.591703125, -2.532416015625, -2.541916015625, -2.5565048828125, -2.546207275390625, -2.554138671875, -2.540467529296875, -2.54025244140625, -2.532615234375, -2.503888671875, -2.47138720703125, -2.486110595703125, -2.496234375, -2.473120849609375, -2.51798681640625, -2.506382080078125, -2.44291748046875, -2.4606552734375, -2.453024169921875, -2.428079833984375, -2.4644365234375, -2.45436083984375, -2.420546875, -2.39953125, -2.392753173828125, -2.40379638671875, -2.38940185546875, -2.38884375, -2.403991455078125, -2.421939453125, -2.37252587890625, -2.3841181640625, -2.3433173828125, -2.3221748046875, -2.384440673828125, -2.340052001953125, -2.334322998046875, -2.38311865234375, -2.406337890625, -2.312294921875, -2.32241552734375, -2.330228515625, -2.34401708984375, -2.2953486328125, -2.285908203125, -2.27679638671875, -2.382724365234375, -2.294373046875, -2.2661142578125, -2.25603076171875, -2.284065673828125, -2.274249267578125, -2.309943115234375, -2.26439404296875, -2.25438671875, -2.3170556640625, -2.220864501953125, -2.249965576171875, -2.237313232421875, -2.24580029296875, -2.20907421875, -2.210512939453125, -2.30501123046875, -2.21739111328125, -2.24376123046875, -2.20668505859375, -2.215618408203125, -2.196561279296875, -2.18455078125, -2.276479736328125, -2.17589111328125, -2.211144775390625, -2.2133955078125, -2.1489873046875, -2.19673974609375, -2.154677734375, -2.12999267578125, -2.24942919921875, -2.122992919921875, -2.12054296875, -2.20929248046875, -2.12677587890625, -2.11535693359375, -2.2375830078125, -2.112549072265625, -2.123431396484375, -2.151298828125, -2.139744140625, -2.148411865234375, -2.10220458984375, -2.1272001953125, -2.1087216796875, -2.256116943359375, -2.34585546875, -2.218542236328125, -2.2743408203125, -2.27957958984375, -2.2477421875, -2.20271240234375, -2.227239990234375, -2.308984619140625, -2.2645361328125, -2.1823251953125, -2.20733740234375, -2.297805419921875, -2.195896484375, -2.245196044921875, -2.277802978515625, -2.20959228515625, -2.1577822265625].\n",
      "INFO:root:MODEL INFERENCE CLASS: NPE\n",
      "[W 2024-05-29 10:59:14,181] Trial 10 failed with parameters: {'model': 'nsf', 'hidden_features': 19, 'num_transforms': 16, 'learning_rate': 1e-05, 'output_dim': 64} because of the following error: AssertionError('Unrecognized device cuda:3, should be one of [`cpu`, `cuda`, f`cuda:{index}`]').\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/vgiusepp/miniconda3/envs/fff/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1459283/1212460247.py\", line 6, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, device), n_trials=100)\n",
      "  File \"/tmp/ipykernel_1459283/1168232568.py\", line 31, in objective\n",
      "    _, summaries = runner(loader=all_loader)\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 289, in __call__\n",
      "    models = [self._setup_engine(net) for net in self.nets]\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 289, in <listcomp>\n",
      "    models = [self._setup_engine(net) for net in self.nets]\n",
      "  File \"/export/home/vgiusepp/CASBI/src/ltu-ili/ili/inference/runner_sbi.py\", line 173, in _setup_engine\n",
      "    return inference_class(\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/snpe/snpe_c.py\", line 84, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/snpe/snpe_base.py\", line 65, in __init__\n",
      "    super().__init__(\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/inference/base.py\", line 111, in __init__\n",
      "    self._device = process_device(device)\n",
      "  File \"/export/home/vgiusepp/.local/lib/python3.10/site-packages/sbi/utils/torchutils.py\", line 38, in process_device\n",
      "    assert device == f\"cuda:{current_gpu_index}\", (\n",
      "AssertionError: Unrecognized device cuda:3, should be one of [`cpu`, `cuda`, f`cuda:{index}`]\n",
      "[W 2024-05-29 10:59:14,190] Trial 10 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 1Training neural network. Epochs trained: 2Training neural network. Epochs trained: 3Training neural network. Epochs trained: 4Training neural network. Epochs trained: 5Training neural network. Epochs trained: 6Training neural network. Epochs trained: 7Training neural network. Epochs trained: 8Training neural network. Epochs trained: 9Training neural network. Epochs trained: 10Training neural network. Epochs trained: 11Training neural network. Epochs trained: 12Training neural network. Epochs trained: 13Training neural network. Epochs trained: 14Training neural network. Epochs trained: 15Training neural network. Epochs trained: 16Training neural network. Epochs trained: 17Training neural network. Epochs trained: 18Training neural network. Epochs trained: 19Training neural network. Epochs trained: 20Training neural network. Epochs trained: 21Training neural network. Epochs trained: 22Training neural network. Epochs trained: 23Training neural network. Epochs trained: 24Training neural network. Epochs trained: 25Training neural network. Epochs trained: 26Training neural network. Epochs trained: 27Training neural network. Epochs trained: 28Training neural network. Epochs trained: 29Training neural network. Epochs trained: 30Training neural network. Epochs trained: 31Training neural network. Epochs trained: 32Training neural network. Epochs trained: 33Training neural network. Epochs trained: 34Training neural network. Epochs trained: 35Training neural network. Epochs trained: 36Training neural network. Epochs trained: 37Training neural network. Epochs trained: 38Training neural network. Epochs trained: 39Training neural network. Epochs trained: 40Training neural network. Epochs trained: 41Training neural network. Epochs trained: 42Training neural network. Epochs trained: 43Training neural network. Epochs trained: 44Training neural network. Epochs trained: 45Training neural network. Epochs trained: 46Training neural network. Epochs trained: 47Training neural network. Epochs trained: 48Training neural network. Epochs trained: 49Training neural network. Epochs trained: 50Training neural network. Epochs trained: 51Training neural network. Epochs trained: 52Training neural network. Epochs trained: 53Training neural network. Epochs trained: 54Training neural network. Epochs trained: 55Training neural network. Epochs trained: 56Training neural network. Epochs trained: 57Training neural network. Epochs trained: 58Training neural network. Epochs trained: 59Training neural network. Epochs trained: 60Training neural network. Epochs trained: 61Training neural network. Epochs trained: 62Training neural network. Epochs trained: 63Training neural network. Epochs trained: 64Training neural network. Epochs trained: 65Training neural network. Epochs trained: 66Training neural network. Epochs trained: 67Training neural network. Epochs trained: 68Training neural network. Epochs trained: 69Training neural network. Epochs trained: 70Training neural network. Epochs trained: 71Training neural network. Epochs trained: 72Training neural network. Epochs trained: 73Training neural network. Epochs trained: 74Training neural network. Epochs trained: 75Training neural network. Epochs trained: 76Training neural network. Epochs trained: 77Training neural network. Epochs trained: 78Training neural network. Epochs trained: 79Training neural network. Epochs trained: 80Training neural network. Epochs trained: 81Training neural network. Epochs trained: 82Training neural network. Epochs trained: 83Training neural network. Epochs trained: 84Training neural network. Epochs trained: 85Training neural network. Epochs trained: 86Training neural network. Epochs trained: 87Training neural network. Epochs trained: 88Training neural network. Epochs trained: 89Training neural network. Epochs trained: 90Training neural network. Epochs trained: 91Training neural network. Epochs trained: 92Training neural network. Epochs trained: 93Training neural network. Epochs trained: 94Training neural network. Epochs trained: 95Training neural network. Epochs trained: 96Training neural network. Epochs trained: 97Training neural network. Epochs trained: 98Training neural network. Epochs trained: 99Training neural network. Epochs trained: 100Training neural network. Epochs trained: 101Training neural network. Epochs trained: 102Training neural network. Epochs trained: 103Training neural network. Epochs trained: 104Training neural network. Epochs trained: 105Training neural network. Epochs trained: 106Training neural network. Epochs trained: 107Training neural network. Epochs trained: 108Training neural network. Epochs trained: 109Training neural network. Epochs trained: 110Training neural network. Epochs trained: 111Training neural network. Epochs trained: 112Training neural network. Epochs trained: 113Training neural network. Epochs trained: 114Training neural network. Epochs trained: 115Training neural network. Epochs trained: 116Training neural network. Epochs trained: 117Training neural network. Epochs trained: 118Training neural network. Epochs trained: 119Training neural network. Epochs trained: 120Training neural network. Epochs trained: 121Training neural network. Epochs trained: 122Training neural network. Epochs trained: 123Training neural network. Epochs trained: 124Training neural network. Epochs trained: 125Training neural network. Epochs trained: 126Training neural network. Epochs trained: 127Training neural network. Epochs trained: 128Training neural network. Epochs trained: 129Training neural network. Epochs trained: 130Training neural network. Epochs trained: 131Training neural network. Epochs trained: 132Training neural network. Epochs trained: 133Training neural network. Epochs trained: 134Training neural network. Epochs trained: 135Training neural network. Epochs trained: 136Training neural network. Epochs trained: 137Training neural network. Epochs trained: 138Training neural network. Epochs trained: 139Training neural network. Epochs trained: 140Training neural network. Epochs trained: 141Training neural network. Epochs trained: 142Training neural network. Epochs trained: 143Training neural network. Epochs trained: 144Training neural network. Epochs trained: 145Training neural network. Epochs trained: 146Training neural network. Epochs trained: 147Training neural network. Epochs trained: 148Training neural network. Epochs trained: 149Training neural network. Epochs trained: 150Training neural network. Epochs trained: 151Training neural network. Epochs trained: 152Training neural network. Epochs trained: 153Training neural network. Epochs trained: 154Training neural network. Epochs trained: 155Training neural network. Epochs trained: 156Training neural network. Epochs trained: 157Training neural network. Epochs trained: 158Training neural network. Epochs trained: 159Training neural network. Epochs trained: 160Training neural network. Epochs trained: 161Training neural network. Epochs trained: 162Training neural network. Epochs trained: 163Training neural network. Epochs trained: 164Training neural network. Epochs trained: 165Training neural network. Epochs trained: 166Training neural network. Epochs trained: 167Training neural network. Epochs trained: 168Training neural network. Epochs trained: 169Training neural network. Epochs trained: 170Training neural network. Epochs trained: 171Training neural network. Epochs trained: 172Training neural network. Epochs trained: 173Training neural network. Epochs trained: 174Training neural network. Epochs trained: 175Training neural network. Epochs trained: 176Training neural network. Epochs trained: 177Training neural network. Epochs trained: 178Training neural network. Epochs trained: 179Training neural network. Epochs trained: 180Training neural network. Epochs trained: 181Training neural network. Epochs trained: 182Training neural network. Epochs trained: 183Training neural network. Epochs trained: 184Training neural network. Epochs trained: 185Training neural network. Epochs trained: 186Training neural network. Epochs trained: 187Training neural network. Epochs trained: 188Training neural network. Epochs trained: 189Training neural network. Epochs trained: 190Training neural network. Epochs trained: 191Training neural network. Epochs trained: 192Training neural network. Epochs trained: 193Training neural network. Epochs trained: 194Training neural network. Epochs trained: 195Training neural network. Epochs trained: 196Training neural network. Epochs trained: 197Training neural network. Epochs trained: 198Training neural network. Epochs trained: 199Training neural network. Epochs trained: 200Training neural network. Epochs trained: 201Training neural network. Epochs trained: 202Training neural network. Epochs trained: 203Training neural network. Epochs trained: 204Training neural network. Epochs trained: 205Training neural network. Epochs trained: 206Training neural network. Epochs trained: 207Training neural network. Epochs trained: 208Training neural network. Epochs trained: 209Training neural network. Epochs trained: 210Training neural network. Epochs trained: 211Training neural network. Epochs trained: 212Training neural network. Epochs trained: 213Training neural network. Epochs trained: 214Training neural network. Epochs trained: 215Training neural network. Epochs trained: 216Training neural network. Epochs trained: 217Training neural network. Epochs trained: 218Training neural network. Epochs trained: 219Training neural network. Epochs trained: 220Training neural network. Epochs trained: 221Training neural network. Epochs trained: 222Training neural network. Epochs trained: 223Training neural network. Epochs trained: 224Training neural network. Epochs trained: 225Training neural network. Epochs trained: 226Training neural network. Epochs trained: 227Training neural network. Epochs trained: 228Training neural network. Epochs trained: 229Training neural network. Epochs trained: 230Training neural network. Epochs trained: 231Training neural network. Epochs trained: 232Training neural network. Epochs trained: 233Training neural network. Epochs trained: 234Training neural network. Epochs trained: 235Training neural network. Epochs trained: 236Training neural network. Epochs trained: 237Training neural network. Epochs trained: 238Training neural network. Epochs trained: 239Training neural network. Epochs trained: 240Training neural network. Epochs trained: 241Training neural network. Epochs trained: 242Training neural network. Epochs trained: 243Training neural network. Epochs trained: 244Training neural network. Epochs trained: 245Training neural network. Epochs trained: 246Training neural network. Epochs trained: 247Training neural network. Epochs trained: 248Training neural network. Epochs trained: 249Training neural network. Epochs trained: 250Training neural network. Epochs trained: 251Training neural network. Epochs trained: 252Training neural network. Epochs trained: 253Training neural network. Epochs trained: 254Training neural network. Epochs trained: 255Training neural network. Epochs trained: 256Training neural network. Epochs trained: 257Training neural network. Epochs trained: 258Training neural network. Epochs trained: 259Training neural network. Epochs trained: 260Training neural network. Epochs trained: 261Training neural network. Epochs trained: 262Training neural network. Epochs trained: 263Training neural network. Epochs trained: 264Training neural network. Epochs trained: 265Training neural network. Epochs trained: 266Training neural network. Epochs trained: 267Training neural network. Epochs trained: 268Training neural network. Epochs trained: 269Training neural network. Epochs trained: 270Training neural network. Epochs trained: 271Training neural network. Epochs trained: 272Training neural network. Epochs trained: 273Training neural network. Epochs trained: 274Training neural network. Epochs trained: 275Training neural network. Epochs trained: 276Training neural network. Epochs trained: 277Training neural network. Epochs trained: 278Training neural network. Epochs trained: 279Training neural network. Epochs trained: 280Training neural network. Epochs trained: 281Training neural network. Epochs trained: 282Training neural network. Epochs trained: 283Training neural network. Epochs trained: 284Training neural network. Epochs trained: 285Training neural network. Epochs trained: 286Training neural network. Epochs trained: 287Training neural network. Epochs trained: 288Training neural network. Epochs trained: 289Training neural network. Epochs trained: 290Training neural network. Epochs trained: 291Training neural network. Epochs trained: 292Training neural network. Epochs trained: 293Training neural network. Epochs trained: 294Training neural network. Epochs trained: 295Training neural network. Epochs trained: 296Training neural network. Epochs trained: 297Training neural network. Epochs trained: 298Training neural network. Epochs trained: 299Training neural network. Epochs trained: 300Training neural network. Epochs trained: 301Training neural network. Epochs trained: 302Training neural network. Epochs trained: 303Training neural network. Epochs trained: 304Training neural network. Epochs trained: 305Training neural network. Epochs trained: 306Training neural network. Epochs trained: 307Training neural network. Epochs trained: 308Training neural network. Epochs trained: 309Training neural network. Epochs trained: 310Training neural network. Epochs trained: 311Training neural network. Epochs trained: 312Training neural network. Epochs trained: 313Training neural network. Epochs trained: 314Training neural network. Epochs trained: 315Training neural network. Epochs trained: 316Training neural network. Epochs trained: 317Training neural network. Epochs trained: 318Training neural network. Epochs trained: 319Training neural network. Epochs trained: 320Training neural network. Epochs trained: 321Training neural network. Epochs trained: 322Training neural network. Epochs trained: 323Training neural network. Epochs trained: 324Training neural network. Epochs trained: 325Training neural network. Epochs trained: 326Training neural network. Epochs trained: 327Training neural network. Epochs trained: 328Training neural network. Epochs trained: 329Training neural network. Epochs trained: 330Training neural network. Epochs trained: 331Training neural network. Epochs trained: 332Training neural network. Epochs trained: 333Training neural network. Epochs trained: 334Training neural network. Epochs trained: 335Training neural network. Epochs trained: 336Training neural network. Epochs trained: 337Training neural network. Epochs trained: 338Training neural network. Epochs trained: 339Training neural network. Epochs trained: 340Training neural network. Epochs trained: 341Training neural network. Epochs trained: 342Training neural network. Epochs trained: 343Training neural network. Epochs trained: 344Training neural network. Epochs trained: 345Training neural network. Epochs trained: 346Training neural network. Epochs trained: 347Training neural network. Epochs trained: 348Training neural network. Epochs trained: 349Training neural network. Epochs trained: 350Training neural network. Epochs trained: 351Training neural network. Epochs trained: 352Training neural network. Epochs trained: 353Training neural network. Epochs trained: 354Training neural network. Epochs trained: 355Training neural network. Epochs trained: 356Training neural network. Epochs trained: 357Training neural network. Epochs trained: 358Training neural network. Epochs trained: 359Training neural network. Epochs trained: 360Training neural network. Epochs trained: 361Training neural network. Epochs trained: 362Training neural network. Epochs trained: 363Training neural network. Epochs trained: 364Training neural network. Epochs trained: 365Training neural network. Epochs trained: 366Training neural network. Epochs trained: 367Training neural network. Epochs trained: 368Training neural network. Epochs trained: 369Training neural network. Epochs trained: 370Training neural network. Epochs trained: 371Training neural network. Epochs trained: 372Training neural network. Epochs trained: 373Training neural network. Epochs trained: 374Training neural network. Epochs trained: 375Training neural network. Epochs trained: 376Training neural network. Epochs trained: 377Training neural network. Epochs trained: 378Training neural network. Epochs trained: 379Training neural network. Epochs trained: 380Training neural network. Epochs trained: 381Training neural network. Epochs trained: 382Training neural network. Epochs trained: 383Training neural network. Epochs trained: 384Training neural network. Epochs trained: 385Training neural network. Epochs trained: 386Training neural network. Epochs trained: 387Training neural network. Epochs trained: 388Training neural network. Epochs trained: 389Training neural network. Epochs trained: 390Training neural network. Epochs trained: 391Training neural network. Epochs trained: 392Training neural network. Epochs trained: 393Training neural network. Epochs trained: 394Training neural network. Epochs trained: 395Training neural network. Epochs trained: 396Training neural network. Epochs trained: 397Training neural network. Epochs trained: 398Training neural network. Epochs trained: 399Training neural network. Epochs trained: 400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m num_gpus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimize_on_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/fff/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import multiprocessing\n",
    "\n",
    "# def optimize_on_device(device_id):\n",
    "#     device = f'cuda:{device_id}'\n",
    "#     study.optimize(lambda trial: objective(trial, device), n_trials=100)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     num_gpus = torch.cuda.device_count()\n",
    "#     with multiprocessing.Pool(num_gpus) as p:\n",
    "#         p.map(optimize_on_device, range(num_gpus))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
