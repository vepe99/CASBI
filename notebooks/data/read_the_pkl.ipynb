{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import yaml\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use('./paper.mcstyle')\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "\n",
    "import ili\n",
    "from ili.dataloaders import StaticNumpyLoader, SBISimulator\n",
    "from ili.validation.runner import ValidationRunner \n",
    "\n",
    "from CASBI.generator.fff.fff_model import FreeFormFlow\n",
    "from CASBI.utils.create_dataframe import rescale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('../../../data/dataframe/dataframe.parquet')\n",
    "data = rescale(data, mean_and_std_path='../../../data/preprocess/mean_and_std.parquet', scale_observations=True, scale_parameter=True, inverse=True)\n",
    "min_feh, max_feh = min(data['feh']), max(data['feh'])\n",
    "min_ofe, max_ofe = min(data['ofe']), max(data['ofe'])\n",
    "data =  data.drop(['gas_log10mass', 'a','redshift', 'mean_metallicity', 'std_metallicity','mean_FeMassFrac', 'std_FeMassFrac', 'mean_OMassFrac', 'std_OMassFrac'], axis=1)\n",
    "conditions = data[data.columns.difference(['feh', 'ofe', 'Galaxy_name'], sort=False)].drop_duplicates()\n",
    "n_halos=3\n",
    "minimum_theta = [conditions[col].values.min() for col in conditions.columns]   \n",
    "maximum_theta = [conditions[col].values.max() for col in conditions.columns]       \n",
    "minimum_theta = np.array(minimum_theta)\n",
    "maximum_theta = np.array(maximum_theta)\n",
    "def repeat_array(arr, repetitions):\n",
    "    return np.repeat(arr, repetitions)\n",
    "repeat_minimum_theta = repeat_array(minimum_theta, n_halos)\n",
    "repeat_maximum_theta = repeat_array(maximum_theta, n_halos) \n",
    "\n",
    "def write_to_yaml(repeat_minimum_theta, repeat_maximum_theta):\n",
    "    # Load the existing data\n",
    "    with open('./training.yaml', 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "\n",
    "    repeat_minimum_theta = repeat_minimum_theta.tolist()\n",
    "    repeat_maximum_theta = repeat_maximum_theta.tolist()\n",
    "    # Update the value\n",
    "    data['prior']['args']['low'] = repeat_minimum_theta\n",
    "    data['prior']['args']['high'] = repeat_maximum_theta\n",
    "\n",
    "    # Write the data back to the file\n",
    "    with open('./training.yaml', 'w') as file:\n",
    "        yaml.safe_dump(data, file)\n",
    "        \n",
    "write_to_yaml(repeat_minimum_theta, repeat_maximum_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_0 = np.load('theta_0.npy')\n",
    "theta_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622ddd2a5c174d37a9ff0f4025e38c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 3000 posterior samples:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (9) must match the size of tensor b (12) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(join(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoy_NPE_posterior.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     samples[m] \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 5\u001b[0m \u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNPE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./x_0.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sbi/utils/posterior_ensemble.py:178\u001b[0m, in \u001b[0;36mNeuralPosteriorEnsemble.sample\u001b[0;34m(self, sample_shape, x, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m posterior_index, sample_size \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mvstack(\n\u001b[1;32m    174\u001b[0m     posterior_indizes\u001b[38;5;241m.\u001b[39munique(return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m )\u001b[38;5;241m.\u001b[39mT:\n\u001b[1;32m    176\u001b[0m     sample_shape_c \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize((\u001b[38;5;28mint\u001b[39m(sample_size),))\n\u001b[1;32m    177\u001b[0m     samples\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposteriors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mposterior_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mvstack(samples)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39msample_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sbi/inference/posteriors/direct_posterior.py:118\u001b[0m, in \u001b[0;36mDirectPosterior.sample\u001b[0;34m(self, sample_shape, x, max_sampling_batch_size, sample_with, show_progress_bars)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_with \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou set `sample_with=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_with\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. As of sbi v0.18.0, setting \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sample_with` is no longer supported. You have to rerun \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.build_posterior(sample_with=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_with\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[0;32m--> 118\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43maccept_reject_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproposal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_reject_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithin_support\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_sampling_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_sampling_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproposal_sampling_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43malternative_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuild_posterior(..., sample_with=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmcmc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sbi/samplers/rejection/rejection.py:276\u001b[0m, in \u001b[0;36maccept_reject_sample\u001b[0;34m(proposal, accept_reject_fn, num_samples, show_progress_bars, warn_acceptance, sample_for_correction_factor, max_sampling_batch_size, proposal_sampling_kwargs, alternative_method, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m proposal\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    272\u001b[0m         (sampling_batch_size,), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mproposal_sampling_kwargs  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     )  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# SNPE-style rejection-sampling when the proposal is the neural net.\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m are_accepted \u001b[38;5;241m=\u001b[39m \u001b[43maccept_reject_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m samples \u001b[38;5;241m=\u001b[39m candidates[are_accepted]\n\u001b[1;32m    280\u001b[0m accepted\u001b[38;5;241m.\u001b[39mappend(samples)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sbi/inference/posteriors/direct_posterior.py:120\u001b[0m, in \u001b[0;36mDirectPosterior.sample.<locals>.<lambda>\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_with \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou set `sample_with=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_with\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. As of sbi v0.18.0, setting \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sample_with` is no longer supported. You have to rerun \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.build_posterior(sample_with=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_with\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    118\u001b[0m samples \u001b[38;5;241m=\u001b[39m accept_reject_sample(\n\u001b[1;32m    119\u001b[0m     proposal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior_estimator,\n\u001b[0;32m--> 120\u001b[0m     accept_reject_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m theta: \u001b[43mwithin_support\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    121\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39mnum_samples,\n\u001b[1;32m    122\u001b[0m     show_progress_bars\u001b[38;5;241m=\u001b[39mshow_progress_bars,\n\u001b[1;32m    123\u001b[0m     max_sampling_batch_size\u001b[38;5;241m=\u001b[39mmax_sampling_batch_size,\n\u001b[1;32m    124\u001b[0m     proposal_sampling_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: x},\n\u001b[1;32m    125\u001b[0m     alternative_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_posterior(..., sample_with=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcmc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    126\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sbi/utils/sbiutils.py:526\u001b[0m, in \u001b[0;36mwithin_support\u001b[0;34m(distribution, samples)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;66;03m# Try to check using the support property, use log prob method otherwise.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 526\u001b[0m     sample_check \u001b[38;5;241m=\u001b[39m \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;66;03m# Before torch v1.7.0, `support.check()` returned bools for every element.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m# From v1.8.0 on, it directly considers all dimensions of a sample. E.g.,\u001b[39;00m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;66;03m# for a single sample in 3D, v1.7.0 would return [[True, True, True]] and\u001b[39;00m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;66;03m# v1.8.0 would return [True].\u001b[39;00m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_check\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/distributions/constraints.py:220\u001b[0m, in \u001b[0;36m_IndependentConstraint.check\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m--> 220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_constraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreinterpreted_batch_ndims:\n\u001b[1;32m    222\u001b[0m         expected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_constraint\u001b[38;5;241m.\u001b[39mevent_dim \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreinterpreted_batch_ndims\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/distributions/constraints.py:400\u001b[0m, in \u001b[0;36m_Interval.check\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower_bound\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m) \u001b[38;5;241m&\u001b[39m (value \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupper_bound)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (9) must match the size of tensor b (12) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "samples = {}\n",
    "m = 'NPE'\n",
    "with open(join('./', 'toy_NPE_posterior.pkl'), 'rb') as f:\n",
    "    samples[m] = pickle.load(f)\n",
    "samples['NPE'].sample((3_000,), x=torch.from_numpy(np.load('./x_0.npy')).unsqueeze(0).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NPE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNPE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NPE'"
     ]
    }
   ],
   "source": [
    "samples['NPE'].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "\n",
    "N_subhalos = 3\n",
    "galaxies_0 = data['Galaxy_name'].sample(N_subhalos)\n",
    "theta_0 =  data[data['Galaxy_name'].isin(galaxies_0)].drop(['feh', 'ofe', 'Galaxy_name'], axis=1).drop_duplicates().values.T.reshape(-1)\n",
    "galaxy_data = data[data['Galaxy_name'].isin(galaxies_0)].values\n",
    "histogram_galaxy, _, _ = np.histogram2d(galaxy_data[:, 0], galaxy_data[:, 1], bins=64, range=[[min_feh, max_feh], [min_ofe, max_ofe]])\n",
    "x_0 =  np.expand_dims(np.log10(histogram_galaxy + 1e-6 +1), axis=0)\n",
    "\n",
    "N=5_000\n",
    "def process_sample(i):\n",
    "    galaxies = data['Galaxy_name'].drop_duplicates().sample(n_halos, random_state=i)\n",
    "    while set(galaxies) == set(galaxies_0):\n",
    "        print('matched galaxies, try again')\n",
    "        galaxies = data['Galaxy_name'].drop_duplicates().sample(n_halos, random_state=i)\n",
    "    parameters =  data[data['Galaxy_name'].isin(galaxies)].drop(['feh', 'ofe', 'Galaxy_name'], axis=1).drop_duplicates().values.T.reshape(-1)\n",
    "    galaxy_data = data[data['Galaxy_name'].isin(galaxies)].values\n",
    "    histogram_galaxy, _, _ = np.histogram2d(galaxy_data[:, 0], galaxy_data[:, 1], bins=64, range=[[min_feh, max_feh], [min_ofe, max_ofe]])\n",
    "    sim_data =  np.expand_dims(np.log10(histogram_galaxy + 1e-6 +1), axis=0)\n",
    "    return parameters, sim_data\n",
    "\n",
    "# Create a pool of workers\n",
    "with Pool() as pool:\n",
    "    # Map the function to the data\n",
    "    results = pool.map(process_sample, range(N))\n",
    "\n",
    "# Unpack the results\n",
    "theta, x = zip(*results)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "theta = torch.from_numpy(np.array(theta)).float()\n",
    "x = torch.from_numpy(np.array(x)).float()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
